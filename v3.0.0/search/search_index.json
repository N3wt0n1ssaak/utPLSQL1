{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Introduction to utPLSQL \u00b6 utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec User Guide Installation Getting Started Annotations Expectations Running unit tests Testing best pracitces Upgrade utPLSQL Reporting Using reporters Reporting errors Code coverage Cheat-sheet About Project Details License Support Authors Contributing Demo project \u00b6 Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarQube . Three steps \u00b6 With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests. Command line \u00b6 The ut_run (for linux/unix) and ut_run.bat (for windows) are simple yet powerful. They can provide output from the tests on the fly. You can also use it to have coloured outputs. Look into utPLSQL-sql-cli project to see more. Coverage \u00b6 If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Introduction to utPLSQL"},{"location":"index.html#introduction-to-utplsql","text":"utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec User Guide Installation Getting Started Annotations Expectations Running unit tests Testing best pracitces Upgrade utPLSQL Reporting Using reporters Reporting errors Code coverage Cheat-sheet About Project Details License Support Authors Contributing","title":"Introduction to utPLSQL"},{"location":"index.html#demo-project","text":"Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarQube .","title":"Demo project"},{"location":"index.html#three-steps","text":"With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests.","title":"Three steps"},{"location":"index.html#command-line","text":"The ut_run (for linux/unix) and ut_run.bat (for windows) are simple yet powerful. They can provide output from the tests on the fly. You can also use it to have coloured outputs. Look into utPLSQL-sql-cli project to see more.","title":"Command line"},{"location":"index.html#coverage","text":"If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Coverage"},{"location":"about/CONTRIBUTING.html","text":"How to contribute \u00b6 The following are the guidelines, everyone should use to contribute to utPLSQL. Changes are welcome from all members of the Community. Getting Started \u00b6 Create a GitHub Account . Fork the utPLSQL Repository and setup your local Repository. Each of the steps below are detailed in the How to Fork article! Clone your Fork to your local machine. Configure \"upstream\" remote to the master utPLSQL repository . Update the git submodules by issuing command: git submodule update --remote --merge For each change you want to make: Create a new branch for your change. Make your change in your new branch. Although changes can be made in the master branch, it easier long term if a new branch is used. Make sure your change is covered with unit tests and/or is represented in examples Verify code compiles and all existing and new unit tests pass. The quickest way to have a Pull Request not be accepted, is to submit code that does not compile or pass tests. Commit change to your local repository. Push change to your remote repository Submit a Pull Request . Note: local and remote branches can be deleted after pull request has been accepted. Note: Getting changes from others requires Syncing your Local repository with Master utPLSQL repository. This can happen at any time. Coding Standards \u00b6 Snake case will be used. This separates keywords in names with underscores. execute_test All names will be lower case. Prefixes: Arguments to procedures and functions will start with a_ an Example would be procedure is_valid(a_owner_name varchar2); Object types and packages will start with ut_ Local variables l_ Global variables g_ Global Constants start with gc_ Types in packages, objects start with t_ Nested Tables start with tt_ varchar2 lengths are set in characters not bytes Testing Environment \u00b6 We are using docker images to test utPLSQL on our Travis CI builds. The following versions of Oracle Database are being used. 11g XE R2 12c SE R1 12c SE R2 These images are based on the official dockerfiles released by Oracle, but due to licensing restrictions, we can't make the images public. You can build your own and use it locally, or push to a private docker repository. The build steps are simple if you already have some experience using Docker. You can find detailed information about how to build your own image with a running database in: example of creating an image with pre-built DB You can find more info about the official Oracle images on the Oracle Database on Docker GitHub page. If you are new to Docker, you can start by reading the Getting Started With Docker docs. Build Notes \u00b6 You need to comment out the VOLUME line. This step is required, because volumes are not saved when using docker commit command. When the build proccess is complete, you will run the container to install the database. Once everything is set up and you see the message \"DATABASE IS READY!\", you may change the password and stop the running container. After the container is stopped, you can safely commit the container. You can use the --squash experimental docker tag to reduce the image size. Example: docker build --force-rm --no-cache --squash -t oracle/db-prebuilt . Travis will use your Docker Hub credentials to pull the private images, and the following secure environment variables must be defined. Variable Description DOCKER_USER DOCKER_PASSWORD Your Docker Hub website credentials. They will be used to pull the private database images. SQLCL \u00b6 Our build configurarion uses SQLCL to run the scripts, and you need to configure a few additional secure environment variables. After the first build, the downloaded file will be cached. Variable Description ORACLE_OTN_USER ORACLE_OTN_PASSWORD Your Oracle website credentials. They will be used to download SQLCL. New to GIT \u00b6 If you are new to GIT here are some links to help you with understanding how it works. GIT Documentation Atlassian Git Tutorial What are other resources for learning Git and GitHub","title":"Contributing"},{"location":"about/CONTRIBUTING.html#how-to-contribute","text":"The following are the guidelines, everyone should use to contribute to utPLSQL. Changes are welcome from all members of the Community.","title":"How to contribute"},{"location":"about/CONTRIBUTING.html#getting-started","text":"Create a GitHub Account . Fork the utPLSQL Repository and setup your local Repository. Each of the steps below are detailed in the How to Fork article! Clone your Fork to your local machine. Configure \"upstream\" remote to the master utPLSQL repository . Update the git submodules by issuing command: git submodule update --remote --merge For each change you want to make: Create a new branch for your change. Make your change in your new branch. Although changes can be made in the master branch, it easier long term if a new branch is used. Make sure your change is covered with unit tests and/or is represented in examples Verify code compiles and all existing and new unit tests pass. The quickest way to have a Pull Request not be accepted, is to submit code that does not compile or pass tests. Commit change to your local repository. Push change to your remote repository Submit a Pull Request . Note: local and remote branches can be deleted after pull request has been accepted. Note: Getting changes from others requires Syncing your Local repository with Master utPLSQL repository. This can happen at any time.","title":"Getting Started"},{"location":"about/CONTRIBUTING.html#coding-standards","text":"Snake case will be used. This separates keywords in names with underscores. execute_test All names will be lower case. Prefixes: Arguments to procedures and functions will start with a_ an Example would be procedure is_valid(a_owner_name varchar2); Object types and packages will start with ut_ Local variables l_ Global variables g_ Global Constants start with gc_ Types in packages, objects start with t_ Nested Tables start with tt_ varchar2 lengths are set in characters not bytes","title":"Coding Standards"},{"location":"about/CONTRIBUTING.html#testing-environment","text":"We are using docker images to test utPLSQL on our Travis CI builds. The following versions of Oracle Database are being used. 11g XE R2 12c SE R1 12c SE R2 These images are based on the official dockerfiles released by Oracle, but due to licensing restrictions, we can't make the images public. You can build your own and use it locally, or push to a private docker repository. The build steps are simple if you already have some experience using Docker. You can find detailed information about how to build your own image with a running database in: example of creating an image with pre-built DB You can find more info about the official Oracle images on the Oracle Database on Docker GitHub page. If you are new to Docker, you can start by reading the Getting Started With Docker docs.","title":"Testing Environment"},{"location":"about/CONTRIBUTING.html#build-notes","text":"You need to comment out the VOLUME line. This step is required, because volumes are not saved when using docker commit command. When the build proccess is complete, you will run the container to install the database. Once everything is set up and you see the message \"DATABASE IS READY!\", you may change the password and stop the running container. After the container is stopped, you can safely commit the container. You can use the --squash experimental docker tag to reduce the image size. Example: docker build --force-rm --no-cache --squash -t oracle/db-prebuilt . Travis will use your Docker Hub credentials to pull the private images, and the following secure environment variables must be defined. Variable Description DOCKER_USER DOCKER_PASSWORD Your Docker Hub website credentials. They will be used to pull the private database images.","title":"Build Notes"},{"location":"about/CONTRIBUTING.html#sqlcl","text":"Our build configurarion uses SQLCL to run the scripts, and you need to configure a few additional secure environment variables. After the first build, the downloaded file will be cached. Variable Description ORACLE_OTN_USER ORACLE_OTN_PASSWORD Your Oracle website credentials. They will be used to download SQLCL.","title":"SQLCL"},{"location":"about/CONTRIBUTING.html#new-to-git","text":"If you are new to GIT here are some links to help you with understanding how it works. GIT Documentation Atlassian Git Tutorial What are other resources for learning Git and GitHub","title":"New to GIT"},{"location":"about/authors.html","text":"Version 3 Major Contributors \u00b6 Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Pavel Kaplya Pazus Robert Love rlove Special thanks to prior major contributors \u00b6 Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Authors"},{"location":"about/authors.html#version-3-major-contributors","text":"Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Pavel Kaplya Pazus Robert Love rlove","title":"Version 3 Major Contributors"},{"location":"about/authors.html#special-thanks-to-prior-major-contributors","text":"Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Special thanks to prior major contributors"},{"location":"about/license.html","text":"Version Information \u00b6 utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"License"},{"location":"about/license.html#version-information","text":"utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"Version Information"},{"location":"about/project-details.html","text":"utPLSQL Project Details \u00b6 utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our guide to contributing","title":"Project Details"},{"location":"about/project-details.html#utplsql-project-details","text":"utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our guide to contributing","title":"utPLSQL Project Details"},{"location":"about/support.html","text":"How to get support \u00b6 Feel free post questions, bugs or issues in the issues area of GitHub . Join developers the utPLSQL team on Slack","title":"Support"},{"location":"about/support.html#how-to-get-support","text":"Feel free post questions, bugs or issues in the issues area of GitHub . Join developers the utPLSQL team on Slack","title":"How to get support"},{"location":"userguide/annotations.html","text":"Annotations \u00b6 Annotations are used to configure tests and suites in a declarative way similar to modern OOP languages. This way, test configuration is stored along with the test logic inside the test package. No configuration files or tables are needed. The annotations names are based on popular testing frameworks such as jUnit. The framework runner searches for all the suitable annotated packages, automatically configures suites, forms suites hierarchy, executes it and reports results in specified formats. Annotations are interpreted only in package specification and are case-insensitive. It is recommended however, to use the lower-case annotations as described in documentation. There are two places where annotations may appear: at the beginning of the package specification ( %suite , %suitepath etc) right before a procedure ( %test , %beforeall , %beforeeach etc). Package level annotations need to be separated by at least one empty line from the underlying procedure annotations. Procedure annotations are defined right before the procedure they reference, no empty lines are allowed. If a package specification contains %suite annotation, it is treated as a test package and processed by the framework. Some annotations accept parameters like %suite , %test %displayname . The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks. Example of annotated test package \u00b6 create or replace package test_pkg is -- %suite(Name of suite) -- %suitepath(all.globaltests) -- %beforeall procedure global_setup ; -- %afterall procedure global_cleanup ; /* Such comments are allowed */ -- %test -- %displayname(Name of a test) procedure some_test ; -- %test(Name of another test) -- %beforetest(setup_another_test) -- %aftertest(cleanup_another_test) procedure another_test ; -- %test -- %displayname(Name of test) -- %disabled procedure disabled_test ; -- %test(Name of test) -- %rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; -- %beforeeach procedure test_setup ; -- %aftereach procedure test_cleanup ; end test_pkg ; Supported annotations \u00b6 Annotation Level Description %suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). %suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. %displayname(<description>) Package/procedure Human-readable and meaningful description of a suite/test. %displayname(Name of the suite/test) . The annotation is provided for flexibility and convenience only. It has exactly the same meaning as <descriotion> in test and suite annotations. If description is provided using both suite / test and displayname , then the one defined as last takes precedence. %test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can by provided (see displayname ). %beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. %afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. %beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. %aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. %beforetest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed before the annotated %test procedure. %aftertest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed after the annotated %test procedure. %rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - A savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) %disabled Package/procedure Used to disable a suite or a test. Disabled suites/tests do not get executed, they are however marked and reported as disabled in a test run. Suitepath concept \u00b6 It is very likely that the application for which you are going to introduce tests consists of many different packages or procedures/functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedure in a single package or even packages themselves might relate to a common module. Lets say you have a complex insurance application the operates with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of you application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off * Payouts The %suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the %suitepath is used by the framework to form a hierarchical structure of them. Your payments recognition test package might look like: create or replace package test_payment_recognition as -- %suite(Payment recognition tests) -- %suitepath(payments) -- %test(Recognize payment by policy number) procedure test_recognize_by_num ; -- %test -- %displayname(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; -- %test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as -- %suite(Payment set off tests) -- %suitepath(payments) -- %test(Set off creation test) procedure test_create_set_off ; -- %test -- %displayname(Set off annulation test) procedure test_annulate_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs test suite for each test package. Then in combines suites into grouping suites by the %suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has is not meeting the expectations of the test. Grouping tests into modules and submodules using the %suitepath annotation allows you to logically organize your projects flat structure of packages int functional groups. Additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing module level common setup for all of the submodules. So in addition to the packages mentioned above you could have following package. create or replace package payments as -- %suite(Payments) -- %beforeall procedure set_common_payments_data ; -- %afterall procedure reset_common_paymnets_data ; end payments ; A %suitepath can be provided in tree ways: * schema - execute all test in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests in all suites from suite1[.suite2][.suite3]...[.procedure] path. If schema is not provided, then current schema is used. Example: :all.rooms_tests . * [schema.]package[.procedure] - execute all tests in the test package provided. The whole hierarchy of suites in the schema is build before, all before/after hooks of partn suites for th provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema. Using automatic rollbacks in tests \u00b6 By default, changes performed by every setup, cleanup and test procedure is isolated using savepoint. This solution is suitable for use-cases, where the code that is getting tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests is not impacting others that might be using a shared development database. If you are in situation, where the code you are testing, is using transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation -- %rollback(manual) on the suite level to disable automatic transaction control for entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most probably fail with error or warning on execution. Some of the automatic rollbacks will most probably fail to execute depending on the configuration you have. In some cases it is needed to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commit in the main session that is executing all your tests. Doing so, allows your test to use automatic transaction control of the framework and release you from the burden of manual cleanup of data that was created or modified by test execution. When you are running test of code that is performing an explicit or implicit commit, you may set the test procedure to run in autonomous transaction with pragma autonomous_transaction . Keep in mind, that when your tests runs in autonomous transaction it will not see the data prepared in setup procedure unless the setup procedure committed the changes. Order of execution \u00b6 When processing the test suite test_pkg defined in Example of annotated test package , the execution will be done in the following order. create a savepoint 'beforeall' execute global_setup create savepoint 'beforeeach' execute test_setup execute some_test execute test_cleanup rollback to savepoint 'beforeeach' create savepoint 'beforeeach' execute test_setup execute setup_anotrher_test execute another_test execute cleanup_another_test execute test_cleanup rollback to savepoint 'beforeeach' mark disabled_test as disabled execute test_setup execute no_transaction_control_test execute test_cleanup execute global_cleanup rollback to savepoint 'beforeall'","title":"Annotations"},{"location":"userguide/annotations.html#annotations","text":"Annotations are used to configure tests and suites in a declarative way similar to modern OOP languages. This way, test configuration is stored along with the test logic inside the test package. No configuration files or tables are needed. The annotations names are based on popular testing frameworks such as jUnit. The framework runner searches for all the suitable annotated packages, automatically configures suites, forms suites hierarchy, executes it and reports results in specified formats. Annotations are interpreted only in package specification and are case-insensitive. It is recommended however, to use the lower-case annotations as described in documentation. There are two places where annotations may appear: at the beginning of the package specification ( %suite , %suitepath etc) right before a procedure ( %test , %beforeall , %beforeeach etc). Package level annotations need to be separated by at least one empty line from the underlying procedure annotations. Procedure annotations are defined right before the procedure they reference, no empty lines are allowed. If a package specification contains %suite annotation, it is treated as a test package and processed by the framework. Some annotations accept parameters like %suite , %test %displayname . The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks.","title":"Annotations"},{"location":"userguide/annotations.html#example-of-annotated-test-package","text":"create or replace package test_pkg is -- %suite(Name of suite) -- %suitepath(all.globaltests) -- %beforeall procedure global_setup ; -- %afterall procedure global_cleanup ; /* Such comments are allowed */ -- %test -- %displayname(Name of a test) procedure some_test ; -- %test(Name of another test) -- %beforetest(setup_another_test) -- %aftertest(cleanup_another_test) procedure another_test ; -- %test -- %displayname(Name of test) -- %disabled procedure disabled_test ; -- %test(Name of test) -- %rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; -- %beforeeach procedure test_setup ; -- %aftereach procedure test_cleanup ; end test_pkg ;","title":"Example of annotated test package"},{"location":"userguide/annotations.html#supported-annotations","text":"Annotation Level Description %suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). %suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. %displayname(<description>) Package/procedure Human-readable and meaningful description of a suite/test. %displayname(Name of the suite/test) . The annotation is provided for flexibility and convenience only. It has exactly the same meaning as <descriotion> in test and suite annotations. If description is provided using both suite / test and displayname , then the one defined as last takes precedence. %test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can by provided (see displayname ). %beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. %afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. %beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. %aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. %beforetest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed before the annotated %test procedure. %aftertest(<procedure_name>) Procedure Denotes that mentioned procedure should be executed after the annotated %test procedure. %rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - A savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) %disabled Package/procedure Used to disable a suite or a test. Disabled suites/tests do not get executed, they are however marked and reported as disabled in a test run.","title":"Supported annotations"},{"location":"userguide/annotations.html#suitepath-concept","text":"It is very likely that the application for which you are going to introduce tests consists of many different packages or procedures/functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedure in a single package or even packages themselves might relate to a common module. Lets say you have a complex insurance application the operates with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of you application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off * Payouts The %suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the %suitepath is used by the framework to form a hierarchical structure of them. Your payments recognition test package might look like: create or replace package test_payment_recognition as -- %suite(Payment recognition tests) -- %suitepath(payments) -- %test(Recognize payment by policy number) procedure test_recognize_by_num ; -- %test -- %displayname(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; -- %test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as -- %suite(Payment set off tests) -- %suitepath(payments) -- %test(Set off creation test) procedure test_create_set_off ; -- %test -- %displayname(Set off annulation test) procedure test_annulate_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs test suite for each test package. Then in combines suites into grouping suites by the %suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has is not meeting the expectations of the test. Grouping tests into modules and submodules using the %suitepath annotation allows you to logically organize your projects flat structure of packages int functional groups. Additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing module level common setup for all of the submodules. So in addition to the packages mentioned above you could have following package. create or replace package payments as -- %suite(Payments) -- %beforeall procedure set_common_payments_data ; -- %afterall procedure reset_common_paymnets_data ; end payments ; A %suitepath can be provided in tree ways: * schema - execute all test in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests in all suites from suite1[.suite2][.suite3]...[.procedure] path. If schema is not provided, then current schema is used. Example: :all.rooms_tests . * [schema.]package[.procedure] - execute all tests in the test package provided. The whole hierarchy of suites in the schema is build before, all before/after hooks of partn suites for th provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema.","title":"Suitepath concept"},{"location":"userguide/annotations.html#using-automatic-rollbacks-in-tests","text":"By default, changes performed by every setup, cleanup and test procedure is isolated using savepoint. This solution is suitable for use-cases, where the code that is getting tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests is not impacting others that might be using a shared development database. If you are in situation, where the code you are testing, is using transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation -- %rollback(manual) on the suite level to disable automatic transaction control for entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most probably fail with error or warning on execution. Some of the automatic rollbacks will most probably fail to execute depending on the configuration you have. In some cases it is needed to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commit in the main session that is executing all your tests. Doing so, allows your test to use automatic transaction control of the framework and release you from the burden of manual cleanup of data that was created or modified by test execution. When you are running test of code that is performing an explicit or implicit commit, you may set the test procedure to run in autonomous transaction with pragma autonomous_transaction . Keep in mind, that when your tests runs in autonomous transaction it will not see the data prepared in setup procedure unless the setup procedure committed the changes.","title":"Using automatic rollbacks in tests"},{"location":"userguide/annotations.html#order-of-execution","text":"When processing the test suite test_pkg defined in Example of annotated test package , the execution will be done in the following order. create a savepoint 'beforeall' execute global_setup create savepoint 'beforeeach' execute test_setup execute some_test execute test_cleanup rollback to savepoint 'beforeeach' create savepoint 'beforeeach' execute test_setup execute setup_anotrher_test execute another_test execute cleanup_another_test execute test_cleanup rollback to savepoint 'beforeeach' mark disabled_test as disabled execute test_setup execute no_transaction_control_test execute test_cleanup execute global_cleanup rollback to savepoint 'beforeall'","title":"Order of execution"},{"location":"userguide/best-practices.html","text":"Best Practices \u00b6 The following are best practices we as utPLSQL have learned about PL/SQL and Unit Testing. Test Isolation and Dependency \u00b6 Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before run Tests should keep environment unchanged post execution Writing tests \u00b6 Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be build so that it can fail, tests that do not fail when needed are useless Gaining value from the tests \u00b6 Tests are only valuable if they are executed frequently, ideally - with every change to the project code Tests need to run very fast, the slower the tests - the longer you wait. Build tests with performance in mind (do you need to have 10k rows to run the tests?) Tests, that are not executed frequently enough get rotten pretty fast and bring burden instead of value. Maintain tests as you maintain code. Tests that are failing, need to be addressed immediately. How can you trust tour tests when 139 of 1000 tests are failing for a month? Will you be able to see each time that it is still the same 139 tests? Tests are not for production \u00b6 Tests generate will generate and operate on fake data. They might insert/update and delete data. You don't want tests to run on production database and touch on real-life data. Tests and their relationship to code under test. \u00b6 Code under test and tests should be in separate packages. This is fundamental separation of responsibilities. Test code commonly will be in the same schema as the tested code. This removes the need to manage privileges for the tests. Version Control \u00b6 Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat database as target, destination for your code not as a source of it.","title":"Testing best pracitces"},{"location":"userguide/best-practices.html#best-practices","text":"The following are best practices we as utPLSQL have learned about PL/SQL and Unit Testing.","title":"Best Practices"},{"location":"userguide/best-practices.html#test-isolation-and-dependency","text":"Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before run Tests should keep environment unchanged post execution","title":"Test Isolation and Dependency"},{"location":"userguide/best-practices.html#writing-tests","text":"Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be build so that it can fail, tests that do not fail when needed are useless","title":"Writing tests"},{"location":"userguide/best-practices.html#gaining-value-from-the-tests","text":"Tests are only valuable if they are executed frequently, ideally - with every change to the project code Tests need to run very fast, the slower the tests - the longer you wait. Build tests with performance in mind (do you need to have 10k rows to run the tests?) Tests, that are not executed frequently enough get rotten pretty fast and bring burden instead of value. Maintain tests as you maintain code. Tests that are failing, need to be addressed immediately. How can you trust tour tests when 139 of 1000 tests are failing for a month? Will you be able to see each time that it is still the same 139 tests?","title":"Gaining value from the tests"},{"location":"userguide/best-practices.html#tests-are-not-for-production","text":"Tests generate will generate and operate on fake data. They might insert/update and delete data. You don't want tests to run on production database and touch on real-life data.","title":"Tests are not for production"},{"location":"userguide/best-practices.html#tests-and-their-relationship-to-code-under-test","text":"Code under test and tests should be in separate packages. This is fundamental separation of responsibilities. Test code commonly will be in the same schema as the tested code. This removes the need to manage privileges for the tests.","title":"Tests and their relationship to code under test."},{"location":"userguide/best-practices.html#version-control","text":"Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat database as target, destination for your code not as a source of it.","title":"Version Control"},{"location":"userguide/coverage.html","text":"Coverage \u00b6 utPLSQL comes with build-in coverage reporting engine. The code coverage reporting is based off DBMS_PROFILER package. Code coverage is gathered for the following source types: * package bodies * type bodies * triggers * stored procedures * stored functions Note: The package specifications and type specifications are explicitly excluded from code coverage analysis.This limitation is introduced to avoid false-negatives. Most of the package specifications don't contain executable code. The only exception is initialization of global constants and variables in package specification.Since, most of package specifications are not executable at all, there is no information available on the number of lines covered and those would eb reported as 0% covered, which is not desired. To obtain information about code coverage of your Unit Tests, all you need to do is run your unit tests with one of build-in code coverage reporters. Following code coverage reporters are supplied with utPLSQL: * ut_coverage_html_reporter - generates a HTML coverage report providing summary and detailed information on code coverage. The html reporter is based on open-source simplecov-html reporter for Ruby. It includes source code of the code that was covered (if possible) * ut_coveralls_reporter - generates a JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by cloud services like coveralls * ut_coverage_sonar_reporter - generates a JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by local services like sonarqube Security model \u00b6 Code coverage is using DBMS_PROFILER to gather information about execution of code under test and therefore follows the DBMS_PROFILER's Security Model In order to be able to gather coverage information, user executing unit tests needs to be either: * Owner of the code that is tested * Have the following privileges to be able to gather coverage on code owned by other users: * create any procedure system privilege * execute privilege on the code that is tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that are tested, but do not have create any procedure system privilege, the code that is tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is testes is complied as NATIVE, the code coverage will not be reported as well. Running unite tests with coverage \u00b6 Using code coverage functionality is as easy as using any other reporter for utPLSQL project. All you need to do is run your tests from your preferred SQL tool and save the outcomes of reporter to a file. All you need to do, is pass the constructor of the reporter to your ut.run Example: begin ut . run ( ut_coverage_html_reporter ()); end ; / Executes all unit tests in current schema, gather information about code coverage and output the html text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce a interactive HTML report. You may see a sample of code coverage for utPLSQL project here The report provides a summary information with list of source code that was expected to be covered. The report allow to navigate to every source and inspect line by line coverage. Coverage reporting options \u00b6 By default the database schema/schemes containing the tests that were executed during the run, are fully reported by coverage reporter. All valid unit tests are excluded from the report regardless if they were invoked or not. This way the coverage report is not affected by presence of tests and contains only the tested code. The default behavior of coverage reporters can be altered, depending on your needs. Including/excluding objects in coverage reports \u00b6 The most basic options are the include/exclude objects lists. You may specify both include and exclude objects lists to specify which objects are to be included in the report and which are to be excluded. Both of those options are meant to be used to narrow down the scope of unit test runs, that is broad by default. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'ut3_user.award_bonus' )); Executes test test_award_bonus and gather coverage only on object ut3_user.award_bonus Alternatively you could run: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' )); Executes test test_award_bonus and gather on all objects in schema ut3_user except valid unit test objects and object betwnstr that schema. You can also combine the parameters and both will be applied. Defining different schema names \u00b6 In some architectures, you might end up in a situation, where your unit tests exist in a different schema than the tested code. This is not the default or recommended approach but is supporter by utPLSQL. In such scenarios, you would probably have a separate database schema to hold unit tests and a separate schema/schemes to hold the tested code. Since by default, coverage reporting is done on the schema/schemes that the invoked tests are on, the code will not be included in coverage report as it is in a different schema than the invoked tests. In this situation you need to provide list of schema names that the tested code is in. This option overrides the default schema names for coverage. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' )); Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on all non unit-test objects from schema usr . You can combine schema names with include/exclude parameters and all will be applied. The a_coverage_schemes parameter takes precedence however, so if include list contains objects from other schemes, that will not be considered. Example: begin ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' ), a_exclude_objects => ut_varchar2_list ( 'usr.betwnstr' ), a_include_objects => ut_varchar2_list ( 'usr.award_bonus' ) ); end ; Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on award_bonus object from schema usr . The exclude list is of no relevance as it is not overlapping with include list. Working with projects and project files \u00b6 Both sonar and coveralls are utilities that are more project-oriented than database-centric. They report statistics and coverage for project files in version control system. Nowadays, most of database projects are moving away from database-centric approach towards project/product-centric approach. Coverage reporting of utPLSQL allows you to perform code coverage analysis for your project files. This feature is supported by all build-in coverage reporting formats. When using this invocation syntax, coverage is only reported for the provided files, so using project files as input for coverage is also a way of limiting the scope of coverage analysis. This syntax also allows usage of a_include_object_list and a_exclude_object_list as optional parameters to filter the scope of analysis. Reporting using externally provided file mapping One of ways to perform coverage reporting on your project files is to provide to the coverage reporter a list of file path/names along with mapping to corresponding object name and object type. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_file_mappings => ut_coverage_file_mappings ( ut_coverage_file_mapping ( file_name => 'sources/hr/award_bonus.prc' , object_owner => 'USR' , object_name => 'AWARD_BONUS' , object_type => 'PROCEDURE' ), ut_coverage_file_mapping ( file_name => 'sources/hr/betwnstr.fnc' , object_owner => 'USR' , object_name => 'BETWNSTR' , object_type => 'FUNCTION' ) ) ); end ; Executes all tests in schema usr and reports coverage for that execution on procedure award_bonus and function betwnstr . The coverage report is mapped-back to file-system object names with paths. Reporting using regex file mapping rule If file names and paths in your project follow a well established naming conventions, then you can use the predefined rule for mapping file names to object names or you can define your own rule and pass it to the coverage reporter at runtime. Example of running with predefined regex mapping rule. begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_files => ut_varchar2_list ( 'sources/hr/award_bonus.prc' , 'sources/hr/betwnstr.fnc' ) ); end ; The predefined rule is based on the following default values for parameters: * a_regex_pattern => '.*(\\\\|\\/)((\\w+)\\.)?(\\w+)\\.(\\w{3})' * a_object_owner_subexpression => 3 * a_object_name_subexpression => 4 * a_object_type_subexpression => 5 * a_file_to_object_type_mapping - defined in table below The predefined file extension to object type mappings file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure Since package specification and type specifications are not considered by coverage, the file extensions for those objects are not included in the mapping. Examples of filename paths that will be mapped correctly using predefined rules. * [...]directory[/subdirectory[/...]]/object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[/subdirectory[/...]]/schema_name.object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\schema_name.object_name.(tpb|pkb|trg|fnc|prc) If file names in your project structure are not prefixed with schema name (like above), the coverage report will look for objects to match the file names in the current schema of the connection that was used to execute tests with coverage. If your project structure is different, you may define your own mapping rule using regex. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources/hr/procedures/award_bonus.sql' , 'sources/hr/functions/betwnstr.sql' ), a_regex_pattern => '.*(\\\\|\\/)(\\w+)\\.(\\w+)\\.(\\w{3})' , a_object_owner_subexpression => 2 , a_object_type_subexpression => 3 , a_object_name_subexpression => 4 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'functions' , 'function' ), ut_key_value_pair ( 'procedures' , 'procedure' ) ) ) ); end ;","title":"Code coverage"},{"location":"userguide/coverage.html#coverage","text":"utPLSQL comes with build-in coverage reporting engine. The code coverage reporting is based off DBMS_PROFILER package. Code coverage is gathered for the following source types: * package bodies * type bodies * triggers * stored procedures * stored functions Note: The package specifications and type specifications are explicitly excluded from code coverage analysis.This limitation is introduced to avoid false-negatives. Most of the package specifications don't contain executable code. The only exception is initialization of global constants and variables in package specification.Since, most of package specifications are not executable at all, there is no information available on the number of lines covered and those would eb reported as 0% covered, which is not desired. To obtain information about code coverage of your Unit Tests, all you need to do is run your unit tests with one of build-in code coverage reporters. Following code coverage reporters are supplied with utPLSQL: * ut_coverage_html_reporter - generates a HTML coverage report providing summary and detailed information on code coverage. The html reporter is based on open-source simplecov-html reporter for Ruby. It includes source code of the code that was covered (if possible) * ut_coveralls_reporter - generates a JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by cloud services like coveralls * ut_coverage_sonar_reporter - generates a JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by local services like sonarqube","title":"Coverage"},{"location":"userguide/coverage.html#security-model","text":"Code coverage is using DBMS_PROFILER to gather information about execution of code under test and therefore follows the DBMS_PROFILER's Security Model In order to be able to gather coverage information, user executing unit tests needs to be either: * Owner of the code that is tested * Have the following privileges to be able to gather coverage on code owned by other users: * create any procedure system privilege * execute privilege on the code that is tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that are tested, but do not have create any procedure system privilege, the code that is tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is testes is complied as NATIVE, the code coverage will not be reported as well.","title":"Security model"},{"location":"userguide/coverage.html#running-unite-tests-with-coverage","text":"Using code coverage functionality is as easy as using any other reporter for utPLSQL project. All you need to do is run your tests from your preferred SQL tool and save the outcomes of reporter to a file. All you need to do, is pass the constructor of the reporter to your ut.run Example: begin ut . run ( ut_coverage_html_reporter ()); end ; / Executes all unit tests in current schema, gather information about code coverage and output the html text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce a interactive HTML report. You may see a sample of code coverage for utPLSQL project here The report provides a summary information with list of source code that was expected to be covered. The report allow to navigate to every source and inspect line by line coverage.","title":"Running unite tests with coverage"},{"location":"userguide/coverage.html#coverage-reporting-options","text":"By default the database schema/schemes containing the tests that were executed during the run, are fully reported by coverage reporter. All valid unit tests are excluded from the report regardless if they were invoked or not. This way the coverage report is not affected by presence of tests and contains only the tested code. The default behavior of coverage reporters can be altered, depending on your needs.","title":"Coverage reporting options"},{"location":"userguide/coverage.html#includingexcluding-objects-in-coverage-reports","text":"The most basic options are the include/exclude objects lists. You may specify both include and exclude objects lists to specify which objects are to be included in the report and which are to be excluded. Both of those options are meant to be used to narrow down the scope of unit test runs, that is broad by default. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'ut3_user.award_bonus' )); Executes test test_award_bonus and gather coverage only on object ut3_user.award_bonus Alternatively you could run: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' )); Executes test test_award_bonus and gather on all objects in schema ut3_user except valid unit test objects and object betwnstr that schema. You can also combine the parameters and both will be applied.","title":"Including/excluding objects in coverage reports"},{"location":"userguide/coverage.html#defining-different-schema-names","text":"In some architectures, you might end up in a situation, where your unit tests exist in a different schema than the tested code. This is not the default or recommended approach but is supporter by utPLSQL. In such scenarios, you would probably have a separate database schema to hold unit tests and a separate schema/schemes to hold the tested code. Since by default, coverage reporting is done on the schema/schemes that the invoked tests are on, the code will not be included in coverage report as it is in a different schema than the invoked tests. In this situation you need to provide list of schema names that the tested code is in. This option overrides the default schema names for coverage. Example: exec ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' )); Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on all non unit-test objects from schema usr . You can combine schema names with include/exclude parameters and all will be applied. The a_coverage_schemes parameter takes precedence however, so if include list contains objects from other schemes, that will not be considered. Example: begin ut . run ( 'ut3_user.test_award_bonus' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'usr' ), a_exclude_objects => ut_varchar2_list ( 'usr.betwnstr' ), a_include_objects => ut_varchar2_list ( 'usr.award_bonus' ) ); end ; Executes test test_award_bonus in schema ut3_user and gather coverage for that execution on award_bonus object from schema usr . The exclude list is of no relevance as it is not overlapping with include list.","title":"Defining different schema names"},{"location":"userguide/coverage.html#working-with-projects-and-project-files","text":"Both sonar and coveralls are utilities that are more project-oriented than database-centric. They report statistics and coverage for project files in version control system. Nowadays, most of database projects are moving away from database-centric approach towards project/product-centric approach. Coverage reporting of utPLSQL allows you to perform code coverage analysis for your project files. This feature is supported by all build-in coverage reporting formats. When using this invocation syntax, coverage is only reported for the provided files, so using project files as input for coverage is also a way of limiting the scope of coverage analysis. This syntax also allows usage of a_include_object_list and a_exclude_object_list as optional parameters to filter the scope of analysis. Reporting using externally provided file mapping One of ways to perform coverage reporting on your project files is to provide to the coverage reporter a list of file path/names along with mapping to corresponding object name and object type. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_file_mappings => ut_coverage_file_mappings ( ut_coverage_file_mapping ( file_name => 'sources/hr/award_bonus.prc' , object_owner => 'USR' , object_name => 'AWARD_BONUS' , object_type => 'PROCEDURE' ), ut_coverage_file_mapping ( file_name => 'sources/hr/betwnstr.fnc' , object_owner => 'USR' , object_name => 'BETWNSTR' , object_type => 'FUNCTION' ) ) ); end ; Executes all tests in schema usr and reports coverage for that execution on procedure award_bonus and function betwnstr . The coverage report is mapped-back to file-system object names with paths. Reporting using regex file mapping rule If file names and paths in your project follow a well established naming conventions, then you can use the predefined rule for mapping file names to object names or you can define your own rule and pass it to the coverage reporter at runtime. Example of running with predefined regex mapping rule. begin ut . run ( 'usr' , ut_coverage_html_reporter (), a_source_files => ut_varchar2_list ( 'sources/hr/award_bonus.prc' , 'sources/hr/betwnstr.fnc' ) ); end ; The predefined rule is based on the following default values for parameters: * a_regex_pattern => '.*(\\\\|\\/)((\\w+)\\.)?(\\w+)\\.(\\w{3})' * a_object_owner_subexpression => 3 * a_object_name_subexpression => 4 * a_object_type_subexpression => 5 * a_file_to_object_type_mapping - defined in table below The predefined file extension to object type mappings file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure Since package specification and type specifications are not considered by coverage, the file extensions for those objects are not included in the mapping. Examples of filename paths that will be mapped correctly using predefined rules. * [...]directory[/subdirectory[/...]]/object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[/subdirectory[/...]]/schema_name.object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\object_name.(tpb|pkb|trg|fnc|prc) * [...]directory[\\subdirectory[\\...]]\\schema_name.object_name.(tpb|pkb|trg|fnc|prc) If file names in your project structure are not prefixed with schema name (like above), the coverage report will look for objects to match the file names in the current schema of the connection that was used to execute tests with coverage. If your project structure is different, you may define your own mapping rule using regex. Example: begin ut . run ( 'usr' , ut_coverage_html_reporter (), ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources/hr/procedures/award_bonus.sql' , 'sources/hr/functions/betwnstr.sql' ), a_regex_pattern => '.*(\\\\|\\/)(\\w+)\\.(\\w+)\\.(\\w{3})' , a_object_owner_subexpression => 2 , a_object_type_subexpression => 3 , a_object_name_subexpression => 4 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'functions' , 'function' ), ut_key_value_pair ( 'procedures' , 'procedure' ) ) ) ); end ;","title":"Working with projects and project files"},{"location":"userguide/exception-reporting.html","text":"Exception handling and reporting \u00b6 The utPLSQL is responsible for handling exceptions wherever they occur in the test run. utPLSQL is trapping most of the exceptions so that the test execution is not affected by individual tests or test packages throwing an exception. The framework provides a full stacktrace for every exception that was thrown. The stacktrace is clean and does not include any utPLSQL library calls in it. To achieve rerunability, the ORA-04068, ORA-04061 exceptions are not handled and test execution will be interrupted if such exception is encountered. This is because of how Oracle behaves on those exceptions. Test execution can fail for different reasons. The failures on different exceptions are handled as follows: * A test package without body - each %test is reported as failed with exception, nothing is executed * A test package with invalid body - each %test is reported as failed with exception, nothing is executed * A test package with invalid spec - package is not considered a valid unit test package and is excluded from execution. When trying to run a test package with invalid spec explicitly, exception is raised. Only valid specifications are parsed for annotations * A test package that is raising an exception in %beforeall - each %test is reported as failed with exception, %test , %beforeeach , %beforetest , %aftertest and %aftereach are not executed. %afterall is executed to allow cleanup of whatever was done in %beforeall * A test package that is raising an exception in %beforeeach - each %test is reported as failed with exception, %test , %beforetest and %aftertest is not executed. The %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %beforetest - the %test is reported as failed with exception, %test is not executed. The %aftertest , %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %test - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftertest - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftereach - each %test is reported as failed with exception. * A test package that is raising an exception in %afterall - all blocks of the package are executed, as the %afterall is the last step of package execution. Exception in %afterall is not affecting test results. A warning with exception stacktrace is displayed in the summary Example of reporting with exception thrown in %beforetest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 39 ORA-06512: at line 6 Finished in ,039346 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %test : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 48 ORA-06512: at line 6 Finished in ,035726 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftertest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 42 ORA-06512: at line 6 Finished in ,045523 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftereach : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content (FAILED - 2) Raises exception when null room name given (FAILED - 3) Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 2) room_with_content error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 3) null_room_name error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 Finished in ,034863 seconds 3 tests, 0 failed, 3 errored, 0 ignored. Example of reporting with exception thrown in %afterall : Remove rooms by name Removes a room without content in it Does not remove room when it has content Raises exception when null room name given Warnings: 1) test_remove_rooms_by_name - Afterall procedure failed: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 35 ORA-06512: at line 6 Finished in ,044902 seconds 3 tests, 0 failed, 0 errored, 0 ignored. 1 warning(s)","title":"Error handling and reporting"},{"location":"userguide/exception-reporting.html#exception-handling-and-reporting","text":"The utPLSQL is responsible for handling exceptions wherever they occur in the test run. utPLSQL is trapping most of the exceptions so that the test execution is not affected by individual tests or test packages throwing an exception. The framework provides a full stacktrace for every exception that was thrown. The stacktrace is clean and does not include any utPLSQL library calls in it. To achieve rerunability, the ORA-04068, ORA-04061 exceptions are not handled and test execution will be interrupted if such exception is encountered. This is because of how Oracle behaves on those exceptions. Test execution can fail for different reasons. The failures on different exceptions are handled as follows: * A test package without body - each %test is reported as failed with exception, nothing is executed * A test package with invalid body - each %test is reported as failed with exception, nothing is executed * A test package with invalid spec - package is not considered a valid unit test package and is excluded from execution. When trying to run a test package with invalid spec explicitly, exception is raised. Only valid specifications are parsed for annotations * A test package that is raising an exception in %beforeall - each %test is reported as failed with exception, %test , %beforeeach , %beforetest , %aftertest and %aftereach are not executed. %afterall is executed to allow cleanup of whatever was done in %beforeall * A test package that is raising an exception in %beforeeach - each %test is reported as failed with exception, %test , %beforetest and %aftertest is not executed. The %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %beforetest - the %test is reported as failed with exception, %test is not executed. The %aftertest , %aftereach and %afterall blocks are getting executed to allow cleanup of whatever was done in %before... blocks * A test package that is raising an exception in %test - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftertest - the %test is reported as failed with exception. The execution of other blocks continues normally * A test package that is raising an exception in %aftereach - each %test is reported as failed with exception. * A test package that is raising an exception in %afterall - all blocks of the package are executed, as the %afterall is the last step of package execution. Exception in %afterall is not affecting test results. A warning with exception stacktrace is displayed in the summary Example of reporting with exception thrown in %beforetest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 39 ORA-06512: at line 6 Finished in ,039346 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %test : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 48 ORA-06512: at line 6 Finished in ,035726 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftertest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 42 ORA-06512: at line 6 Finished in ,045523 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftereach : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content (FAILED - 2) Raises exception when null room name given (FAILED - 3) Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 2) room_with_content error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 3) null_room_name error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 Finished in ,034863 seconds 3 tests, 0 failed, 3 errored, 0 ignored. Example of reporting with exception thrown in %afterall : Remove rooms by name Removes a room without content in it Does not remove room when it has content Raises exception when null room name given Warnings: 1) test_remove_rooms_by_name - Afterall procedure failed: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 35 ORA-06512: at line 6 Finished in ,044902 seconds 3 tests, 0 failed, 0 errored, 0 ignored. 1 warning(s)","title":"Exception handling and reporting"},{"location":"userguide/expectations.html","text":"Concepts \u00b6 Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. To achieve that, we use a combination of expectation and matcher to perform the check on the data. Example of unit test procedure body. begin ut . expect ( 'the tested value' ). to_ ( equal ( 'the expected value' ) ); end ; Expectation is a set of the expected value(s), actual values(s) and the matcher(s) to run on those values. Matcher is defining the comparison operation to be performed on expected and actual values. Pseudo-code: ut.expect( a_actual {data-type} ).to_( {matcher} ); ut.expect( a_actual {data-type} ).not_to( {matcher} ); All matchers have shortcuts like: ut.expect( a_actual {data-type} ).to_{matcher}; ut.expect( a_actual {data-type} ).not_to_{matcher}; Matchers \u00b6 utPLSQL provides following matchers to perform checks on the expected and actual values. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match be_between \u00b6 Validates that the actual value is between the lower and upper bound. Example: begin ut . expect ( a_actual => 3 ). to_be_between ( a_lower_bound => 1 , a_upper_bound => 3 ); ut . expect ( 3 ). to_be_between ( 1 , 3 ); --or ut . expect ( a_actual => 3 ). to_ ( be_between ( a_lower_bound => 1 , a_upper_bound => 3 ) ); ut . expect ( 3 ). to_ ( be_between ( 1 , 3 ) ); end ; be_empty \u00b6 Unary matcher that validates if the provided data-set is empty. Usage: procedure test_if_cursor_is_empty is l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 1 = 0 ; ut . expect ( l_cursor ). to_be_empty (); --or ut . expect ( l_cursor ). to_ ( be_empty () ); end ; When used with anydata, it is only valid for collection data types. be_false \u00b6 Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); --or ut . expect ( ( 1 = 0 ) ). to_ ( be_false () ); end ; be_greater_or_equal \u00b6 Allows to check if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); --or ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate - 1 ) ); end ; be_greater_than \u00b6 Allows to check if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); --or ut . expect ( 2 ). to_ ( be_greater_than ( 1 ) ); end ; be_less_or_equal \u00b6 Allows to check if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); --or ut . expect ( 3 ). to_ ( be_less_or_equal ( 3 ) ); end ; be_less_than \u00b6 Allows to check if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); --or ut . expect ( 3 ). to_ ( be_less_than ( 2 ) ); end ; be_like \u00b6 Validates that the actual value is like the expected expression. Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem#_%' , '#' ); --or ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ) ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( '%rem#_%' , '#' ) ); end ; Parameters a_mask and a_escape_char represent a valid parameters of the Oracle like function be_not_null \u00b6 Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); --or ut . expect ( to_clob ( 'ABC' ) ). to_ ( be_not_null () ); --or ut . expect ( to_clob ( 'ABC' ) ). not_to ( be_null () ); end ; be_null \u00b6 Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( cast ( null as varchar2 ( 100 )) ). to_be_null (); --or ut . expect ( cast ( null as varchar2 ( 100 )) ). to_ ( be_null () ); end ; be_true \u00b6 Unary matcher that validates if the provided value is false. - boolean Usage: begin ut . expect ( ( 1 = 1 ) ). to_be_true (); --or ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); end ; equal \u00b6 The equal matcher is a very restrictive matcher. It only returns true, if compared data-types are the same. That means, that comparing varchar2 to a number will fail even if the varchar2 contains the same number. This matcher is designed to capture changes of data-type, so that if you expect your variable to be number and is now something else, the test will fail and give you early indication of potential problem. Usage: declare x varchar2 ( 100 ); y varchar2 ( 100 ); begin ut . expect ( 'a dog' ). to_equal ( 'a dog' ); ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_nulls_are_equal => true ); --or ut . expect ( 'a dog' ). to_ ( equal ( 'a dog' ) ); ut . expect ( a_actual => y ). to_ ( equal ( a_expected => x , a_nulls_are_equal => true ) ); end ; The a_nulls_are_equal parameter decides on the behavior of null=null comparison ( this comparison by default is true! ) Comparing cursors \u00b6 The equal matcher accepts additional parameter a_exclude varchar2 or a_exclude ut_varchar2_list , when used to compare cursor data. Those parameters allow passing a list of column names to exclude from data comparison. The list can be a comma separated varchar2 list or a ut_varchar2_list collection. The column names accepted by parameter are case sensitive and cannot be quoted. If a_exclude parameter is not specified, all columns are included. If a column to be excluded does not exist, the column cannot be excluded and it's name is simply ignored. It is useful when testing cursors containing data that is beyond our control (like default or trigger/procedure generated sysdate values on columns). procedure test_cursors_skip_columns is x sys_refcursor ; y sys_refcursor ; begin open x for select 'text' ignore_me , d . * from user_tables d ; open y for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_exclude => 'IGNORE_ME,ADate' ); end ; Using cursors to compare PLSQL records on Oracle 12c \u00b6 There is a great article by Tim Hall on using the TABLE Operator with Locally Defined Types in PL/SQL . If you are on Oracle 12c, you can benefit from this feature to make comparison of PLSQL records and tables super-simple in utPLSQL. You can use the feature described in article to convert PLSQL records and collection types to cursors. Complex cursor data can then be compared in utPLQL. Comparing cursor data containing DATE fields \u00b6 Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far most flexible and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened decides ont the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time part of it. You should use procedures ut.set_nls , ut.reset_nls around cursors that you want to compare in your tests. This way, the DATE data in cursors will get properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that date in l_expected and l_actual is compared using date-time formatting. create table events ( description varchar2 ( 4000 ), event_date date ); create or replace function get_events ( a_date_from date , a_date_to date ) return sys_refcursor is l_result sys_refcursor ; begin open l_result for select description , event_date from events where event_date between a_date_from and a_date_to ; return l_result ; end ; / create or replace package test_get_events is --%suite(get_events) --%beforeall procedure setup_events ; --%test(returns event within date range) procedure get_events_for_date_range ; end ; / create or replace package body test_get_events is gc_description constant varchar2 ( 30 ) : = 'Test event' ; gc_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); procedure setup_events is begin insert into events ( description , event_date ) values ( gc_description , gc_event_date ); end ; procedure get_events_for_date_range is l_expected sys_refcursor ; l_actual sys_refcursor ; l_expected_bad_date sys_refcursor ; l_second number : = 1 / 24 / 60 / 60 ; begin ut . set_nls (); open l_expected for select gc_description as description , gc_event_date as event_date from dual ; open l_expected_bad_date for select gc_description as description , gc_event_date + l_second as event_date from dual ; l_actual : = get_events ( gc_event_date - 1 , gc_event_date + 1 ); ut . reset_nls (); ut . expect ( l_actual ). to_equal ( l_expected ); ut . expect ( l_actual ). not_to_equal ( l_expected_bad_date ); end ; end ; / begin ut . run (); end ; / drop table events ; drop function get_events ; drop package test_get_events ; Comparing user defined types and collections \u00b6 The anydata data type is used to compare user defined object and collections. Example: create type department as object ( name varchar2 ( 30 )); / create type departments as table of department ; / create or replace package demo_dept as -- %suite(demo) --%test(demo of object to object comparison) procedure test_department ; --%test(demo of collection comparison) procedure test_departments ; end ; / create or replace package body demo_dept as procedure test_department is v_expected department ; v_actual department ; begin v_expected : = department ( 'HR' ); v_actual : = department ( 'IT' ); ut . expect ( anydata . convertObject ( v_expected ) ). to_equal ( anydata . convertObject ( v_actual ) ); end ; procedure test_department is v_expected department ; v_actual department ; begin v_expected : = departments ( department ( 'HR' )); v_actual : = departments ( department ( 'IT' )); ut . expect ( anydata . convertCollection ( v_expected ) ). to_equal ( anydata . convertCollection ( v_actual ) ); end ; end ; / This test will fail as the v_acutal is not equal v_expected . match \u00b6 Validates that the actual value is matching the expected regular expression. Usage: begin ut . expect ( a_actual => '123-456-ABcd' ). to_match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ); ut . expect ( 'some value' ). to_match ( '^some.*' ); --or ut . expect ( a_actual => '123-456-ABcd' ). to_ ( match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ) ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ); end ; Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle regexp_like function Supported data types \u00b6 Below matrix illustrates the data types supported by different matchers. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match anydata X X X X blob X X X boolean X X X X X clob X X X X X date X X X X X X X X number X X X X X X X X refcursor X X X X timestamp X X X X X X X X timestamp with timezone X X X X X X X X timestamp with local timezone X X X X X X X X varchar2 X X X X X X interval year to month X X X X X X X X interval day to second X X X X X X X X Negating a matcher \u00b6 Expectations provide a very convenient way to perform a check on negated matcher. Syntax of check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax of check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: begin ut . expect ( null ). to_ ( be_true () ); ut . expect ( null ). not_to ( be_true () ); end ; Since NULL is neither true not it is not true, both expectations will report failure.","title":"Expectations"},{"location":"userguide/expectations.html#concepts","text":"Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. To achieve that, we use a combination of expectation and matcher to perform the check on the data. Example of unit test procedure body. begin ut . expect ( 'the tested value' ). to_ ( equal ( 'the expected value' ) ); end ; Expectation is a set of the expected value(s), actual values(s) and the matcher(s) to run on those values. Matcher is defining the comparison operation to be performed on expected and actual values. Pseudo-code: ut.expect( a_actual {data-type} ).to_( {matcher} ); ut.expect( a_actual {data-type} ).not_to( {matcher} ); All matchers have shortcuts like: ut.expect( a_actual {data-type} ).to_{matcher}; ut.expect( a_actual {data-type} ).not_to_{matcher};","title":"Concepts"},{"location":"userguide/expectations.html#matchers","text":"utPLSQL provides following matchers to perform checks on the expected and actual values. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match","title":"Matchers"},{"location":"userguide/expectations.html#be_between","text":"Validates that the actual value is between the lower and upper bound. Example: begin ut . expect ( a_actual => 3 ). to_be_between ( a_lower_bound => 1 , a_upper_bound => 3 ); ut . expect ( 3 ). to_be_between ( 1 , 3 ); --or ut . expect ( a_actual => 3 ). to_ ( be_between ( a_lower_bound => 1 , a_upper_bound => 3 ) ); ut . expect ( 3 ). to_ ( be_between ( 1 , 3 ) ); end ;","title":"be_between"},{"location":"userguide/expectations.html#be_empty","text":"Unary matcher that validates if the provided data-set is empty. Usage: procedure test_if_cursor_is_empty is l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 1 = 0 ; ut . expect ( l_cursor ). to_be_empty (); --or ut . expect ( l_cursor ). to_ ( be_empty () ); end ; When used with anydata, it is only valid for collection data types.","title":"be_empty"},{"location":"userguide/expectations.html#be_false","text":"Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); --or ut . expect ( ( 1 = 0 ) ). to_ ( be_false () ); end ;","title":"be_false"},{"location":"userguide/expectations.html#be_greater_or_equal","text":"Allows to check if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); --or ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate - 1 ) ); end ;","title":"be_greater_or_equal"},{"location":"userguide/expectations.html#be_greater_than","text":"Allows to check if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); --or ut . expect ( 2 ). to_ ( be_greater_than ( 1 ) ); end ;","title":"be_greater_than"},{"location":"userguide/expectations.html#be_less_or_equal","text":"Allows to check if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); --or ut . expect ( 3 ). to_ ( be_less_or_equal ( 3 ) ); end ;","title":"be_less_or_equal"},{"location":"userguide/expectations.html#be_less_than","text":"Allows to check if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); --or ut . expect ( 3 ). to_ ( be_less_than ( 2 ) ); end ;","title":"be_less_than"},{"location":"userguide/expectations.html#be_like","text":"Validates that the actual value is like the expected expression. Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem#_%' , '#' ); --or ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( a_mask => '%rem#_%' , a_escape_char => '#' ) ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( '%rem#_%' , '#' ) ); end ; Parameters a_mask and a_escape_char represent a valid parameters of the Oracle like function","title":"be_like"},{"location":"userguide/expectations.html#be_not_null","text":"Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); --or ut . expect ( to_clob ( 'ABC' ) ). to_ ( be_not_null () ); --or ut . expect ( to_clob ( 'ABC' ) ). not_to ( be_null () ); end ;","title":"be_not_null"},{"location":"userguide/expectations.html#be_null","text":"Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( cast ( null as varchar2 ( 100 )) ). to_be_null (); --or ut . expect ( cast ( null as varchar2 ( 100 )) ). to_ ( be_null () ); end ;","title":"be_null"},{"location":"userguide/expectations.html#be_true","text":"Unary matcher that validates if the provided value is false. - boolean Usage: begin ut . expect ( ( 1 = 1 ) ). to_be_true (); --or ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); end ;","title":"be_true"},{"location":"userguide/expectations.html#equal","text":"The equal matcher is a very restrictive matcher. It only returns true, if compared data-types are the same. That means, that comparing varchar2 to a number will fail even if the varchar2 contains the same number. This matcher is designed to capture changes of data-type, so that if you expect your variable to be number and is now something else, the test will fail and give you early indication of potential problem. Usage: declare x varchar2 ( 100 ); y varchar2 ( 100 ); begin ut . expect ( 'a dog' ). to_equal ( 'a dog' ); ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_nulls_are_equal => true ); --or ut . expect ( 'a dog' ). to_ ( equal ( 'a dog' ) ); ut . expect ( a_actual => y ). to_ ( equal ( a_expected => x , a_nulls_are_equal => true ) ); end ; The a_nulls_are_equal parameter decides on the behavior of null=null comparison ( this comparison by default is true! )","title":"equal"},{"location":"userguide/expectations.html#comparing-cursors","text":"The equal matcher accepts additional parameter a_exclude varchar2 or a_exclude ut_varchar2_list , when used to compare cursor data. Those parameters allow passing a list of column names to exclude from data comparison. The list can be a comma separated varchar2 list or a ut_varchar2_list collection. The column names accepted by parameter are case sensitive and cannot be quoted. If a_exclude parameter is not specified, all columns are included. If a column to be excluded does not exist, the column cannot be excluded and it's name is simply ignored. It is useful when testing cursors containing data that is beyond our control (like default or trigger/procedure generated sysdate values on columns). procedure test_cursors_skip_columns is x sys_refcursor ; y sys_refcursor ; begin open x for select 'text' ignore_me , d . * from user_tables d ; open y for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( a_actual => y ). to_equal ( a_expected => x , a_exclude => 'IGNORE_ME,ADate' ); end ;","title":"Comparing cursors"},{"location":"userguide/expectations.html#using-cursors-to-compare-plsql-records-on-oracle-12c","text":"There is a great article by Tim Hall on using the TABLE Operator with Locally Defined Types in PL/SQL . If you are on Oracle 12c, you can benefit from this feature to make comparison of PLSQL records and tables super-simple in utPLSQL. You can use the feature described in article to convert PLSQL records and collection types to cursors. Complex cursor data can then be compared in utPLQL.","title":"Using cursors to compare PLSQL records on Oracle 12c"},{"location":"userguide/expectations.html#comparing-cursor-data-containing-date-fields","text":"Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far most flexible and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened decides ont the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time part of it. You should use procedures ut.set_nls , ut.reset_nls around cursors that you want to compare in your tests. This way, the DATE data in cursors will get properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that date in l_expected and l_actual is compared using date-time formatting. create table events ( description varchar2 ( 4000 ), event_date date ); create or replace function get_events ( a_date_from date , a_date_to date ) return sys_refcursor is l_result sys_refcursor ; begin open l_result for select description , event_date from events where event_date between a_date_from and a_date_to ; return l_result ; end ; / create or replace package test_get_events is --%suite(get_events) --%beforeall procedure setup_events ; --%test(returns event within date range) procedure get_events_for_date_range ; end ; / create or replace package body test_get_events is gc_description constant varchar2 ( 30 ) : = 'Test event' ; gc_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); procedure setup_events is begin insert into events ( description , event_date ) values ( gc_description , gc_event_date ); end ; procedure get_events_for_date_range is l_expected sys_refcursor ; l_actual sys_refcursor ; l_expected_bad_date sys_refcursor ; l_second number : = 1 / 24 / 60 / 60 ; begin ut . set_nls (); open l_expected for select gc_description as description , gc_event_date as event_date from dual ; open l_expected_bad_date for select gc_description as description , gc_event_date + l_second as event_date from dual ; l_actual : = get_events ( gc_event_date - 1 , gc_event_date + 1 ); ut . reset_nls (); ut . expect ( l_actual ). to_equal ( l_expected ); ut . expect ( l_actual ). not_to_equal ( l_expected_bad_date ); end ; end ; / begin ut . run (); end ; / drop table events ; drop function get_events ; drop package test_get_events ;","title":"Comparing cursor data containing DATE fields"},{"location":"userguide/expectations.html#comparing-user-defined-types-and-collections","text":"The anydata data type is used to compare user defined object and collections. Example: create type department as object ( name varchar2 ( 30 )); / create type departments as table of department ; / create or replace package demo_dept as -- %suite(demo) --%test(demo of object to object comparison) procedure test_department ; --%test(demo of collection comparison) procedure test_departments ; end ; / create or replace package body demo_dept as procedure test_department is v_expected department ; v_actual department ; begin v_expected : = department ( 'HR' ); v_actual : = department ( 'IT' ); ut . expect ( anydata . convertObject ( v_expected ) ). to_equal ( anydata . convertObject ( v_actual ) ); end ; procedure test_department is v_expected department ; v_actual department ; begin v_expected : = departments ( department ( 'HR' )); v_actual : = departments ( department ( 'IT' )); ut . expect ( anydata . convertCollection ( v_expected ) ). to_equal ( anydata . convertCollection ( v_actual ) ); end ; end ; / This test will fail as the v_acutal is not equal v_expected .","title":"Comparing user defined types and collections"},{"location":"userguide/expectations.html#match","text":"Validates that the actual value is matching the expected regular expression. Usage: begin ut . expect ( a_actual => '123-456-ABcd' ). to_match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ); ut . expect ( 'some value' ). to_match ( '^some.*' ); --or ut . expect ( a_actual => '123-456-ABcd' ). to_ ( match ( a_pattern => '\\d{3}-\\d{3}-[a-z]' , a_modifiers => 'i' ) ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ); end ; Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle regexp_like function","title":"match"},{"location":"userguide/expectations.html#supported-data-types","text":"Below matrix illustrates the data types supported by different matchers. be_between be_empty be_false be_greater_than be_greater_or_equal be_less_or_equal be_less_than be_like be_not_null be_null be_true equal match anydata X X X X blob X X X boolean X X X X X clob X X X X X date X X X X X X X X number X X X X X X X X refcursor X X X X timestamp X X X X X X X X timestamp with timezone X X X X X X X X timestamp with local timezone X X X X X X X X varchar2 X X X X X X interval year to month X X X X X X X X interval day to second X X X X X X X X","title":"Supported data types"},{"location":"userguide/expectations.html#negating-a-matcher","text":"Expectations provide a very convenient way to perform a check on negated matcher. Syntax of check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax of check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: begin ut . expect ( null ). to_ ( be_true () ); ut . expect ( null ). not_to ( be_true () ); end ; Since NULL is neither true not it is not true, both expectations will report failure.","title":"Negating a matcher"},{"location":"userguide/getting-started.html","text":"Getting started with TDD and utPLSQL \u00b6 utPLSQL is designed in a way that allows you follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD. Gather requirement \u00b6 We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position Create a test \u00b6 We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable. Create test package \u00b6 create or replace package test_betwnstr as -- %suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Define specification for test \u00b6 create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as package specification requires body. Define body of first test \u00b6 create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing, as the test suite package body is invalid. Looks like we need to define the function we want to test. Implement code to fulfill requirement \u00b6 Define tested function \u00b6 create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , l_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return expected results. Let us fix this and continue form here. Fix the tested function \u00b6 The function returned string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , l_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great! Refactor \u00b6 Once our tests are passing, we can safely refactor (restructure) the code as we have safety harness in place to assure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is similarly important. Further requirements \u00b6 It seems like our work is done. We have function that returns a substring from start position to end position. As we move, through process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of edge cases. Once defined we can start implementing tests for those behaviors and adjust tested function to meet requirements specified in tests. Add test for additional requirement \u00b6 New requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; -- %test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position. Implementing requirement \u00b6 Lets fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress. Refactoring \u00b6 When all tests are passing we can proceed with safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. Alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Remaining requirements \u00b6 You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Getting Started"},{"location":"userguide/getting-started.html#getting-started-with-tdd-and-utplsql","text":"utPLSQL is designed in a way that allows you follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD.","title":"Getting started with TDD and utPLSQL"},{"location":"userguide/getting-started.html#gather-requirement","text":"We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position","title":"Gather requirement"},{"location":"userguide/getting-started.html#create-a-test","text":"We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable.","title":"Create a test"},{"location":"userguide/getting-started.html#create-test-package","text":"create or replace package test_betwnstr as -- %suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Create test package"},{"location":"userguide/getting-started.html#define-specification-for-test","text":"create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as package specification requires body.","title":"Define specification for test"},{"location":"userguide/getting-started.html#define-body-of-first-test","text":"create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing, as the test suite package body is invalid. Looks like we need to define the function we want to test.","title":"Define body of first test"},{"location":"userguide/getting-started.html#implement-code-to-fulfill-requirement","text":"","title":"Implement code to fulfill requirement"},{"location":"userguide/getting-started.html#define-tested-function","text":"create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , l_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return expected results. Let us fix this and continue form here.","title":"Define tested function"},{"location":"userguide/getting-started.html#fix-the-tested-function","text":"The function returned string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , l_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great!","title":"Fix the tested function"},{"location":"userguide/getting-started.html#refactor","text":"Once our tests are passing, we can safely refactor (restructure) the code as we have safety harness in place to assure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is similarly important.","title":"Refactor"},{"location":"userguide/getting-started.html#further-requirements","text":"It seems like our work is done. We have function that returns a substring from start position to end position. As we move, through process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of edge cases. Once defined we can start implementing tests for those behaviors and adjust tested function to meet requirements specified in tests.","title":"Further requirements"},{"location":"userguide/getting-started.html#add-test-for-additional-requirement","text":"New requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as -- %suite(Between string function) -- %test(Returns substring from start position to end position) procedure basic_usage ; -- %test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position.","title":"Add test for additional requirement"},{"location":"userguide/getting-started.html#implementing-requirement","text":"Lets fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress.","title":"Implementing requirement"},{"location":"userguide/getting-started.html#refactoring","text":"When all tests are passing we can proceed with safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. Alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Refactoring"},{"location":"userguide/getting-started.html#remaining-requirements","text":"You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Remaining requirements"},{"location":"userguide/install.html","text":"Downloading latest version of utPLSQL \u00b6 It is quite easy to download latest version of utPLSQL from github on Unix machines. Here is a little snippet that can be handy for downloading latest version. #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) Headless installation \u00b6 To simply install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. This will create a new user UT3 with password XNtxj8eEgA6X6b6f , grant all needed privileges to that user and create PUBLIC synonyms needed to use the utPLSQL framework. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @@install_headless.sql SYSDBA is needed to grant access to DBMS_LOCK. Recommended Schema \u00b6 It is recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. The installation user/schema must have the following Oracle system permissions during the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE VIEW CREATE SYNONYM ALTER SESSION In addition it must be granted execute to the following system packages. DBMS_LOCK utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. The uninstall process will not drop profiler tables, as they can potentially be shared and reused for profiling PLSQL code. It is up to DBA to maintain the storage of the profiler tables. Installation Procedure \u00b6 Creating schema for utPLSQL \u00b6 To create the utPLSQL schema and grant all the needed privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users Installing utPLSQL \u00b6 To install the utPLSQL framework into your database run the /source/install.sql script and provide schema_name where utPLSQL is to be installed. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3 Allowing other users to access utPLSQL framework \u00b6 In order to allow other users to access utPLSQL, synonyms must be created and grants need to be added. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to individual user execute script source/create_synonyms_and_grants_for_user.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_user.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer Additional requirements \u00b6 In order to use Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges. Uninstalling utPLSQL \u00b6 To uninstall run /source/uninstall.sql and provide schema_name where utPLSQL is installed. The uninstall script will remove all the objects installed by the install script. Additionally, all the public and private synonyms pointing to the objects in utPLSQL schema will be removed. If you have you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. In order for the uninstall to be successful, you need to use the uninstall script, that was provided whit the exact version that was installed on your database. The uninstall script provided with version 3.0.1 will probably not work, if you want to remove version 3.0.0 from your database. Version upgrade \u00b6 Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install new version Working with utPLSQL v2 \u00b6 If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Installation"},{"location":"userguide/install.html#downloading-latest-version-of-utplsql","text":"It is quite easy to download latest version of utPLSQL from github on Unix machines. Here is a little snippet that can be handy for downloading latest version. #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\" | sed 's/\"//g' )","title":"Downloading latest version of utPLSQL"},{"location":"userguide/install.html#headless-installation","text":"To simply install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. This will create a new user UT3 with password XNtxj8eEgA6X6b6f , grant all needed privileges to that user and create PUBLIC synonyms needed to use the utPLSQL framework. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @@install_headless.sql SYSDBA is needed to grant access to DBMS_LOCK.","title":"Headless installation"},{"location":"userguide/install.html#recommended-schema","text":"It is recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. The installation user/schema must have the following Oracle system permissions during the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE VIEW CREATE SYNONYM ALTER SESSION In addition it must be granted execute to the following system packages. DBMS_LOCK utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. The uninstall process will not drop profiler tables, as they can potentially be shared and reused for profiling PLSQL code. It is up to DBA to maintain the storage of the profiler tables.","title":"Recommended Schema"},{"location":"userguide/install.html#installation-procedure","text":"","title":"Installation Procedure"},{"location":"userguide/install.html#creating-schema-for-utplsql","text":"To create the utPLSQL schema and grant all the needed privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users","title":"Creating schema for utPLSQL"},{"location":"userguide/install.html#installing-utplsql","text":"To install the utPLSQL framework into your database run the /source/install.sql script and provide schema_name where utPLSQL is to be installed. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3","title":"Installing utPLSQL"},{"location":"userguide/install.html#allowing-other-users-to-access-utplsql-framework","text":"In order to allow other users to access utPLSQL, synonyms must be created and grants need to be added. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to individual user execute script source/create_synonyms_and_grants_for_user.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_user.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer","title":"Allowing other users to access utPLSQL framework"},{"location":"userguide/install.html#additional-requirements","text":"In order to use Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges.","title":"Additional requirements"},{"location":"userguide/install.html#uninstalling-utplsql","text":"To uninstall run /source/uninstall.sql and provide schema_name where utPLSQL is installed. The uninstall script will remove all the objects installed by the install script. Additionally, all the public and private synonyms pointing to the objects in utPLSQL schema will be removed. If you have you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. In order for the uninstall to be successful, you need to use the uninstall script, that was provided whit the exact version that was installed on your database. The uninstall script provided with version 3.0.1 will probably not work, if you want to remove version 3.0.0 from your database.","title":"Uninstalling utPLSQL"},{"location":"userguide/install.html#version-upgrade","text":"Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install new version","title":"Version upgrade"},{"location":"userguide/install.html#working-with-utplsql-v2","text":"If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Working with utPLSQL v2"},{"location":"userguide/reporters.html","text":"utPLSQL provides the following reporting formats. Documentation reporter \u00b6 The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); You may also invoke unit tests directly from command line by calling. ut_run user/pass@dbsid Invoking tests from command line tool ut_run allows you to track progress of test execution. In that case, the documentation reporter will provide information about each test that was executed as soon as it's execution finishes. For more details on using the ut_run script look into utPLSQL-sql-cli project. The ut_documentation_reporter doesn't accept any arguments. Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution Color output from documentation reporter \u00b6 When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter. XUnit reporter \u00b6 Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in XUnit/JUnit format. The ut_xunit_reporter is producing outcomes as XUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Invocation of tests with XUnit reporter. exec ut.run(ut_xunit_reporter()); The ut_xunit_reporter doesn't accept any arguments. Example of xunit report integrated with Jenkins CI Example of failure report details Teamcity reporter \u00b6 Teamcity is a CI server by Jetbrains. It supports XUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details Sonar test reporter \u00b6 If you are using SonarQube to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section. Coverage reporters \u00b6 utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them.","title":"Using reporters"},{"location":"userguide/reporters.html#documentation-reporter","text":"The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); You may also invoke unit tests directly from command line by calling. ut_run user/pass@dbsid Invoking tests from command line tool ut_run allows you to track progress of test execution. In that case, the documentation reporter will provide information about each test that was executed as soon as it's execution finishes. For more details on using the ut_run script look into utPLSQL-sql-cli project. The ut_documentation_reporter doesn't accept any arguments. Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution","title":"Documentation reporter"},{"location":"userguide/reporters.html#color-output-from-documentation-reporter","text":"When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter.","title":"Color output from documentation reporter"},{"location":"userguide/reporters.html#xunit-reporter","text":"Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in XUnit/JUnit format. The ut_xunit_reporter is producing outcomes as XUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Invocation of tests with XUnit reporter. exec ut.run(ut_xunit_reporter()); The ut_xunit_reporter doesn't accept any arguments. Example of xunit report integrated with Jenkins CI Example of failure report details","title":"XUnit reporter"},{"location":"userguide/reporters.html#teamcity-reporter","text":"Teamcity is a CI server by Jetbrains. It supports XUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details","title":"Teamcity reporter"},{"location":"userguide/reporters.html#sonar-test-reporter","text":"If you are using SonarQube to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section.","title":"Sonar test reporter"},{"location":"userguide/reporters.html#coverage-reporters","text":"utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them.","title":"Coverage reporters"},{"location":"userguide/running-unit-tests.html","text":"Running tests \u00b6 utPLSQL framework provides two main entry points to run unit tests from within database: ut.run procedures and functions ut_runner.run procedures Those two entry points differ in purpose and behavior. Most of the times, you will want to use ut.run as the ut_runner is designed for API integration and does not output the results to the screen directly. utPLSQL-sql-cli \u00b6 If you are thinking about running you tests from a command line or from a CI server like Jenkins/Temcity the best way is to use the utPLSQL-sql-cli You may download the latest release of the command line client automatically by using the below command (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-sql-cli/releases/latest | awk '/zipball_url/ { print $2 }' | sed -r 's/\"|,//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-sql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-sql-cli.zip ut.run \u00b6 Package ut contains overloaded procedures and functions run . The run API is designed to be called directly by developer, when using IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. One-line call is enough to execute a set of tests form one or multiple schemes. The procedures execute specified tests and produces outputs to DBMS_OUTPUT using specified reporter The functions can only be used in SELECT statements. They execute specified tests and produce outputs as a pipelined data stream to be consumed by select satement. ut.run procedures \u00b6 Below examples illustrate different ways and options to invoke ut.run procedures. alter session set current_schema = hr ; begin ut . run (); end ; Executes all tests in current schema ( HR ). begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . begin ut . run ( ut_varcahr2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. Note: ut_documentation_reporter is default reporter for all API's defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. begin ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the XUnit reporter. For details on build-in reporters look at reporters documentation . ut.run functions \u00b6 The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide outputs as pipelined stream and therefore need to be executed as select statements. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ())); ut_runner.run procedures \u00b6 The ut_runner provides API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference as compared to ut.run API is that the ut_runner.run does not print outputs to the screen. ut_runner.run accepts multiple reporters. Each reporter produces outputs into a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. The concept is pretty simple. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_id's. as a separate thread, start the ut_runner.run and pass reporters with previously defined output_id's for each reporter start a separate thread and read outputs from ut_output_buffer.get_lines table function by providing the output_id defined in the main thread.","title":"Running unit tests"},{"location":"userguide/running-unit-tests.html#running-tests","text":"utPLSQL framework provides two main entry points to run unit tests from within database: ut.run procedures and functions ut_runner.run procedures Those two entry points differ in purpose and behavior. Most of the times, you will want to use ut.run as the ut_runner is designed for API integration and does not output the results to the screen directly.","title":"Running tests"},{"location":"userguide/running-unit-tests.html#utplsql-sql-cli","text":"If you are thinking about running you tests from a command line or from a CI server like Jenkins/Temcity the best way is to use the utPLSQL-sql-cli You may download the latest release of the command line client automatically by using the below command (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-sql-cli/releases/latest | awk '/zipball_url/ { print $2 }' | sed -r 's/\"|,//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-sql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-sql-cli.zip","title":"utPLSQL-sql-cli"},{"location":"userguide/running-unit-tests.html#utrun","text":"Package ut contains overloaded procedures and functions run . The run API is designed to be called directly by developer, when using IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. One-line call is enough to execute a set of tests form one or multiple schemes. The procedures execute specified tests and produces outputs to DBMS_OUTPUT using specified reporter The functions can only be used in SELECT statements. They execute specified tests and produce outputs as a pipelined data stream to be consumed by select satement.","title":"ut.run"},{"location":"userguide/running-unit-tests.html#utrun-procedures","text":"Below examples illustrate different ways and options to invoke ut.run procedures. alter session set current_schema = hr ; begin ut . run (); end ; Executes all tests in current schema ( HR ). begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . begin ut . run ( ut_varcahr2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. Note: ut_documentation_reporter is default reporter for all API's defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. begin ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the XUnit reporter. For details on build-in reporters look at reporters documentation .","title":"ut.run procedures"},{"location":"userguide/running-unit-tests.html#utrun-functions","text":"The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide outputs as pipelined stream and therefore need to be executed as select statements. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_xunit_reporter ()));","title":"ut.run functions"},{"location":"userguide/running-unit-tests.html#ut_runnerrun-procedures","text":"The ut_runner provides API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference as compared to ut.run API is that the ut_runner.run does not print outputs to the screen. ut_runner.run accepts multiple reporters. Each reporter produces outputs into a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. The concept is pretty simple. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_id's. as a separate thread, start the ut_runner.run and pass reporters with previously defined output_id's for each reporter start a separate thread and read outputs from ut_output_buffer.get_lines table function by providing the output_id defined in the main thread.","title":"ut_runner.run procedures"},{"location":"userguide/upgrade.html","text":"How to upgrade from prior versions \u00b6 utPLSQL v3 is a total rewrite of previous version. There is no automated way to migrate tests from version 2.x to version 3. There are plans to build a mapping/bridging solution that would allow running v2 tests using v3 framework.","title":"Upgrade utPLSQL"},{"location":"userguide/upgrade.html#how-to-upgrade-from-prior-versions","text":"utPLSQL v3 is a total rewrite of previous version. There is no automated way to migrate tests from version 2.x to version 3. There are plans to build a mapping/bridging solution that would allow running v2 tests using v3 framework.","title":"How to upgrade from prior versions"}]}