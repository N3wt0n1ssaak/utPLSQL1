{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"What is utPLSQL \u00b6 utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec Demo project \u00b6 Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarCloud . Three steps \u00b6 With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests. Command line \u00b6 You can use the utPLSQL command line client utPLSQL-cli to run tests without the need for Oracle Client or any IDE like SQLDeveloper/TOAD etc. Amongst many benefits they provide ability to: * see the progress of test execution for long-running tests - real-time reporting * use many reporting formats simultaneously and save reports to files (publish) * map your project source files and test files into database objects Download the latest client and you are good to go. See project readme for details. Coverage \u00b6 If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Index"},{"location":"index.html#what-is-utplsql","text":"utPLSQL is a Unit Testing framework for Oracle PL/SQL. The framework follows industry standards and best patterns of modern Unit Testing frameworks like JUnit and RSpec","title":"What is utPLSQL"},{"location":"index.html#demo-project","text":"Have a look at our demo project . It uses Travis CI to build on every commit, runs all tests, publishes test results and code coverage to SonarCloud .","title":"Demo project"},{"location":"index.html#three-steps","text":"With just three simple steps you can define and run your unit tests for PLSQL code. Install the utPLSQL framework Create Unit Tests to for the code Run the tests Here is how you can simply create tested code, unit tests and execute the tests using SQL Developer Check out the sections on annotations and expectations to see how to define your tests.","title":"Three steps"},{"location":"index.html#command-line","text":"You can use the utPLSQL command line client utPLSQL-cli to run tests without the need for Oracle Client or any IDE like SQLDeveloper/TOAD etc. Amongst many benefits they provide ability to: * see the progress of test execution for long-running tests - real-time reporting * use many reporting formats simultaneously and save reports to files (publish) * map your project source files and test files into database objects Download the latest client and you are good to go. See project readme for details.","title":"Command line"},{"location":"index.html#coverage","text":"If you want to have code coverage gathered on your code , it's best to use ut_run to execute your tests with multiple reporters and have both test execution report as well as coverage report saved to a file. Check out the coverage documentation for options of coverage reporting","title":"Coverage"},{"location":"compare_version2_to_3.html","text":"For version 3 has been a complete rewrite of the framework, the way it can be used is different to the previous versions, but also more in line with other modern unit-testing frameworks like JUnit and RSpec. There is a migration tool that can help you to migrate your existing utPLSQL v2 tests to the v3 capabilities. Feature comparison \u00b6 Feature Version 2 Version 3 Easy to install Yes Yes Documentation Yes Yes License GPL v2 Apache 2.0 Tests Creation Declarative test configuration No Yes - Annotations 1 Tests as Packages Yes Yes Multiple Tests in a single Package Yes Yes Optional Setup/Teardown No Yes Different Setup/Teardown For Each Test in a Single Package No Yes - Annotations 1 Suite Definition Storage Tables Package - Annotations 1 Multiple Suites Yes Yes Suites can contain Suites No Yes Automatic Test detection No Yes - Annotations 1 Unconstrained naming of Test packages No - prefixes Yes - name not relevant Require Prefix on Test procedures No - prefixes Yes - name not relevant Auto Compilation of Tests Yes No (Let us know if you use this) Assertion Library 30 assertions 2 26 matchers (13 + 13 negated) Extendable assertions No Yes - custom matchers PLSQL Record Assertions generated code through utRecEq Package possible on Oracle 12c+ using cursor matchers Test Skeleton Generation Yes No (Let us know if you use this) Test Execution 3 Single Test Package Execution Yes Yes Single Test Procedure Execution No Yes Test Suite Execution Yes Yes Subset of Suite Execution No Yes Multiple Suite Execution No Yes Organizing Suites into hierarchies No Yes Code Coverage Reporting No Yes Html Coverage Report No Yes Sonar XML Coverage Report No Yes Coveralls Json Coverage Report No Yes Framework Transaction Control No Yes - Annotations 1 Test Output Real-time test execution progress reporting No Yes Multiple Output Reporters can be used during test execution No Yes DBMS_OUTPUT Yes Yes (clean formatting) File Yes (to db server only) Yes (on client side) Stored in Table Yes No (can be added as custom reporter) XUnit format support No Yes HTML Format Yes No Custom Output reporter Yes-needs configuration Yes - no config needed 1 Annotations are specially formatted comments in your package specification. This enables declarative test configuration that is coupled with the source code. See Documentation for more details. 2 utAssert2 package - Contains 59 Assertions - 2 Not implemented = 57, 28 are duplicated only change on outcome_in parameter 57-28 = 29, utPipe package - Contains 1 Assertion 29 + 1 = 30 3 Test execution comparison is in a single call so the results are combined. We know it was always possible to group in any way with multiple calls. But that may not be desired under a CI system where you want a single JUnit XML Output.","title":"Compare version2 to 3"},{"location":"compare_version2_to_3.html#feature-comparison","text":"Feature Version 2 Version 3 Easy to install Yes Yes Documentation Yes Yes License GPL v2 Apache 2.0 Tests Creation Declarative test configuration No Yes - Annotations 1 Tests as Packages Yes Yes Multiple Tests in a single Package Yes Yes Optional Setup/Teardown No Yes Different Setup/Teardown For Each Test in a Single Package No Yes - Annotations 1 Suite Definition Storage Tables Package - Annotations 1 Multiple Suites Yes Yes Suites can contain Suites No Yes Automatic Test detection No Yes - Annotations 1 Unconstrained naming of Test packages No - prefixes Yes - name not relevant Require Prefix on Test procedures No - prefixes Yes - name not relevant Auto Compilation of Tests Yes No (Let us know if you use this) Assertion Library 30 assertions 2 26 matchers (13 + 13 negated) Extendable assertions No Yes - custom matchers PLSQL Record Assertions generated code through utRecEq Package possible on Oracle 12c+ using cursor matchers Test Skeleton Generation Yes No (Let us know if you use this) Test Execution 3 Single Test Package Execution Yes Yes Single Test Procedure Execution No Yes Test Suite Execution Yes Yes Subset of Suite Execution No Yes Multiple Suite Execution No Yes Organizing Suites into hierarchies No Yes Code Coverage Reporting No Yes Html Coverage Report No Yes Sonar XML Coverage Report No Yes Coveralls Json Coverage Report No Yes Framework Transaction Control No Yes - Annotations 1 Test Output Real-time test execution progress reporting No Yes Multiple Output Reporters can be used during test execution No Yes DBMS_OUTPUT Yes Yes (clean formatting) File Yes (to db server only) Yes (on client side) Stored in Table Yes No (can be added as custom reporter) XUnit format support No Yes HTML Format Yes No Custom Output reporter Yes-needs configuration Yes - no config needed 1 Annotations are specially formatted comments in your package specification. This enables declarative test configuration that is coupled with the source code. See Documentation for more details. 2 utAssert2 package - Contains 59 Assertions - 2 Not implemented = 57, 28 are duplicated only change on outcome_in parameter 57-28 = 29, utPipe package - Contains 1 Assertion 29 + 1 = 30 3 Test execution comparison is in a single call so the results are combined. We know it was always possible to group in any way with multiple calls. But that may not be desired under a CI system where you want a single JUnit XML Output.","title":"Feature comparison"},{"location":"about/authors.html","text":"utPLSQL v3 Major Contributors \u00b6 Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Lukasz Wasylow lwasylow Pavel Kaplya Pazus Robert Love rlove Samuel Nitsche pesse Vinicius Avellar viniciusam Many thanks to all the contributors Special thanks to prior major contributors \u00b6 Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Authors"},{"location":"about/authors.html#utplsql-v3-major-contributors","text":"Listed Alphabetically Name GitHub account David Pyke Shoelace Jacek Gebal jgebal Lukasz Wasylow lwasylow Pavel Kaplya Pazus Robert Love rlove Samuel Nitsche pesse Vinicius Avellar viniciusam Many thanks to all the contributors","title":"utPLSQL v3 Major Contributors"},{"location":"about/authors.html#special-thanks-to-prior-major-contributors","text":"Steven Feuerstein - Original Author Chris Rimmer Patrick Barel Paul Walker","title":"Special thanks to prior major contributors"},{"location":"about/license.html","text":"Version Information \u00b6 utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"License"},{"location":"about/license.html#version-information","text":"utPLSQL version 3 is licensed under Apache 2.0 External code used in the development of this project, but is not required for use. Tool License Purpose Travis-Oracle ISC Install Oracle for Travis Builds mkDocs BSD Produce HTML version of documentation Note: Version 1 & 2 of utPLSQL were licensed under GPL, version 3 was a complete rewrite from scratch which a allowed us to change the license to be more permissive.","title":"Version Information"},{"location":"about/project-details.html","text":"utPLSQL Project Details \u00b6 utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our contributing guide","title":"Project Details"},{"location":"about/project-details.html#utplsql-project-details","text":"utPLSQL is open source project hosted on GitHub . Contributions, help and constructive feedback is always appreciated. If you are interested in helping please read our contributing guide","title":"utPLSQL Project Details"},{"location":"about/support.html","text":"How to get support \u00b6 Feel free to post questions, bugs or issues in the issues area of GitHub Join developers team on utPLSQL Slack","title":"Support"},{"location":"about/support.html#how-to-get-support","text":"Feel free to post questions, bugs or issues in the issues area of GitHub Join developers team on utPLSQL Slack","title":"How to get support"},{"location":"userguide/advanced_data_comparison.html","text":"Advanced data comparison \u00b6 utPLSQL expectations incorporates advanced data comparison options when comparing compound data-types: refcursor object type nested table and varray json data-types Advanced data-comparison options are available for the equal and contain matcher. Syntax ut.expect( a_actual {data-type} ).to_( equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to( equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]) ); ut.expect( a_actual {data-type} ).to_equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to_equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]] ); ut.expect( a_actual {data-type} ).to_( contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to( contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]) ); ut.expect( a_actual {data-type} ).to_contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to_contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); extended_option can be one of: include(a_items varchar2) - item or comma separated list of items to include exclude(a_items varchar2) - item or comma separated list of items to exclude include(a_items ut_varchar2_list) - table of items to include exclude(a_items ut_varchar2_list) - table of items to exclude unordered - ignore order of data sets when comparing data. Default when comparing data-sets with to_contain join_by(a_columns varchar2) - column or comma separated list of columns to join two cursors by join_by(a_columns ut_varchar2_list) - table of columns to join two cursors by unordered_columns / uc - ignore the ordering of columns / attributes in compared data-sets. Column/attribute names will be used to identify data to be compared and the position will be ignored. Each item in the comma separated list can be: - a column name of cursor to be compared - an attribute name of object type to be compared - an attribute name of object type within a table of objects to be compared - Include and exclude option will not support implicit colum names that starts with single quota, or in fact any other special characters e.g. <, >, & Each element in ut_varchar2_list nested table can be an item or a comma separated list of items. When specifying column/attribute names, keep in mind that the names are case sensitive . Excluding elements from data comparison \u00b6 Consider the following examples declare l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_equal ( l_expected ). exclude ( 'IGNORE_ME,ADate' ); end ; / declare l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d where rownum = 1 ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_contain ( l_expected ). exclude ( 'IGNORE_ME,ADate' ); end ; / Produces: SUCCESS Actual: refcursor [ count = 23 ] was expected to equal: refcursor [ count = 23 ] SUCCESS Actual: refcursor [ count = 23 ] was expected to contain: refcursor [ count = 1 ] Columns 'ignore_me' and \"ADate\" will get excluded from data comparison. The actual data is equal/contains expected, when those columns are excluded. Note This option is useful in scenarios, when you need to exclude incomparable/unpredictable column data like CREATE_DATE of a record that is maintained by default value on a table column. Selecting columns for data comparison \u00b6 Consider the following example declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); end ; / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 6 ; ut . expect ( l_actual ). to_contain ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); end ; / Produces: SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 5 ] was expected to contain: refcursor [ count = 3 ] Only columns RN , A_Column and SOME_COL will be included in data comparison. The actual data is equal/contains expected, when only those columns are included. Note This option can be useful in scenarios where you need to narrow-down the scope of test so that the test is only focused on very specific data. Combining include/exclude options \u00b6 You can chain the advanced options in an expectation and mix the varchar2 with ut_varchar2_list arguments. When doing so, the final list of items to include/exclude will be a concatenation of all items. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'Y' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ) . include ( 'RN' ) . include ( ut_varchar2_list ( 'A_Column' , 'SOME_COL' ) ) . exclude ( 'SOME_COL' ); end ; / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'Y' SOME_COL , a . * from all_objects a where rownum < 6 ; ut . expect ( l_actual ). to_contain ( l_expected ) . include ( 'RN' ) . include ( ut_varchar2_list ( 'A_Column' , 'SOME_COL' ) ) . exclude ( 'SOME_COL' ); end ; / Results: SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 5 ] was expected to contain: refcursor [ count = 3 ] Example of include / exclude for anydata.convertCollection create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). include ( 'NAME' ); end ; declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). exclude ( 'AGE' ); end ; declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). include ( 'AGE' ); end ; / Results: SUCCESS Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] SUCCESS Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] FAILURE Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <AGE>45</AGE> Row No. 1 - Expected: <AGE>47</AGE> at \"anonymous block\", line 5 Unordered \u00b6 Unordered option allows for quick comparison of two compound data types without need of ordering them in any way. Result of such comparison will be limited to only information about row existing or not existing in given set without actual information about exact differences. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id from all_users union all select 'TEST' username , - 600 user_id from dual order by 1 desc ; open l_actual for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). unordered ; end ; / Above test will result in two differences of one row extra and one row missing. FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 29 ] Diff: Rows: [ 2 differences ] Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> Missing: <USERNAME>TEST</USERNAME><USER_ID>-600</USER_ID> at \"anonymous block\", line 15 Note Consider using join_by( columns... ) over unordered() with the equal matcher. The join_by method is much faster at performing data comparison. The contain matcher is not considering the order of the compared data-sets. Using unordered makes no difference (it's default). Join By option \u00b6 The join_by syntax enables comparison of unordered compound data types by joining data using specified columns. You can join two compound data types by defining join column(s) that will be used to uniquely identify and compare data rows. With this option, framework is able to identify which rows are missing, which are extra and which are different without need to have both cursors uniformly ordered. When the specified join column(s) are not unique, join will partition set over rows with the same key and join on row number as well as given join key. The extra or missing rows will be presented to user as well as all non-matching rows. Join by option can be used in conjunction with include or exclude options. However if any of the join keys is part of exclude set, comparison will fail and report to user that sets could not be joined on specific key, as the key was excluded. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id from all_users union all select 'TEST' username , - 600 user_id from dual order by 1 desc ; open l_actual for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'USERNAME' ); end ; / Above test will result in a difference in row 'TEST' regardless of data order. FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 29 ] Diff: Rows: [ 1 differences ] PK <USERNAME>TEST</USERNAME> - Actual: <USER_ID>-610</USER_ID> PK <USERNAME>TEST</USERNAME> - Expected: <USER_ID>-600</USER_ID> PK <USERNAME>TEST</USERNAME> - Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> at \"anonymous block\", line 15 Note When using join_by , the join column(s) are displayed first (as PK) to help you identify the mismatched rows/columns. You can use join_by syntax in combination with contain matcher. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_actual for select username , user_id from all_users ; open l_expected for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual ; ut . expect ( l_actual ). to_contain ( l_expected ). join_by ( 'USERNAME' ); end ; / Above test will indicate that in actual data-set FAILURE Actual : refcursor [ count = 28 ] was expected to contain : refcursor [ count = 29 ] Diff : Rows : [ 1 differences ] PK < USERNAME > TEST </ USERNAME > - Missing : < USERNAME > TEST </ USERNAME >< USER_ID >- 610 </ USER_ID > at \"anonymous block\" , line 11 Joining using multiple columns \u00b6 You can specify multiple columns in join_by declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id , created from all_users order by 1 desc ; open l_actual for select username , user_id , created from all_users union all select 'TEST' username , - 610 user_id , sysdate from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'USERNAME, USER_ID' ); end ; / Produces: FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 28 ] Diff: Rows: [ 1 differences ] PK <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> - Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID><CREATED>2019-07-11</CREATED> at \"anonymous block\", line 13 Joining using attributes of object in column list \u00b6 join_by allows for joining data by attributes of object from column list of the compared compound data types. To reference attribute as PK, use slash symbol / to separate nested elements. In the below example, cursors are joined using the NAME attribute of object in column SOMEONE create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select person ( 'Jack' , 42 ) someone from dual union all select person ( 'Pat' , 44 ) someone from dual union all select person ( 'Matt' , 45 ) someone from dual ; open l_actual for select person ( 'Matt' , 55 ) someone from dual union all select person ( 'Pat' , 44 ) someone from dual ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'SOMEONE/NAME' ); end ; / Produces: FAILURE Actual: refcursor [ count = 2 ] was expected to equal: refcursor [ count = 3 ] Diff: Rows: [ 2 differences ] PK <NAME>Matt</NAME> - Actual: <SOMEONE><NAME>Matt</NAME><AGE>55</AGE></SOMEONE> PK <NAME>Matt</NAME> - Actual: <AGE>55</AGE> PK <NAME>Matt</NAME> - Expected: <SOMEONE><NAME>Matt</NAME><AGE>45</AGE></SOMEONE> PK <NAME>Matt</NAME> - Expected: <AGE>45</AGE> PK <NAME>Jack</NAME> - Missing: <SOMEONE><NAME>Jack</NAME><AGE>42</AGE></SOMEONE> at \"anonymous block\", line 12 Note join_by does not support joining on individual elements of nested table. You can still use data of the nested table as a PK value. When collection is referenced in join_by , test will fail with appropriate message, as it cannot perform a join. create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / create or replace package body test_join_by is procedure test_join_by_collection_elem is l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select people ( person ( 'Matt' , 45 )) persons from dual ; open l_actual for select people ( person ( 'Matt' , 45 )) persons from dual ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'PERSONS/PERSON/NAME' ); end ; end ; / FAILURE Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] Diff: Unable to join sets: Join key PERSONS/PERSON/NAME does not exists in expected Join key PERSONS/PERSON/NAME does not exists in actual Please make sure that your join clause is not refferring to collection element at \"anonymous block\", line 7 Note join_by option is slower to process as it needs to perform a cursor join. It is still faster than the unordered . Defining item lists in option \u00b6 You may provide items for include / exclude / join_by as a single varchar2 value containing comma-separated list of attributes. You may provide items for include / exclude / join_by as a a ut_varchar2_list of attributes. Note - object type attributes are nested under <OBJECTY_TYPE> element - nested table and varray items type attributes are nested under <ARRAY><OBJECTY_TYPE> elements Example of a valid parameter to include columns: RN , A_Column , SOME_COL in data comparison. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( ut_varchar2_list ( 'RN' , 'A_Column' , 'SOME_COL' ) ); end ; / SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] Unordered columns / uc option \u00b6 If you need to perform data comparison of compound data types without strictly depending on column order in the returned result-set, use the unordered_columns option. Shortcut name uc is also available for that option. Expectations that compare compound data type data with unordered_columns option, will not fail when columns are ordered differently. This option can be useful whn we have no control over the ordering of the column or the column order is not of importance from testing perspective. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange open l_actual for select owner , object_name , object_type from all_objects where owner = user order by 1 , 2 , 3 asc ; open l_expected for select object_type , owner , object_name from all_objects where owner = user and rownum < 20 ; --Assert ut . expect ( l_actual ). to_contain ( l_expected ). unordered_columns (); end ; / Produces: SUCCESS Actual: refcursor [ count = 348 ] was expected to contain: refcursor [ count = 19 ]","title":"Advanced data comparison"},{"location":"userguide/advanced_data_comparison.html#advanced-data-comparison","text":"utPLSQL expectations incorporates advanced data comparison options when comparing compound data-types: refcursor object type nested table and varray json data-types Advanced data-comparison options are available for the equal and contain matcher. Syntax ut.expect( a_actual {data-type} ).to_( equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to( equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]) ); ut.expect( a_actual {data-type} ).to_equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to_equal( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]] ); ut.expect( a_actual {data-type} ).to_( contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to( contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]) ); ut.expect( a_actual {data-type} ).to_contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); ut.expect( a_actual {data-type} ).not_to_contain( a_expected {data-type})[.extendend_option()[.extendend_option()[...]]]); extended_option can be one of: include(a_items varchar2) - item or comma separated list of items to include exclude(a_items varchar2) - item or comma separated list of items to exclude include(a_items ut_varchar2_list) - table of items to include exclude(a_items ut_varchar2_list) - table of items to exclude unordered - ignore order of data sets when comparing data. Default when comparing data-sets with to_contain join_by(a_columns varchar2) - column or comma separated list of columns to join two cursors by join_by(a_columns ut_varchar2_list) - table of columns to join two cursors by unordered_columns / uc - ignore the ordering of columns / attributes in compared data-sets. Column/attribute names will be used to identify data to be compared and the position will be ignored. Each item in the comma separated list can be: - a column name of cursor to be compared - an attribute name of object type to be compared - an attribute name of object type within a table of objects to be compared - Include and exclude option will not support implicit colum names that starts with single quota, or in fact any other special characters e.g. <, >, & Each element in ut_varchar2_list nested table can be an item or a comma separated list of items. When specifying column/attribute names, keep in mind that the names are case sensitive .","title":"Advanced data comparison"},{"location":"userguide/advanced_data_comparison.html#excluding-elements-from-data-comparison","text":"Consider the following examples declare l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_equal ( l_expected ). exclude ( 'IGNORE_ME,ADate' ); end ; / declare l_expected sys_refcursor ; l_actual sys_refcursor ; begin open l_expected for select 'text' ignore_me , d . * from user_tables d where rownum = 1 ; open l_actual for select sysdate \"ADate\" , d . * from user_tables d ; ut . expect ( l_actual ). to_contain ( l_expected ). exclude ( 'IGNORE_ME,ADate' ); end ; / Produces: SUCCESS Actual: refcursor [ count = 23 ] was expected to equal: refcursor [ count = 23 ] SUCCESS Actual: refcursor [ count = 23 ] was expected to contain: refcursor [ count = 1 ] Columns 'ignore_me' and \"ADate\" will get excluded from data comparison. The actual data is equal/contains expected, when those columns are excluded. Note This option is useful in scenarios, when you need to exclude incomparable/unpredictable column data like CREATE_DATE of a record that is maintained by default value on a table column.","title":"Excluding elements from data comparison"},{"location":"userguide/advanced_data_comparison.html#selecting-columns-for-data-comparison","text":"Consider the following example declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); end ; / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 6 ; ut . expect ( l_actual ). to_contain ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); end ; / Produces: SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 5 ] was expected to contain: refcursor [ count = 3 ] Only columns RN , A_Column and SOME_COL will be included in data comparison. The actual data is equal/contains expected, when only those columns are included. Note This option can be useful in scenarios where you need to narrow-down the scope of test so that the test is only focused on very specific data.","title":"Selecting columns for data comparison"},{"location":"userguide/advanced_data_comparison.html#combining-includeexclude-options","text":"You can chain the advanced options in an expectation and mix the varchar2 with ut_varchar2_list arguments. When doing so, the final list of items to include/exclude will be a concatenation of all items. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'Y' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ) . include ( 'RN' ) . include ( ut_varchar2_list ( 'A_Column' , 'SOME_COL' ) ) . exclude ( 'SOME_COL' ); end ; / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'Y' SOME_COL , a . * from all_objects a where rownum < 6 ; ut . expect ( l_actual ). to_contain ( l_expected ) . include ( 'RN' ) . include ( ut_varchar2_list ( 'A_Column' , 'SOME_COL' ) ) . exclude ( 'SOME_COL' ); end ; / Results: SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 5 ] was expected to contain: refcursor [ count = 3 ] Example of include / exclude for anydata.convertCollection create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). include ( 'NAME' ); end ; declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). exclude ( 'AGE' ); end ; declare l_actual people : = people ( person ( 'Matt' , 45 )); l_expected people : = people ( person ( 'Matt' , 47 )); begin ut3 . ut . expect ( anydata . convertCollection ( l_actual )). to_equal ( anydata . convertCollection ( l_expected )). include ( 'AGE' ); end ; / Results: SUCCESS Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] SUCCESS Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] FAILURE Actual: ut3.people [ count = 1 ] was expected to equal: ut3.people [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <AGE>45</AGE> Row No. 1 - Expected: <AGE>47</AGE> at \"anonymous block\", line 5","title":"Combining include/exclude options"},{"location":"userguide/advanced_data_comparison.html#unordered","text":"Unordered option allows for quick comparison of two compound data types without need of ordering them in any way. Result of such comparison will be limited to only information about row existing or not existing in given set without actual information about exact differences. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id from all_users union all select 'TEST' username , - 600 user_id from dual order by 1 desc ; open l_actual for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). unordered ; end ; / Above test will result in two differences of one row extra and one row missing. FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 29 ] Diff: Rows: [ 2 differences ] Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> Missing: <USERNAME>TEST</USERNAME><USER_ID>-600</USER_ID> at \"anonymous block\", line 15 Note Consider using join_by( columns... ) over unordered() with the equal matcher. The join_by method is much faster at performing data comparison. The contain matcher is not considering the order of the compared data-sets. Using unordered makes no difference (it's default).","title":"Unordered"},{"location":"userguide/advanced_data_comparison.html#join-by-option","text":"The join_by syntax enables comparison of unordered compound data types by joining data using specified columns. You can join two compound data types by defining join column(s) that will be used to uniquely identify and compare data rows. With this option, framework is able to identify which rows are missing, which are extra and which are different without need to have both cursors uniformly ordered. When the specified join column(s) are not unique, join will partition set over rows with the same key and join on row number as well as given join key. The extra or missing rows will be presented to user as well as all non-matching rows. Join by option can be used in conjunction with include or exclude options. However if any of the join keys is part of exclude set, comparison will fail and report to user that sets could not be joined on specific key, as the key was excluded. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id from all_users union all select 'TEST' username , - 600 user_id from dual order by 1 desc ; open l_actual for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'USERNAME' ); end ; / Above test will result in a difference in row 'TEST' regardless of data order. FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 29 ] Diff: Rows: [ 1 differences ] PK <USERNAME>TEST</USERNAME> - Actual: <USER_ID>-610</USER_ID> PK <USERNAME>TEST</USERNAME> - Expected: <USER_ID>-600</USER_ID> PK <USERNAME>TEST</USERNAME> - Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> at \"anonymous block\", line 15 Note When using join_by , the join column(s) are displayed first (as PK) to help you identify the mismatched rows/columns. You can use join_by syntax in combination with contain matcher. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_actual for select username , user_id from all_users ; open l_expected for select username , user_id from all_users union all select 'TEST' username , - 610 user_id from dual ; ut . expect ( l_actual ). to_contain ( l_expected ). join_by ( 'USERNAME' ); end ; / Above test will indicate that in actual data-set FAILURE Actual : refcursor [ count = 28 ] was expected to contain : refcursor [ count = 29 ] Diff : Rows : [ 1 differences ] PK < USERNAME > TEST </ USERNAME > - Missing : < USERNAME > TEST </ USERNAME >< USER_ID >- 610 </ USER_ID > at \"anonymous block\" , line 11","title":"Join By option"},{"location":"userguide/advanced_data_comparison.html#joining-using-multiple-columns","text":"You can specify multiple columns in join_by declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select username , user_id , created from all_users order by 1 desc ; open l_actual for select username , user_id , created from all_users union all select 'TEST' username , - 610 user_id , sysdate from dual order by 1 asc ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'USERNAME, USER_ID' ); end ; / Produces: FAILURE Actual: refcursor [ count = 29 ] was expected to equal: refcursor [ count = 28 ] Diff: Rows: [ 1 differences ] PK <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID> - Extra: <USERNAME>TEST</USERNAME><USER_ID>-610</USER_ID><CREATED>2019-07-11</CREATED> at \"anonymous block\", line 13","title":"Joining using multiple columns"},{"location":"userguide/advanced_data_comparison.html#joining-using-attributes-of-object-in-column-list","text":"join_by allows for joining data by attributes of object from column list of the compared compound data types. To reference attribute as PK, use slash symbol / to separate nested elements. In the below example, cursors are joined using the NAME attribute of object in column SOMEONE create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select person ( 'Jack' , 42 ) someone from dual union all select person ( 'Pat' , 44 ) someone from dual union all select person ( 'Matt' , 45 ) someone from dual ; open l_actual for select person ( 'Matt' , 55 ) someone from dual union all select person ( 'Pat' , 44 ) someone from dual ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'SOMEONE/NAME' ); end ; / Produces: FAILURE Actual: refcursor [ count = 2 ] was expected to equal: refcursor [ count = 3 ] Diff: Rows: [ 2 differences ] PK <NAME>Matt</NAME> - Actual: <SOMEONE><NAME>Matt</NAME><AGE>55</AGE></SOMEONE> PK <NAME>Matt</NAME> - Actual: <AGE>55</AGE> PK <NAME>Matt</NAME> - Expected: <SOMEONE><NAME>Matt</NAME><AGE>45</AGE></SOMEONE> PK <NAME>Matt</NAME> - Expected: <AGE>45</AGE> PK <NAME>Jack</NAME> - Missing: <SOMEONE><NAME>Jack</NAME><AGE>42</AGE></SOMEONE> at \"anonymous block\", line 12 Note join_by does not support joining on individual elements of nested table. You can still use data of the nested table as a PK value. When collection is referenced in join_by , test will fail with appropriate message, as it cannot perform a join. create or replace type person as object ( name varchar2 ( 100 ), age integer ) / create or replace type people as table of person / create or replace package body test_join_by is procedure test_join_by_collection_elem is l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select people ( person ( 'Matt' , 45 )) persons from dual ; open l_actual for select people ( person ( 'Matt' , 45 )) persons from dual ; ut . expect ( l_actual ). to_equal ( l_expected ). join_by ( 'PERSONS/PERSON/NAME' ); end ; end ; / FAILURE Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] Diff: Unable to join sets: Join key PERSONS/PERSON/NAME does not exists in expected Join key PERSONS/PERSON/NAME does not exists in actual Please make sure that your join clause is not refferring to collection element at \"anonymous block\", line 7 Note join_by option is slower to process as it needs to perform a cursor join. It is still faster than the unordered .","title":"Joining using attributes of object in column list"},{"location":"userguide/advanced_data_comparison.html#defining-item-lists-in-option","text":"You may provide items for include / exclude / join_by as a single varchar2 value containing comma-separated list of attributes. You may provide items for include / exclude / join_by as a a ut_varchar2_list of attributes. Note - object type attributes are nested under <OBJECTY_TYPE> element - nested table and varray items type attributes are nested under <ARRAY><OBJECTY_TYPE> elements Example of a valid parameter to include columns: RN , A_Column , SOME_COL in data comparison. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( 'RN,A_Column,SOME_COL' ); open l_expected for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL from dual a connect by level < 4 ; open l_actual for select rownum as rn , 'a' as \"A_Column\" , 'x' SOME_COL , a . * from all_objects a where rownum < 4 ; ut . expect ( l_actual ). to_equal ( l_expected ). include ( ut_varchar2_list ( 'RN' , 'A_Column' , 'SOME_COL' ) ); end ; / SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ] SUCCESS Actual: refcursor [ count = 3 ] was expected to equal: refcursor [ count = 3 ]","title":"Defining item lists in option"},{"location":"userguide/advanced_data_comparison.html#unordered-columns-uc-option","text":"If you need to perform data comparison of compound data types without strictly depending on column order in the returned result-set, use the unordered_columns option. Shortcut name uc is also available for that option. Expectations that compare compound data type data with unordered_columns option, will not fail when columns are ordered differently. This option can be useful whn we have no control over the ordering of the column or the column order is not of importance from testing perspective. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange open l_actual for select owner , object_name , object_type from all_objects where owner = user order by 1 , 2 , 3 asc ; open l_expected for select object_type , owner , object_name from all_objects where owner = user and rownum < 20 ; --Assert ut . expect ( l_actual ). to_contain ( l_expected ). unordered_columns (); end ; / Produces: SUCCESS Actual: refcursor [ count = 348 ] was expected to contain: refcursor [ count = 19 ]","title":"Unordered columns / uc option"},{"location":"userguide/annotations.html","text":"Annotations are used to configure tests and suites in a declarative way similar to modern OOP languages. This way, test configuration is stored along with the test logic inside the test package. No additional configuration files or tables are needed for test cases. The annotation names are based on popular testing frameworks such as JUnit. The framework runner searches for all the suitable annotated packages, automatically configures suites, forms the suite hierarchy, executes it and reports results in specified formats. Annotation is defined by: - single line comment -- (double hyphen) - followed directly by a % (percent) - followed by annotation name - followed by optional annotation text placed in single brackets. All of text between first opening bracket and last closing bracket in annotation line is considered to be annotation text Examples: --%suite(The name of my test suite) - represents suite annotation with text The name of my test suite utPLSQL interprets the whole line of annotation and will treat all the text from the first opening bracket in the line to the last closing bracket Example: --%suite(Stuff) -- we should name this ( correctly ) - represents suite annotation with text Stuff) -- we should name this ( correctly Do not place comments within annotation line to avoid unexpected behaviors. Note: Annotations are interpreted only in the package specification and are case-insensitive. We strongly recommend using lower-case annotations as described in this documentation. There are two distinct types of annotations, identified by their location in package. - package annotations - procedure annotations Procedure level annotations \u00b6 Annotation placed directly before a procedure ( --%test , --%beforeall , --%beforeeach etc.). There can not be any empty lines or comments between annotation line and procedure line. There can be many annotations for a procedure. Valid procedure annotations example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package test_package is --%suite --%test() --%disabled procedure my_first_procedure ; $ if dbms_db_version . version >= 12 $ then --This is ok - annotation before procedure --%test() procedure my_first_procedure ; $ end --A comment goes before annotations --%test() procedure my_first_procedure ; end ; Invalid procedure annotations examples: package test_package is --%suite --%test() --This is wrong as there is an empty line between procedure and annotation procedure my_first_procedure ; --%test() --This is wrong as there is a comment line between procedure and annotation procedure proc1 ; --%test() --This is wrong as there is a compiler directive between procedure and annotation $ if dbms_db_version . version >= 12 $ then procedure proc_12 ; $ end --%test() -- procedure another_proc; /* The above is wrong as the procedure is commented out and annotation is not procedure annotation anymore */ end ; Package level annotations \u00b6 Those annotations placed at any place in package except directly before procedure ( --%suite , --%suitepath etc.). We strongly recommend putting package level annotations at the very top of package except for the --%context annotations (described below) Valid package annotations example: package test_package is --%suite --%suitepath(org.utplsql.example) --%beforeall(some_package.some_procedure) --%context --%test() procedure my_first_procedure ; --%endcontext end ; Invalid package annotations examples: package test_package is --%suite --This is wrong as suite annotation is not a procedure annotation procedure irrelevant ; --%context --This is wrong as there is no empty line between package level annotation and procedure level annotation --%test() procedure my_first_procedure ; end ; Supported annotations \u00b6 Annotation Level Description --%suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). --%suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. --%displayname(<description>) Package/procedure Human-readable and meaningful description of a context/suite/test. Overrides the <description> provided with suite / test / context annotation. This annotation is redundant and might be removed in future releases. --%test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can be provided (see displayname ). --%throws(<exception>[,...]) Procedure Denotes that the annotated test procedure must throw one of the exceptions provided. Supported forms of exceptions are: numeric literals, numeric constant names, exception constant names, predefined Oracle exception names. --%beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. --%beforeall([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed once before all elements of the suite. --%afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. --%afterall([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed once after all elements of the suite. --%beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. --%beforeeach([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed before each %test procedure in the suite. --%aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. --%aftereach([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed after each %test procedure in the suite. --%beforetest([[<owner>.]<package>.]<procedure>[,...]) Procedure Denotes that mentioned procedure(s) should be executed before the annotated %test procedure. --%aftertest([[<owner>.]<package>.]<procedure>[,...]) Procedure Denotes that mentioned procedure(s) should be executed after the annotated %test procedure. --%rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - a savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) --%disabled(<reason>) Package/procedure Used to disable a suite, whole context or a test. Disabled suites/contexts/tests do not get executed, they are however marked and reported as disabled in a test run. The reason that will be displayed next to disabled tests is decided based on hierarchy suites -> context -> test --%context(<description>) Package Denotes start of a named context (sub-suite) in a suite package an optional description for context can be provided. --%name(<name>) Package Denotes name for a context. Must be placed after the context annotation and before start of nested context. --%endcontext Package Denotes end of a nested context (sub-suite) in a suite package --%tags Package/procedure Used to label a test or a suite for purpose of identification Suite \u00b6 The --%suite annotation denotes PLSQL package as a unit test suite. It accepts an optional description that will be visible when running the tests. When description is not provided, package name is displayed on report. Note Package is considered a test-suite only when package specification contains the --%suite annotation at the package level. Some annotations like --%suite , --%test and --%displayname accept parameters. The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks. If the parameters are placed without brackets or with incomplete brackets, they will be ignored. Example: --%suite(The name of suite without closing bracket Example: --%suite The name of suite without brackets Suite package without description. create or replace package test_package as --%suite end ; / exec ut . run ( 'test_package' ); test_package Finished in .002415 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Suite package with description. create or replace package test_package as --%suite(Tests for a package) end ; / exec ut . run ( 'test_package' ); Tests for a package Finished in .001646 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) When multiple --%suite annotations are specified in package, the first annotation will be used and a warning message will appear indicating duplicate annotation. create or replace package test_package as --%suite(Tests for a package) --%suite(Bad annotation) end ; / exec ut . run ( 'test_package' ); Tests for a package Warnings: 1) test_package Duplicate annotation \"--%suite\". Annotation ignored. at \"TESTS_OWNER.TEST_PACKAGE\", line 3 Finished in .003318 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 1 warning(s) When --%suite annotation is bound to procedure, it is ignored and results in package not getting recognized as test suite. create or replace package test_package as --%suite(Tests for a package) procedure some_proc ; end ; / exec ut . run ( 'test_package' ); ORA-20204: Suite package TESTS_OWNER.test_package not found ORA-06512: at \"UT3.UT_RUNNER\", line 106 ORA-06512: at \"UT3.UT\", line 115 ORA-06512: at \"UT3.UT\", line 306 ORA-06512: at \"UT3.UT\", line 364 ORA-06512: at line 1 Test \u00b6 The --%test annotation denotes procedure withing test suite as a unit test. It accepts an optional description that will be reported when the test is executed. When description is not provided, procedure name is displayed on report. If --%test raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite Test procedure without description. create or replace package test_package as --%suite(Tests for a package) --%test procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package some_test [.003 sec] Finished in .004109 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Test procedure with description. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.005 sec] Finished in .006828 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) When multiple --%test annotations are specified for a procedure, the first annotation will be used and a warning message will appear indicating duplicate annotation. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%test(Duplicate description) procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.007 sec] Warnings: 1) test_package Duplicate annotation \"--%test\". Annotation ignored. at \"TESTS_OWNER.TEST_PACKAGE.SOME_TEST\", line 5 Finished in .008815 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 1 warning(s) Disabled \u00b6 Marks annotated suite package or test procedure as disabled. You can provide the reason why the test is disabled that will be displayed in output. Disabling suite. create or replace package test_package as --%suite(Tests for a package) --%disabled(Reason for disabling suite) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [0 sec] (DISABLED - Reason for disabling suite) Description of another behavior [0 sec] (DISABLED - Reason for disabling suite) Finished in .001441 seconds 2 tests, 0 failed, 0 errored, 2 disabled, 0 warning(s) Disabling the context(s). create or replace package test_package as --%suite(Tests for a package) --%context(Context1) --%test(Description of tested behavior) procedure some_test ; --%endcontext --%context(Context2) --%disabled(Reason for disabling context2) --%test(Description of another behavior) procedure other_test ; --%endcontext end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Context1 Description of tested behavior [.002 sec] Context2 Description of another behavior [0 sec] (DISABLED - Reason for disabling context2) Finished in .005079 seconds 2 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s) Disabling individual test(s). create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) --%disabled(Reason for disabling test) procedure other_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.004 sec] Description of another behavior [0 sec] (DISABLED - Reason for disabling test) Finished in .005868 seconds 2 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s) Beforeall \u00b6 There are two possible ways to use the --%beforeall annotation. As a procedure level annotation: --%suite(Some test suite) --%beforeall procedure to_be_executed_before_all ; --%test procedure some_test ; Marks annotated procedure to be executed before all test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%beforeall(to_be_executed_before_all, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_before_all ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed before all test procedures in a suite. If --%beforeall raises an exception, suite content cannot be safely executed as the setup was not executed successfully for the suite. If --%beforeall raises an exception the following will happen: - the --%beforeall procedures that follow the failed one, will not be executed - all --%test procedures and their --%beforeeach , --%aftereach , --%beforetest and --%aftertest procedures within suite package will not be executed - all --%test procedures will be marked as failed - the --%afterall procedures will be executed - test execution will continue uninterrupted for other suite packages When multiple --%beforeall procedures are defined in a suite package, all of them will be executed before invoking any test. For multiple --%beforeall procedures order of execution is defined by annotation position in the package specification. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeall procedure setup_stuff ; end ; / create or replace package body test_package as procedure setup_stuff is begin dbms_output . put_line ( '--- SETUP_STUFF invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package --- SETUP_STUFF invoked --- Description of tested behavior [.004 sec] Description of another behavior [.003 sec] Finished in .012292 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) In the below example a combination pacakge and procedure level --%beforeall annotations is used. The order of execution of the beforeall procedures is determined by the annotation position in package. All of the --%beforeall procedures get invoked before any test is executed in a suite. create or replace package test_package as --%suite(Tests for a package) --%beforeall(initial_setup,test_package.another_setup) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeall procedure next_setup ; --%beforeall(one_more_setup) procedure another_setup ; procedure one_more_setup ; procedure initial_setup ; end ; / create or replace package body test_package as procedure one_more_setup is begin dbms_output . put_line ( '--- ONE_MORE_SETUP invoked ---' ); end ; procedure next_setup is begin dbms_output . put_line ( '--- NEXT_SETUP invoked ---' ); end ; procedure another_setup is begin dbms_output . put_line ( '--- ANOTHER_SETUP invoked ---' ); end ; procedure initial_setup is begin dbms_output . put_line ( '--- INITIAL_SETUP invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); ``` Tests for a package --- INITIAL_SETUP invoked --- --- ANOTHER_SETUP invoked --- --- NEXT_SETUP invoked --- --- ONE_MORE_SETUP invoked --- Description of tested behavior [.003 sec] Description of another behavior [.002 sec] Finished in .018944 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) ``` When multiple --%beforeall annotations are specified for a procedure, the first annotation will be used and a warning message will appear indicating duplicate annotation. When procedure is annotated as both --%beforeall and --%test , the procedure will become a test and a warning message will appear indicating invalid annotation combination. create or replace package test_package as --%suite(Tests for a package) --%beforeall --%beforeall procedure initial_setup ; --%test(Description of tested behavior) --%beforeall procedure some_test ; --%test(Description of another behavior) procedure other_test ; end ; / create or replace package body test_package as procedure initial_setup is begin dbms_output . put_line ( '--- INITIAL_SETUP invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); ``` Tests for a package --- INITIAL_SETUP invoked --- Description of tested behavior [.003 sec] Description of another behavior [.004 sec] Warnings: 1) test_package Duplicate annotation \"--%beforeall\". Annotation ignored. at \"UT3_TESTER.TEST_PACKAGE.INITIAL_SETUP\", line 5 2) test_package Annotation \"--%beforeall\" cannot be used with annotation: \"--%test\" at \"UT3_TESTER.TEST_PACKAGE.SOME_TEST\", line 9 Finished in .012158 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 2 warning(s) ``` Afterall \u00b6 There are two possible ways to use the --%afterall annotation. As a procedure level annotation: --%suite(Some test suite) --%afterall procedure to_be_executed_after_all ; --%test procedure some_test ; Marks annotated procedure to be executed after all test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%afterall(to_be_executed_after_all, other_package.some_cleanup) --%test procedure some_test ; procedure to_be_executed_after_all ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed after all test procedures in a suite. If --%afterall raises an exception the following will happen: - a warning will be raised, indicating that --%afterall procedure has failed - execution will continue uninterrupted for rest of the suite If --%afterall raises an exception, it can have negative impact on other tests, as the environment was not cleaned-up after the tests. This however doesn't have direct impact on test execution within current suite, as the tests are already complete by the time --%afterall is called. When multiple --%afterall procedures are defined in a suite, all of them will be executed after invoking all tests from the suite. For multiple --%afterall procedures order of execution is defined by annotation position in the package specification. All rules defined for --%beforeall also apply for --%afterall annotation. See beforeall for more details. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%afterall procedure cleanup_stuff ; end ; / create or replace package body test_package as procedure cleanup_stuff is begin dbms_output . put_line ( '---CLEANUP_STUFF invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.003 sec] Description of another behavior [.005 sec] ---CLEANUP_STUFF invoked --- Finished in .014161 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Beforeeach \u00b6 The procedure annotated as --%beforeeach is getting executed before each test in a suite. That means that the procedure will be executed as many times as there are test in suite package. There are two possible ways to use the --%beforeeach annotation. As a procedure level annotation: --%suite(Some test suite) --%beforeeach procedure to_be_executed_before_each ; --%test procedure some_test ; Marks annotated procedure to be executed before each test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%beforeeach(to_be_executed_before_each, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_before_each ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed before each test procedure in a suite. If a test is marked as disabled the --%beforeeach procedure is not invoked for that test. If --%beforeeach raises an unhandled exception the following will happen: - the following --%beforeeach as well as all --%beforetest for that test will not be executed - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite As a rule, the --%beforeeach execution gets aborted if preceding --%beforeeach failed. When multiple --%beforeeach procedures are defined in a suite, all of them will be executed before invoking each test. For multiple --%beforeeach procedures order of execution is defined by annotation position in the package specification. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeeach procedure setup_for_test ; --%beforeall procedure setup_stuff ; end ; / create or replace package body test_package as procedure setup_stuff is begin dbms_output . put_line ( '---SETUP_STUFF invoked ---' ); end ; procedure setup_for_test is begin dbms_output . put_line ( '---SETUP_FOR_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package ---SETUP_STUFF invoked --- Description of tested behavior [.004 sec] ---SETUP_FOR_TEST invoked --- ---SOME_TEST invoked --- Description of another behavior [.006 sec] ---SETUP_FOR_TEST invoked --- ---OTHER_TEST invoked --- Finished in .014683 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) See beforeall for more examples. Aftereach \u00b6 Marks annotated procedure to be executed after each test procedure in a suite. The procedure annotated as --%aftereach is getting executed after each test in a suite. That means that the procedure will be executed as many times as there are test in suite package. There are two possible ways to use the --%aftereach annotation. As a procedure level annotation: --%suite(Some test suite) --%aftereach procedure to_be_executed_after_each ; --%test procedure some_test ; Marks annotated procedure to be executed after each test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%aftereach(to_be_executed_after_each, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_after_each ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed after each test procedure in a suite. If a test is marked as disabled the --%aftereach procedure is not invoked for that test. If --%aftereach raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%aftereach procedures are defined in a suite, all of them will be executed after invoking each test. For multiple --%aftereach procedures order of execution is defined by the annotation position in the package specification. As a rule, the --%aftereach gets executed even if the associated --%beforeeach , --%beforetest , --%test or other --%aftereach procedures have raised unhandled exceptions. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%aftereach procedure cleanup_for_test ; --%afterall procedure cleanup_stuff ; end ; / create or replace package body test_package as procedure cleanup_stuff is begin dbms_output . put_line ( '---CLEANUP_STUFF invoked ---' ); end ; procedure cleanup_for_test is begin dbms_output . put_line ( '---CLEANUP_FOR_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.006 sec] ---SOME_TEST invoked --- ---CLEANUP_FOR_TEST invoked --- Description of another behavior [.006 sec] ---OTHER_TEST invoked --- ---CLEANUP_FOR_TEST invoked --- ---CLEANUP_STUFF invoked --- Finished in .018115 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) See beforeall for more examples. Beforetest \u00b6 Indicates specific setup procedure(s) to be executed for a test. The procedure(s) can be located either: - within current package (package name is optional) - within another package The annotation need to be placed alongside --%test annotation. The --%beforetest procedures are executed after invoking all --%beforeeach for a test. If a test is marked as disabled the --%beforetest procedures are not invoked for that test. If --%beforetest raises an unhandled exception the following will happen: - the following --%beforetest for that test will not be executed - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%beforetest procedures are defined for a test, all of them will be executed before invoking the test. The order of execution for --%beforetest procedures is defined by: - position of procedure on the list within single annotation - annotation position As a rule, the --%beforetest execution gets aborted if preceding --%beforeeach or --%beforetest failed. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%beforetest(test_package.setup_for_a_test) --%beforetest(another_setup_for_a_test) procedure some_test ; --%test(Description of another behavior) --%beforetest(test_package.setup_for_a_test, another_setup_for_a_test) procedure other_test ; procedure another_setup_for_a_test ; procedure setup_for_a_test ; end ; / create or replace package body test_package as procedure setup_for_a_test is begin dbms_output . put_line ( '---SETUP_FOR_A_TEST invoked ---' ); end ; procedure another_setup_for_a_test is begin dbms_output . put_line ( '---ANOTHER_SETUP_FOR_A_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.008 sec] ---SETUP_FOR_A_TEST invoked --- ---ANOTHER_SETUP_FOR_A_TEST invoked --- ---SOME_TEST invoked --- Description of another behavior [.005 sec] ---SETUP_FOR_A_TEST invoked --- ---ANOTHER_SETUP_FOR_A_TEST invoked --- ---OTHER_TEST invoked --- Finished in .015185 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Aftertest \u00b6 Indicates specific cleanup procedure(s) to be executed for a test. The procedure(s) can be located either: - within current package (package name is optional) - within another package The annotation need to be placed alongside --%test annotation. If a test is marked as disabled the --%aftertest procedures are not invoked for that test. If --%aftertest raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the following --%aftertest and all --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%aftertest procedures are defined for a test, all of them will be executed after invoking the test. The order of execution for --%aftertest procedures is defined by: - position of procedure on the list within single annotation - annotation position As a rule, the --%aftertest gets executed even if the associated --%beforeeach , --%beforetest , --%test or other --%aftertest procedures have raised unhandled exceptions. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%aftertest(test_package.cleanup_for_a_test) --%aftertest(another_cleanup_for_a_test) procedure some_test ; --%test(Description of another behavior) --%aftertest(test_package.cleanup_for_a_test, another_cleanup_for_a_test) procedure other_test ; procedure another_cleanup_for_a_test ; procedure cleanup_for_a_test ; end ; / create or replace package body test_package as procedure cleanup_for_a_test is begin dbms_output . put_line ( '---CLEANUP_FOR_A_TEST invoked ---' ); end ; procedure another_cleanup_for_a_test is begin dbms_output . put_line ( '---ANOTHER_CLEANUP_FOR_A_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.008 sec] ---SOME_TEST invoked --- ---CLEANUP_FOR_A_TEST invoked --- ---ANOTHER_CLEANUP_FOR_A_TEST invoked --- Description of another behavior [.006 sec] ---OTHER_TEST invoked --- ---CLEANUP_FOR_A_TEST invoked --- ---ANOTHER_CLEANUP_FOR_A_TEST invoked --- Finished in .016873 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Context \u00b6 In most of the cases, the code to be tested is consisting of PLSQL packages containing procedures and functions. When creating test suites, it's quite common to maintain one to one relationship between test suite packages and tested code. When it comes to test procedures themselves, it is best practice to have one test procedure for one tested behavior of the code that is tested. The relationship between test procedure and tested code will be therefore many to one or many to many in most of the cases. With this comes a challenge. How to group tests, related to one tested behavior, so that it is obvious that they relate to the same thing. This is where utPLSQL contexts come handy. Contexts allow for creating sub-suites within a suite package and they allow for grouping of tests that are somehow related. In essence, context behaves like a suite within a suite. Context have following characteristics: - context starts with the --%context annotation and ends with --%endcontext . Everything placed between those two annotations belongs to that context - can have a description provided as parameter for example --%context(Some interesting stuff) . - can have a name provided with --%name annotation. This is different than with suite and test annotations, where name is taken from package/procedure name. - contexts can be nested, you can place a context inside another context - when no name is provided for context, the context is named context_N where N is the number of the context in suite or parent context. - context name must be unique within it's parent (suite / parent context) - if context name is not unique within it's parent, context and it's entire content is excluded from execution - context name should not contain spaces or special characters - context name cannot contain a . (full stop/period) character - suite/context can have multiple nested sibling contexts in it - contexts can have their own --%beforeall , --%beforeeach , --%afterall and --%aftereach procedures - --%beforeall , --%beforeeach , --%afterall and --%aftereach procedures defined at ancestor level, propagate to context - if --%endcontext is missing for a context, the context spans to the end of package specification The below example illustrates usage of --%context for separating tests for individual procedures of package. Sample tables and code create table rooms ( room_key number primary key , name varchar2 ( 100 ) not null ); create table room_contents ( contents_key number primary key , room_key number not null , name varchar2 ( 100 ) not null , create_date timestamp default current_timestamp not null , constraint fk_rooms foreign key ( room_key ) references rooms ( room_key ) ); create or replace package rooms_management is procedure remove_rooms_by_name ( a_name rooms . name % type ); procedure add_rooms_content ( a_room_name rooms . name % type , a_content_name room_contents . name % type ); end ; / create or replace package body rooms_management is procedure remove_rooms_by_name ( a_name rooms . name % type ) is begin if a_name is null then raise program_error ; end if ; delete from rooms where name like a_name ; end ; procedure add_rooms_content ( a_room_name rooms . name % type , a_content_name room_contents . name % type ) is l_room_key rooms . room_key % type ; begin select room_key into l_room_key from rooms where name = a_room_name ; insert into room_contents ( contents_key , room_key , name ) select nvl ( max ( contents_key ) + 1 , 1 ) as contents_key , l_room_key , a_content_name from room_contents ; end ; end ; / Below test suite defines: - --%beforeall outside of context, that will be executed before all tests - --%context(remove_rooms_by_name) to group tests related to remove_rooms_by_name functionality - --%context(add_rooms_content) to group tests related to add_rooms_content functionality create or replace package test_rooms_management is gc_null_value_exception constant integer : = - 1400 ; --%suite(Rooms management) --%beforeall procedure setup_rooms ; --%context(remove_rooms_by_name) --%displayname(Remove rooms by name) --%test(Removes a room without content in it) procedure remove_empty_room ; --%test(Raises exception when null room name given) --%throws(-6501) procedure null_room_name ; --%endcontext --%context(add_rooms_content) --%displayname(Add content to a room) --%test(Fails when room name is not valid) --%throws(no_data_found) procedure fails_on_room_name_invalid ; --%test(Fails when content name is null) --%throws(test_rooms_management.gc_null_value_exception) procedure fails_on_content_null ; --%test(Adds a content to existing room) procedure add_content_success ; --%endcontext end ; / create or replace package body test_rooms_management is procedure setup_rooms is begin insert all into rooms values ( 1 , 'Dining Room' ) into rooms values ( 2 , 'Living Room' ) into rooms values ( 3 , 'Bathroom' ) select 1 from dual ; insert all into room_contents values ( 1 , 1 , 'Table' , sysdate ) into room_contents values ( 3 , 1 , 'Chair' , sysdate ) into room_contents values ( 4 , 2 , 'Sofa' , sysdate ) into room_contents values ( 5 , 2 , 'Lamp' , sysdate ) select 1 from dual ; dbms_output . put_line ( '---SETUP_ROOMS invoked ---' ); end ; procedure remove_empty_room is l_rooms_not_named_b sys_refcursor ; l_remaining_rooms sys_refcursor ; begin open l_rooms_not_named_b for select * from rooms where name not like 'B%' ; rooms_management . remove_rooms_by_name ( 'B%' ); open l_remaining_rooms for select * from rooms ; ut . expect ( l_remaining_rooms ). to_equal ( l_rooms_not_named_b ); end ; procedure room_with_content is begin rooms_management . remove_rooms_by_name ( 'Living Room' ); end ; procedure null_room_name is begin --Act rooms_management . remove_rooms_by_name ( NULL ); --Assert done by --%throws annotation end ; procedure fails_on_room_name_invalid is begin --Act rooms_management . add_rooms_content ( 'bad room name' , 'Chair' ); --Assert done by --%throws annotation end ; procedure fails_on_content_null is begin --Act rooms_management . add_rooms_content ( 'Dining Room' , null ); --Assert done by --%throws annotation end ; procedure add_content_success is l_expected room_contents . name % type ; l_actual room_contents . name % type ; begin --Arrange l_expected : = 'Table' ; --Act rooms_management . add_rooms_content ( 'Dining Room' , l_expected ); --Assert select name into l_actual from room_contents where contents_key = ( select max ( contents_key ) from room_contents ); ut . expect ( l_actual ). to_equal ( l_expected ); end ; end ; / When te tests are executed exec ut . run ( 'test_rooms_management' ); The following report is displayed Rooms management ---SETUP_ROOMS invoked --- remove_rooms_by_name Removes a room without content in it [.015 sec] Raises exception when null room name given [.002 sec] add_rooms_content Fails when room name is not valid [.003 sec] Fails when content name is null [.003 sec] Adds a content to existing room [.003 sec] Finished in .035261 seconds 5 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Example of nested contexts test suite specification. Source - slide 145 of Structure and Interpretation of Test Cases by Kevlin Henney create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%test(Is empty) procedure is_empty ; --%test(Preserves positive bounding capacity) procedure positive_bounding_capacity ; --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%test(Dequeues an empty value) procedure deq_empty_value ; --%test(Remains empty when null enqueued) procedure empty_with_null_enq ; --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%context(that is not full) --%test(Becomes longer when non null value enqueued) procedure grow_on_enq_non_null ; --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%test(Ignores further enqueued values) procedure full_ignore_enq ; --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%test(Dequeues values in order enqueued) procedure dequeue_ordered ; --%test(Remains unchanged when null enqueued) procedure no_change_on_null_enq ; --%endcontext end ; When such specification gets executed ut.run('queue_spec'') (without body created) you will see the nesting of tests within contexts. Queue specification An empty queue Dequeues an empty value [.014 sec] (FAILED - 1) Remains empty when null enqueued [.004 sec] (FAILED - 2) Becomes non empty when non null value enqueued [.005 sec] (FAILED - 3) A non empty queue that is not full Becomes longer when non null value enqueued [.005 sec] (FAILED - 4) Becomes full when enqueued up to capacity [.005 sec] (FAILED - 5) That is full Ignores further enqueued values [.004 sec] (FAILED - 6) Becomes non full when dequeued [.005 sec] (FAILED - 7) Dequeues values in order enqueued [.006 sec] (FAILED - 8) Remains unchanged when null enqueued [.004 sec] (FAILED - 9) A new queue Is empty [.007 sec] (FAILED - 10) Preserves positive bounding capacity [.006 sec] (FAILED - 11) Cannot be created with non positive bounding capacity [.005 sec] (FAILED - 12) Failures: 1) deq_empty_value ORA-04067: not executed, package body \"UT3.QUEUE_SPEC\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3.QUEUE_SPEC\" ORA-06512: at line 6 ... Finished in .088573 seconds 12 tests, 0 failed, 12 errored, 0 disabled, 0 warning(s) Suite nesting allows for organizing tests into human-readable specification of behavior. Name \u00b6 The --%name annotation is currently only used only for naming a context. If a context doesn't have explicit name specified, then the name is given automatically by framework. The automatic name will be context_#n where n is a context number within a suite/parent context. The --%name can be useful when you would like to run only a specific context or its items by suitepath . Consider the below example. create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%context(that is not full) --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%endcontext end ; In the above code, suitepaths, context names and context descriptions will be as follows. suitepath description name queue_spec Queue specification queue_spec queue_spec.context_#1 A new queue context_#1 queue_spec.context_#2 An empty queue context_#2 queue_spec.context_#3 A non empty queue context_#3 queue_spec.context_#3.context_#1 that is not full context_#1 queue_spec.context_#3.context_#2 that is full context_#2 In order to run only the tests for the context A non empty queue that is not full you will need to call utPLSQL as below: exec ut . run ( ':queue_spec.context_#3.context_#1' ); You can use --%name annotation to explicitly name contexts on suitepath. create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%name(a_new_queue) --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%name(an_empty_queue) --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%name(a_non_empty_queue) --%context(that is not full) --%name(that_is_not_full) --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%name(that_is_full) --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%endcontext end ; In the above code, suitepaths, context names and context descriptions will be as follows. suitepath description name queue_spec Queue specification queue_spec queue_spec.a_new_queue A new queue a_new_queue queue_spec.an_empty_queue An empty queue an_empty_queue queue_spec.a_non_empty_queue A non empty queue a_non_empty_queue queue_spec.a_non_empty_queue.that_is_not_full that is not full that_is_not_full queue_spec.a_non_empty_queue.that_is_full that is full that_is_full The --%name annotation is only relevant for: - running subsets of tests by given context suitepath - some of test reports, like ut_junit_reporter that use suitepath or test-suite element names (not descriptions) for reporting Name naming convention \u00b6 The value of --%name annotation must follow the following naming rules: - cannot contain spaces - cannot contain a . (full stop/dot) - is case-insensitive Tags \u00b6 Tag is a label attached to the test or a suite. It is used for identification and execution of a group of tests / suites that share the same tag. It allows for grouping of tests / suites using various categorization and place tests / suites in multiple buckets. Same tests can be grouped with other tests based on the functionality , frequency, type of output etc. e.g. --%tags(batch,daily,csv) or --%tags(online,json) --%tags(api) Tags are defined as a comma separated list within the --%tags annotation. When executing a test run with tag filter applied, the framework will find all tests associated with the given tags and execute them. The framework applies OR logic to all specified tags so any test / suite that matches at least one tag will be included in the test run. When a suite/context is tagged, all of its children will automatically inherit the tag and get executed along with the parent. Parent suite tests are not executed, but a suitepath hierarchy is kept. Sample test suite package with tags. create or replace package ut_sample_test is --%suite(Sample Test Suite) --%tags(api) --%test(Compare Ref Cursors) --%tags(complex,fast) procedure ut_refcursors1 ; --%test(Run equality test) --%tags(simple,fast) procedure ut_test ; end ut_sample_test ; / create or replace package body ut_sample_test is procedure ut_refcursors1 is v_actual sys_refcursor ; v_expected sys_refcursor ; begin open v_expected for select 1 as test from dual ; open v_actual for select 2 as test from dual ; ut . expect ( v_actual ). to_equal ( v_expected ); end ; procedure ut_test is begin ut . expect ( 1 ). to_equal ( 0 ); end ; end ut_sample_test ; / Execution of the test is done by using the parameter a_tags select * from table ( ut . run ( a_path => 'ut_sample_test' , a_tags => 'api' )); The above call will execute all tests from ut_sample_test package as the whole suite is tagged with api select * from table ( ut . run ( a_tags => 'complex' )); The above call will execute only the ut_sample_test.ut_refcursors1 test, as only the test ut_refcursors1 is tagged with complex select * from table ( ut . run ( a_tags => 'fast' )); The above call will execute both ut_sample_test.ut_refcursors1 and ut_sample_test.ut_test tests, as both tests are tagged with fast Tag naming convention \u00b6 Tags must follow the below naming convention: tag is case sensitive tag can contain special characters like $#/\\?-! etc. tag cannot be an empty string tag cannot start with a dash, e.g. -some-stuff is not a valid tag tag cannot contain spaces, e.g. test of batch . To create a multi-word tag use underscores or dashes, e.g. test_of_batch , test-of-batch leading and trailing spaces are ignored in tag name, e.g. --%tags( tag1 , tag2 ) becomes tag1 and tag2 tag names Excluding tests/suites by tags \u00b6 It is possible to exclude parts of test suites with tags. In order to do so, prefix the tag name to exclude with a - (dash) sign when invoking the test run. Examples (based on above sample test suite) select * from table ( ut . run ( a_tags => 'api,fast,-complex' )); The above call will execute all suites/contexts/tests that are marked with any of tags api or fast except those suites/contexts/tests that are marked as complex . Given the above example package ut_sample_test , only ut_sample_test.ut_test will be executed. Suitepath \u00b6 It is very likely that the application for which you are going to introduce tests consists of many different packages, procedures and functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedures in a single package and packages might be grouped into modules and modules into subject areas. As your project grows, the codebase will grow to. utPLSQL allows you to group packages into modules and also allows for nesting modules. Let's say you have a complex insurance application that deals with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of your application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off The --%suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the --%suitepath is used by the framework to form them into a hierarchical structure. Your payments recognition test package might look like: create or replace package test_payment_recognition as --%suite(Payment recognition tests) --%suitepath(payments) --%test(Recognize payment by policy number) procedure test_recognize_by_num ; --%test(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; --%test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as --%suite(Payment set off tests) --%suitepath(payments) --%test(Creates set off) procedure test_create_set_off ; --%test(Cancels set off) procedure test_cancel_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs a test suite for each test package. Then it combines suites into grouping suites by the --%suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has not met the expectations of the test. Grouping tests into modules and submodules using the --%suitepath annotation allows you to logically organize your project's flat structure of packages into functional groups. An additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing a common module level setup for all of the submodules. So in addition to the packages mentioned above you could have the following package. create or replace package payments as --%suite(Payments) --%beforeall procedure set_common_payments_data ; --%afterall procedure reset_common_paymnets_data ; end payments ; When executing tests, path for executing tests can be provided in three ways: * schema - execute all tests in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests by suitepath in all suites on path suite1[.suite2][.suite3]...[.procedure]. If schema is not provided, then the current schema is used. Example: :all.rooms_tests * [schema.]package[.procedure] - execute all tests in the specified test package. The whole hierarchy of suites in the schema is built before all before/after hooks or part suites for the provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema. Rollback \u00b6 By default, changes performed by every setup, cleanup and test procedure are isolated by savepoints. This solution is suitable for use-cases where the code that is being tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests does not impact others who might be using a shared development database. If you are in a situation where the code you are testing uses transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation --%rollback(manual) on the suite level to disable automatic transaction control for the entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in a suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most likely fail with error or warning on execution. Some of the automatic rollbacks will probably fail to execute depending on the configuration you have. In some cases it is necessary to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commits in the main session that is executing all your tests. Doing so allows your tests to use the framework's automatic transaction control and releases you from the burden of manual cleanup of data that was created or modified by test execution. When you are testing code that performs explicit or implicit commits, you may set the test procedure to run as an autonomous transaction with pragma autonomous_transaction . Keep in mind that when your test runs as autonomous transaction it will not see the data prepared in a setup procedure unless the setup procedure committed the changes. Note The --%suitepath annotation, when used, must be provided with a value of path. The path in suitepath cannot contain spaces. Dot (.) identifies individual elements of the path. Example: --%suitepath(org.utplsql.core.utils) Throws \u00b6 The --%throws annotation allows you to specify a list of exceptions as one of: - number literals - example --%throws(-20134) - variables of type exception defined in a package specification - example --%throws(exc_pkg.c_exception_No_variable) - variables of type number defined in a package specification - example --%throws(exc_pkg.c_some_exception) - predefined oracle exceptions - example --%throws(no_data_found) The annotation is ignored, when no valid arguments are provided. Examples of invalid annotations --%throws() , --%throws , --%throws(abe, 723pf) . If --%throws annotation is specified with arguments and no exception is raised, the test is marked as failed. If --%throws annotation is specified with arguments and exception raised is not on the list of provided exceptions, the test is marked as failed. The framework will raise a warning, when --%throws annotation has invalid arguments or when no arguments were provided. Annotation --%throws(7894562, operaqk, -=1, -20496, pow74d, posdfk3) will be interpreted as --%throws(-20496) . Please note that NO_DATA_FOUND exception is a special case in Oracle. To capture it use NO_DATA_FOUND named exception or -1403 exception No. \u200b Example: create or replace package exc_pkg is c_e_option1 constant number : = - 20200 ; c_e_option2 constant varchar2 ( 10 ) : = '-20201' ; c_e_option3 number : = - 20202 ; e_option4 exception ; pragma exception_init ( e_option4 , - 20203 ); end ; / create or replace package example_pgk as --%suite(Example Throws Annotation) --%test(Throws one of the listed exceptions) --%throws(-20145,bad,-20146, -20189 ,-20563) procedure raised_one_listed_exception ; --%test(Throws different exception than expected) --%throws(-20144) procedure raised_different_exception ; --%test(Throws different exception than listed) --%throws(-20144,-00001,-20145) procedure raised_unlisted_exception ; --%test(Gives failure when an exception is expected and nothing is thrown) --%throws(-20459, -20136, -20145) procedure nothing_thrown ; --%test(Throws package exception option1) --%throws(exc_pkg.c_e_option1) procedure raised_option1_exception ; --%test(Throws package exception option2) --%throws(exc_pkg.c_e_option2) procedure raised_option2_exception ; --%test(Throws package exception option3) --%throws(exc_pkg.c_e_option3) procedure raised_option3_exception ; --%test(Throws package exception option4) --%throws(exc_pkg.e_option4) procedure raised_option4_exception ; --%test(Raise name exception) --%throws(DUP_VAL_ON_INDEX) procedure raise_named_exc ; --%test(Invalid throws annotation) --%throws procedure bad_throws_annotation ; end ; / create or replace package body example_pgk is procedure raised_one_listed_exception is begin raise_application_error ( - 20189 , 'Test error' ); end ; procedure raised_different_exception is begin raise_application_error ( - 20143 , 'Test error' ); end ; procedure raised_unlisted_exception is begin raise_application_error ( - 20143 , 'Test error' ); end ; procedure nothing_thrown is begin ut . expect ( 1 ). to_equal ( 1 ); end ; procedure raised_option1_exception is begin raise_application_error ( exc_pkg . c_e_option1 , 'Test error' ); end ; procedure raised_option2_exception is begin raise_application_error ( exc_pkg . c_e_option2 , 'Test error' ); end ; procedure raised_option3_exception is begin raise_application_error ( exc_pkg . c_e_option3 , 'Test error' ); end ; procedure raised_option4_exception is begin raise exc_pkg . e_option4 ; end ; procedure raise_named_exc is begin raise DUP_VAL_ON_INDEX ; end ; procedure bad_throws_annotation is begin null ; end ; end ; / exec ut3 . ut . run ( 'example_pgk' ); Running the test will give report: Example Throws Annotation Throws one of the listed exceptions [.002 sec] Throws different exception than expected [.002 sec] (FAILED - 1) Throws different exception than listed [.003 sec] (FAILED - 2) Gives failure when an exception is expected and nothing is thrown [.002 sec] (FAILED - 3) Throws package exception option1 [.003 sec] Throws package exception option2 [.002 sec] Throws package exception option3 [.002 sec] Throws package exception option4 [.002 sec] Raise name exception [.002 sec] Invalid throws annotation [.002 sec] Failures: 1) raised_different_exception Actual: -20143 was expected to equal: -20144 ORA-20143: Test error ORA-06512: at \"UT3.EXAMPLE_PGK\", line 9 ORA-06512: at \"UT3.EXAMPLE_PGK\", line 9 ORA-06512: at line 6 2) raised_unlisted_exception Actual: -20143 was expected to be one of: (-20144, -1, -20145) ORA-20143: Test error ORA-06512: at \"UT3.EXAMPLE_PGK\", line 14 ORA-06512: at \"UT3.EXAMPLE_PGK\", line 14 ORA-06512: at line 6 3) nothing_thrown Expected one of exceptions (-20459, -20136, -20145) but nothing was raised. Warnings: 1) example_pgk Invalid parameter value \"bad\" for \"--%throws\" annotation. Parameter ignored. at \"UT3.EXAMPLE_PGK.RAISED_ONE_LISTED_EXCEPTION\", line 6 2) example_pgk \"--%throws\" annotation requires a parameter. Annotation ignored. at \"UT3.EXAMPLE_PGK.BAD_THROWS_ANNOTATION\", line 42 Finished in .025784 seconds 10 tests, 3 failed, 0 errored, 0 disabled, 2 warning(s) Order of execution \u00b6 create or replace package test_employee_pkg is --%suite(Employee management) --%suitepath(com.my_company.hr) --%rollback(auto) --%beforeall procedure setup_employees ; --%beforeall procedure setup_departments ; --%afterall procedure cleanup_log_table ; --%context(add_employee) --%beforeeach procedure setup_for_add_employees ; --%test(Raises exception when employee already exists) --%throws(-20145) procedure add_existing_employee ; --%test(Inserts employee to emp table) procedure add_employee ; --%endcontext --%context(remove_employee) --%beforeall procedure setup_for_remove_employee ; --%test(Removed employee from emp table) procedure del_employee ; --%endcontext --%test(Test without context) --%beforetest(setup_another_test) --%aftertest(cleanup_another_test) procedure some_test ; --%test(Name of test) --%disabled procedure disabled_test ; --%test(Name of test) --%rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; --%beforeeach procedure set_session_context ; --%aftereach procedure cleanup_session_context ; end test_employee_pkg ; When processing the test suite test_employee_pkg defined in Example of annotated test package , the order of execution will be as follows. create a savepoint 'before-suite' execute setup_employees (--%beforeall) execute setup_departments (--%beforeall) create a savepoint 'before-context' create savepoint 'before-test' execute test_setup (--%beforeeach) execute setup_for_add_employees (--%beforeeach from context) execute add_existing_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' create savepoint 'before-test' (--%suite) execute test_setup (--%beforeeach) execute setup_for_add_employees (--%beforeeach from context) execute add_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' rollback to savepoint 'before-context' create a savepoint 'before-context' execute setup_for_remove_employee (--%beforeall from context) create savepoint 'before-test' execute test_setup (--%beforeeach) execute add_existing_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' rollback to savepoint 'before-context' create savepoint 'before-test' execute test_setup (--%beforeeach) execute some_test (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' create savepoint 'before-test' execute test_setup (--%beforeeach) execute setup_another_test (--%beforetest) execute another_test (--%test) execute cleanup_another_test (--%aftertest) execute test_cleanup (--%beforeeach) rollback to savepoint 'before-test' mark disabled_test as disabled (--%test --%disabled) execute test_setup (--%beforeeach) execute no_transaction_control_test (--%test) execute test_cleanup (--%aftertest) execute global_cleanup (--%afterall) rollback to savepoint 'before-suite' Note utPLSQL does not guarantee ordering of tests in suite. On contrary utPLSQL might give random order of tests/contexts in suite. Order of execution within multiple occurrences of before / after procedures is determined by the order of annotations in specific block (context/suite) of package specification. sys_context \u00b6 It is possible to access information about currently running suite. The information is available by calling sys_context( 'UT3_INFO', attribute ) . It can be accessed from any procecure invoked as part of utPLSQL test execution. Note: Context name is derived from schema name where utPLSQL is installed. The context name in below examples represents the default install schema -> UT3 If you install utPLSQL into another schema the context name will be different. For example if utPLSQL is installed into HR schema, the context name will be HR_INFO Following attributes are populated: - For entire duration of the test-run: - sys_context( 'UT3_INFO', 'COVERAGE_RUN_ID' ); - Value of COVERAGE_RUN_ID used by utPLSQL internally for coverage gathering - sys_context( 'UT3_INFO', 'RUN_PATHS' ); - list of suitepaths / suitenames used as input parameters for call to ut.run(...) or ut_runner.run(...) - sys_context( 'UT3_INFO', 'SUITE_DESCRIPTION' ); - the description of test suite that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_PACKAGE' ); - the owner and name of test suite package that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_PATH' ); - the suitepath for the test suite package that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_START_TIME' ); - the execution start timestamp of test suite package that is currently being executed - sys_context( 'UT3_INFO', 'CURRENT_EXECUTABLE_NAME' ); - the owner.package.procedure of currently running test suite executable - sys_context( 'UT3_INFO', 'CURRENT_EXECUTABLE_TYPE' ); - the type of currently running test suite executable (one of: beforeall , beforeeach , beforetest , test , aftertest , aftereach , afterall When running in suite context sys_context( 'UT3_INFO', 'CONTEXT_DESCRIPTION' ); - the description of test suite context that is currently being executed sys_context( 'UT3_INFO', 'CONTEXT_NAME' ); - the name of test suite context that is currently being executed sys_context( 'UT3_INFO', 'CONTEXT_PATH' ); - the suitepath for the currently executed test suite context sys_context( 'UT3_INFO', 'CONTEXT_START_TIME' ); - the execution start timestamp for the currently executed test suite context When running a suite executable procedure that is a test or beforeeach , aftereach , beforetest , aftertest sys_context( 'UT3_INFO', 'TEST_DESCRIPTION' ); - the description of test for which the current executable is being invoked sys_context( 'UT3_INFO', 'TEST_NAME' ); - the name of test for which the current executable is being invoked sys_context( 'UT3_INFO', 'TEST_START_TIME' ); - the execution start timestamp of test that is currently being executed (the time when first beforeeach / beforetest was called for that test) Example: create or replace procedure which_procecure_called_me is begin dbms_output . put_line ( 'Currently running utPLSQL ' || sys_context ( 'ut3_info' , 'current_executable_type' ) || ' ' || sys_context ( 'ut3_info' , 'current_executable_name' ) ); end ; / create or replace package test_call is --%suite --%beforeall procedure beforeall ; --%beforeeach procedure beforeeach ; --%test procedure test1 ; --%test procedure test2 ; end ; / create or replace package body test_call is procedure beforeall is begin which_procecure_called_me (); dbms_output . put_line ( 'Current test procedure is: ' || sys_context ( 'ut3_info' , 'test_name' )); end ; procedure beforeeach is begin which_procecure_called_me (); dbms_output . put_line ( 'Current test procedure is: ' || sys_context ( 'ut3_info' , 'test_name' )); end ; procedure test1 is begin which_procecure_called_me (); ut . expect ( sys_context ( 'ut3_info' , 'suite_package' )). to_equal ( user || '.test_call' ); end ; procedure test2 is begin which_procecure_called_me (); ut . expect ( sys_context ( 'ut3_info' , 'test_name' )). to_equal ( user || '.test_call.test2' ); end ; end ; / exec ut . run ( 'test_call' ); test_call Currently running utPLSQL beforeall UT3.test_call.beforeall Current test procedure is: test1 [.008 sec] Currently running utPLSQL beforeeach UT3.test_call.beforeeach Current test procedure is: UT3.test_call.test1 Currently running utPLSQL test UT3.test_call.test1 test2 [.004 sec] Currently running utPLSQL beforeeach UT3.test_call.beforeeach Current test procedure is: UT3.test_call.test2 Currently running utPLSQL test UT3.test_call.test2 Finished in .021295 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Annotation cache \u00b6 utPLSQL needs to scan the source of package specifications to identify and parse annotations. To improve framework startup time, especially when dealing with database users owning large amounts of packages, the framework has a built-in persistent cache for annotations. The annotation cache is checked for staleness and refreshed automatically on every run. The initial startup of utPLSQL for a schema will take longer than consecutive executions. If you are in a situation where your database is controlled via CI/CD server and is refreshed/wiped before each run of your tests, consider building the annotation cache upfront and taking a snapshot of the database after the cache has been refreshed. To build the annotation cache without actually invoking any tests, call ut_runner.rebuild_annotation_cache(a_object_owner) for every unit test owner for which you want to have the annotation cache prebuilt. Example: exec ut_runner . rebuild_annotation_cache ( 'HR' ); To purge the annotation cache call ut_runner.purge_cache(a_object_owner, a_object_type) . Both parameters are optional and if not provided, all owners/object_types will be purged. Example: exec ut_runner . purge_cache ( 'HR' , 'PACKAGE' );","title":"Annotations"},{"location":"userguide/annotations.html#procedure-level-annotations","text":"Annotation placed directly before a procedure ( --%test , --%beforeall , --%beforeeach etc.). There can not be any empty lines or comments between annotation line and procedure line. There can be many annotations for a procedure. Valid procedure annotations example: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package test_package is --%suite --%test() --%disabled procedure my_first_procedure ; $ if dbms_db_version . version >= 12 $ then --This is ok - annotation before procedure --%test() procedure my_first_procedure ; $ end --A comment goes before annotations --%test() procedure my_first_procedure ; end ; Invalid procedure annotations examples: package test_package is --%suite --%test() --This is wrong as there is an empty line between procedure and annotation procedure my_first_procedure ; --%test() --This is wrong as there is a comment line between procedure and annotation procedure proc1 ; --%test() --This is wrong as there is a compiler directive between procedure and annotation $ if dbms_db_version . version >= 12 $ then procedure proc_12 ; $ end --%test() -- procedure another_proc; /* The above is wrong as the procedure is commented out and annotation is not procedure annotation anymore */ end ;","title":"Procedure level annotations"},{"location":"userguide/annotations.html#package-level-annotations","text":"Those annotations placed at any place in package except directly before procedure ( --%suite , --%suitepath etc.). We strongly recommend putting package level annotations at the very top of package except for the --%context annotations (described below) Valid package annotations example: package test_package is --%suite --%suitepath(org.utplsql.example) --%beforeall(some_package.some_procedure) --%context --%test() procedure my_first_procedure ; --%endcontext end ; Invalid package annotations examples: package test_package is --%suite --This is wrong as suite annotation is not a procedure annotation procedure irrelevant ; --%context --This is wrong as there is no empty line between package level annotation and procedure level annotation --%test() procedure my_first_procedure ; end ;","title":"Package level annotations"},{"location":"userguide/annotations.html#supported-annotations","text":"Annotation Level Description --%suite(<description>) Package Mandatory. Marks package as a test suite. Optional suite description can be provided (see displayname ). --%suitepath(<path>) Package Similar to java package. The annotation allows logical grouping of suites into hierarchies. --%displayname(<description>) Package/procedure Human-readable and meaningful description of a context/suite/test. Overrides the <description> provided with suite / test / context annotation. This annotation is redundant and might be removed in future releases. --%test(<description>) Procedure Denotes that the annotated procedure is a unit test procedure. Optional test description can be provided (see displayname ). --%throws(<exception>[,...]) Procedure Denotes that the annotated test procedure must throw one of the exceptions provided. Supported forms of exceptions are: numeric literals, numeric constant names, exception constant names, predefined Oracle exception names. --%beforeall Procedure Denotes that the annotated procedure should be executed once before all elements of the suite. --%beforeall([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed once before all elements of the suite. --%afterall Procedure Denotes that the annotated procedure should be executed once after all elements of the suite. --%afterall([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed once after all elements of the suite. --%beforeeach Procedure Denotes that the annotated procedure should be executed before each %test procedure in the suite. --%beforeeach([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed before each %test procedure in the suite. --%aftereach Procedure Denotes that the annotated procedure should be executed after each %test procedure in the suite. --%aftereach([[<owner>.]<package>.]<procedure>[,...]) Package Denotes that the mentioned procedure(s) should be executed after each %test procedure in the suite. --%beforetest([[<owner>.]<package>.]<procedure>[,...]) Procedure Denotes that mentioned procedure(s) should be executed before the annotated %test procedure. --%aftertest([[<owner>.]<package>.]<procedure>[,...]) Procedure Denotes that mentioned procedure(s) should be executed after the annotated %test procedure. --%rollback(<type>) Package/procedure Defines transaction control. Supported values: auto (default) - a savepoint is created before invocation of each \"before block\" is and a rollback to specific savepoint is issued after each \"after\" block; manual - rollback is never issued automatically. Property can be overridden for child element (test in suite) --%disabled(<reason>) Package/procedure Used to disable a suite, whole context or a test. Disabled suites/contexts/tests do not get executed, they are however marked and reported as disabled in a test run. The reason that will be displayed next to disabled tests is decided based on hierarchy suites -> context -> test --%context(<description>) Package Denotes start of a named context (sub-suite) in a suite package an optional description for context can be provided. --%name(<name>) Package Denotes name for a context. Must be placed after the context annotation and before start of nested context. --%endcontext Package Denotes end of a nested context (sub-suite) in a suite package --%tags Package/procedure Used to label a test or a suite for purpose of identification","title":"Supported annotations"},{"location":"userguide/annotations.html#suite","text":"The --%suite annotation denotes PLSQL package as a unit test suite. It accepts an optional description that will be visible when running the tests. When description is not provided, package name is displayed on report. Note Package is considered a test-suite only when package specification contains the --%suite annotation at the package level. Some annotations like --%suite , --%test and --%displayname accept parameters. The parameters for annotations need to be placed in brackets. Values for parameters should be provided without any quotation marks. If the parameters are placed without brackets or with incomplete brackets, they will be ignored. Example: --%suite(The name of suite without closing bracket Example: --%suite The name of suite without brackets Suite package without description. create or replace package test_package as --%suite end ; / exec ut . run ( 'test_package' ); test_package Finished in .002415 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Suite package with description. create or replace package test_package as --%suite(Tests for a package) end ; / exec ut . run ( 'test_package' ); Tests for a package Finished in .001646 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) When multiple --%suite annotations are specified in package, the first annotation will be used and a warning message will appear indicating duplicate annotation. create or replace package test_package as --%suite(Tests for a package) --%suite(Bad annotation) end ; / exec ut . run ( 'test_package' ); Tests for a package Warnings: 1) test_package Duplicate annotation \"--%suite\". Annotation ignored. at \"TESTS_OWNER.TEST_PACKAGE\", line 3 Finished in .003318 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 1 warning(s) When --%suite annotation is bound to procedure, it is ignored and results in package not getting recognized as test suite. create or replace package test_package as --%suite(Tests for a package) procedure some_proc ; end ; / exec ut . run ( 'test_package' ); ORA-20204: Suite package TESTS_OWNER.test_package not found ORA-06512: at \"UT3.UT_RUNNER\", line 106 ORA-06512: at \"UT3.UT\", line 115 ORA-06512: at \"UT3.UT\", line 306 ORA-06512: at \"UT3.UT\", line 364 ORA-06512: at line 1","title":"Suite"},{"location":"userguide/annotations.html#test","text":"The --%test annotation denotes procedure withing test suite as a unit test. It accepts an optional description that will be reported when the test is executed. When description is not provided, procedure name is displayed on report. If --%test raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite Test procedure without description. create or replace package test_package as --%suite(Tests for a package) --%test procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package some_test [.003 sec] Finished in .004109 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Test procedure with description. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.005 sec] Finished in .006828 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) When multiple --%test annotations are specified for a procedure, the first annotation will be used and a warning message will appear indicating duplicate annotation. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%test(Duplicate description) procedure some_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.007 sec] Warnings: 1) test_package Duplicate annotation \"--%test\". Annotation ignored. at \"TESTS_OWNER.TEST_PACKAGE.SOME_TEST\", line 5 Finished in .008815 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 1 warning(s)","title":"Test"},{"location":"userguide/annotations.html#disabled","text":"Marks annotated suite package or test procedure as disabled. You can provide the reason why the test is disabled that will be displayed in output. Disabling suite. create or replace package test_package as --%suite(Tests for a package) --%disabled(Reason for disabling suite) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [0 sec] (DISABLED - Reason for disabling suite) Description of another behavior [0 sec] (DISABLED - Reason for disabling suite) Finished in .001441 seconds 2 tests, 0 failed, 0 errored, 2 disabled, 0 warning(s) Disabling the context(s). create or replace package test_package as --%suite(Tests for a package) --%context(Context1) --%test(Description of tested behavior) procedure some_test ; --%endcontext --%context(Context2) --%disabled(Reason for disabling context2) --%test(Description of another behavior) procedure other_test ; --%endcontext end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Context1 Description of tested behavior [.002 sec] Context2 Description of another behavior [0 sec] (DISABLED - Reason for disabling context2) Finished in .005079 seconds 2 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s) Disabling individual test(s). create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) --%disabled(Reason for disabling test) procedure other_test ; end ; / create or replace package body test_package as procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.004 sec] Description of another behavior [0 sec] (DISABLED - Reason for disabling test) Finished in .005868 seconds 2 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s)","title":"Disabled"},{"location":"userguide/annotations.html#beforeall","text":"There are two possible ways to use the --%beforeall annotation. As a procedure level annotation: --%suite(Some test suite) --%beforeall procedure to_be_executed_before_all ; --%test procedure some_test ; Marks annotated procedure to be executed before all test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%beforeall(to_be_executed_before_all, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_before_all ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed before all test procedures in a suite. If --%beforeall raises an exception, suite content cannot be safely executed as the setup was not executed successfully for the suite. If --%beforeall raises an exception the following will happen: - the --%beforeall procedures that follow the failed one, will not be executed - all --%test procedures and their --%beforeeach , --%aftereach , --%beforetest and --%aftertest procedures within suite package will not be executed - all --%test procedures will be marked as failed - the --%afterall procedures will be executed - test execution will continue uninterrupted for other suite packages When multiple --%beforeall procedures are defined in a suite package, all of them will be executed before invoking any test. For multiple --%beforeall procedures order of execution is defined by annotation position in the package specification. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeall procedure setup_stuff ; end ; / create or replace package body test_package as procedure setup_stuff is begin dbms_output . put_line ( '--- SETUP_STUFF invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package --- SETUP_STUFF invoked --- Description of tested behavior [.004 sec] Description of another behavior [.003 sec] Finished in .012292 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) In the below example a combination pacakge and procedure level --%beforeall annotations is used. The order of execution of the beforeall procedures is determined by the annotation position in package. All of the --%beforeall procedures get invoked before any test is executed in a suite. create or replace package test_package as --%suite(Tests for a package) --%beforeall(initial_setup,test_package.another_setup) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeall procedure next_setup ; --%beforeall(one_more_setup) procedure another_setup ; procedure one_more_setup ; procedure initial_setup ; end ; / create or replace package body test_package as procedure one_more_setup is begin dbms_output . put_line ( '--- ONE_MORE_SETUP invoked ---' ); end ; procedure next_setup is begin dbms_output . put_line ( '--- NEXT_SETUP invoked ---' ); end ; procedure another_setup is begin dbms_output . put_line ( '--- ANOTHER_SETUP invoked ---' ); end ; procedure initial_setup is begin dbms_output . put_line ( '--- INITIAL_SETUP invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); ``` Tests for a package --- INITIAL_SETUP invoked --- --- ANOTHER_SETUP invoked --- --- NEXT_SETUP invoked --- --- ONE_MORE_SETUP invoked --- Description of tested behavior [.003 sec] Description of another behavior [.002 sec] Finished in .018944 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) ``` When multiple --%beforeall annotations are specified for a procedure, the first annotation will be used and a warning message will appear indicating duplicate annotation. When procedure is annotated as both --%beforeall and --%test , the procedure will become a test and a warning message will appear indicating invalid annotation combination. create or replace package test_package as --%suite(Tests for a package) --%beforeall --%beforeall procedure initial_setup ; --%test(Description of tested behavior) --%beforeall procedure some_test ; --%test(Description of another behavior) procedure other_test ; end ; / create or replace package body test_package as procedure initial_setup is begin dbms_output . put_line ( '--- INITIAL_SETUP invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); ``` Tests for a package --- INITIAL_SETUP invoked --- Description of tested behavior [.003 sec] Description of another behavior [.004 sec] Warnings: 1) test_package Duplicate annotation \"--%beforeall\". Annotation ignored. at \"UT3_TESTER.TEST_PACKAGE.INITIAL_SETUP\", line 5 2) test_package Annotation \"--%beforeall\" cannot be used with annotation: \"--%test\" at \"UT3_TESTER.TEST_PACKAGE.SOME_TEST\", line 9 Finished in .012158 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 2 warning(s) ```","title":"Beforeall"},{"location":"userguide/annotations.html#afterall","text":"There are two possible ways to use the --%afterall annotation. As a procedure level annotation: --%suite(Some test suite) --%afterall procedure to_be_executed_after_all ; --%test procedure some_test ; Marks annotated procedure to be executed after all test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%afterall(to_be_executed_after_all, other_package.some_cleanup) --%test procedure some_test ; procedure to_be_executed_after_all ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed after all test procedures in a suite. If --%afterall raises an exception the following will happen: - a warning will be raised, indicating that --%afterall procedure has failed - execution will continue uninterrupted for rest of the suite If --%afterall raises an exception, it can have negative impact on other tests, as the environment was not cleaned-up after the tests. This however doesn't have direct impact on test execution within current suite, as the tests are already complete by the time --%afterall is called. When multiple --%afterall procedures are defined in a suite, all of them will be executed after invoking all tests from the suite. For multiple --%afterall procedures order of execution is defined by annotation position in the package specification. All rules defined for --%beforeall also apply for --%afterall annotation. See beforeall for more details. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%afterall procedure cleanup_stuff ; end ; / create or replace package body test_package as procedure cleanup_stuff is begin dbms_output . put_line ( '---CLEANUP_STUFF invoked ---' ); end ; procedure some_test is begin null ; end ; procedure other_test is begin null ; end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.003 sec] Description of another behavior [.005 sec] ---CLEANUP_STUFF invoked --- Finished in .014161 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Afterall"},{"location":"userguide/annotations.html#beforeeach","text":"The procedure annotated as --%beforeeach is getting executed before each test in a suite. That means that the procedure will be executed as many times as there are test in suite package. There are two possible ways to use the --%beforeeach annotation. As a procedure level annotation: --%suite(Some test suite) --%beforeeach procedure to_be_executed_before_each ; --%test procedure some_test ; Marks annotated procedure to be executed before each test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%beforeeach(to_be_executed_before_each, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_before_each ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed before each test procedure in a suite. If a test is marked as disabled the --%beforeeach procedure is not invoked for that test. If --%beforeeach raises an unhandled exception the following will happen: - the following --%beforeeach as well as all --%beforetest for that test will not be executed - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite As a rule, the --%beforeeach execution gets aborted if preceding --%beforeeach failed. When multiple --%beforeeach procedures are defined in a suite, all of them will be executed before invoking each test. For multiple --%beforeeach procedures order of execution is defined by annotation position in the package specification. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%beforeeach procedure setup_for_test ; --%beforeall procedure setup_stuff ; end ; / create or replace package body test_package as procedure setup_stuff is begin dbms_output . put_line ( '---SETUP_STUFF invoked ---' ); end ; procedure setup_for_test is begin dbms_output . put_line ( '---SETUP_FOR_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package ---SETUP_STUFF invoked --- Description of tested behavior [.004 sec] ---SETUP_FOR_TEST invoked --- ---SOME_TEST invoked --- Description of another behavior [.006 sec] ---SETUP_FOR_TEST invoked --- ---OTHER_TEST invoked --- Finished in .014683 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) See beforeall for more examples.","title":"Beforeeach"},{"location":"userguide/annotations.html#aftereach","text":"Marks annotated procedure to be executed after each test procedure in a suite. The procedure annotated as --%aftereach is getting executed after each test in a suite. That means that the procedure will be executed as many times as there are test in suite package. There are two possible ways to use the --%aftereach annotation. As a procedure level annotation: --%suite(Some test suite) --%aftereach procedure to_be_executed_after_each ; --%test procedure some_test ; Marks annotated procedure to be executed after each test procedures in a suite. As a package level annotation (not associated with any procedure). --%suite(Some test suite) --%aftereach(to_be_executed_after_each, other_package.some_setup) --%test procedure some_test ; procedure to_be_executed_after_each ; Indicates that the procedure(s) mentioned as the annotation parameter are to be executed after each test procedure in a suite. If a test is marked as disabled the --%aftereach procedure is not invoked for that test. If --%aftereach raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%aftereach procedures are defined in a suite, all of them will be executed after invoking each test. For multiple --%aftereach procedures order of execution is defined by the annotation position in the package specification. As a rule, the --%aftereach gets executed even if the associated --%beforeeach , --%beforetest , --%test or other --%aftereach procedures have raised unhandled exceptions. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) procedure some_test ; --%test(Description of another behavior) procedure other_test ; --%aftereach procedure cleanup_for_test ; --%afterall procedure cleanup_stuff ; end ; / create or replace package body test_package as procedure cleanup_stuff is begin dbms_output . put_line ( '---CLEANUP_STUFF invoked ---' ); end ; procedure cleanup_for_test is begin dbms_output . put_line ( '---CLEANUP_FOR_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.006 sec] ---SOME_TEST invoked --- ---CLEANUP_FOR_TEST invoked --- Description of another behavior [.006 sec] ---OTHER_TEST invoked --- ---CLEANUP_FOR_TEST invoked --- ---CLEANUP_STUFF invoked --- Finished in .018115 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) See beforeall for more examples.","title":"Aftereach"},{"location":"userguide/annotations.html#beforetest","text":"Indicates specific setup procedure(s) to be executed for a test. The procedure(s) can be located either: - within current package (package name is optional) - within another package The annotation need to be placed alongside --%test annotation. The --%beforetest procedures are executed after invoking all --%beforeeach for a test. If a test is marked as disabled the --%beforetest procedures are not invoked for that test. If --%beforetest raises an unhandled exception the following will happen: - the following --%beforetest for that test will not be executed - the test will be marked as errored and exception stack trace will be captured and reported - the --%aftertest , --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%beforetest procedures are defined for a test, all of them will be executed before invoking the test. The order of execution for --%beforetest procedures is defined by: - position of procedure on the list within single annotation - annotation position As a rule, the --%beforetest execution gets aborted if preceding --%beforeeach or --%beforetest failed. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%beforetest(test_package.setup_for_a_test) --%beforetest(another_setup_for_a_test) procedure some_test ; --%test(Description of another behavior) --%beforetest(test_package.setup_for_a_test, another_setup_for_a_test) procedure other_test ; procedure another_setup_for_a_test ; procedure setup_for_a_test ; end ; / create or replace package body test_package as procedure setup_for_a_test is begin dbms_output . put_line ( '---SETUP_FOR_A_TEST invoked ---' ); end ; procedure another_setup_for_a_test is begin dbms_output . put_line ( '---ANOTHER_SETUP_FOR_A_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.008 sec] ---SETUP_FOR_A_TEST invoked --- ---ANOTHER_SETUP_FOR_A_TEST invoked --- ---SOME_TEST invoked --- Description of another behavior [.005 sec] ---SETUP_FOR_A_TEST invoked --- ---ANOTHER_SETUP_FOR_A_TEST invoked --- ---OTHER_TEST invoked --- Finished in .015185 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Beforetest"},{"location":"userguide/annotations.html#aftertest","text":"Indicates specific cleanup procedure(s) to be executed for a test. The procedure(s) can be located either: - within current package (package name is optional) - within another package The annotation need to be placed alongside --%test annotation. If a test is marked as disabled the --%aftertest procedures are not invoked for that test. If --%aftertest raises an unhandled exception the following will happen: - the test will be marked as errored and exception stack trace will be captured and reported - the following --%aftertest and all --%aftereach procedures will be executed for the errored test - the --%afterall procedures will be executed - test execution will continue uninterrupted for rest of the suite When multiple --%aftertest procedures are defined for a test, all of them will be executed after invoking the test. The order of execution for --%aftertest procedures is defined by: - position of procedure on the list within single annotation - annotation position As a rule, the --%aftertest gets executed even if the associated --%beforeeach , --%beforetest , --%test or other --%aftertest procedures have raised unhandled exceptions. create or replace package test_package as --%suite(Tests for a package) --%test(Description of tested behavior) --%aftertest(test_package.cleanup_for_a_test) --%aftertest(another_cleanup_for_a_test) procedure some_test ; --%test(Description of another behavior) --%aftertest(test_package.cleanup_for_a_test, another_cleanup_for_a_test) procedure other_test ; procedure another_cleanup_for_a_test ; procedure cleanup_for_a_test ; end ; / create or replace package body test_package as procedure cleanup_for_a_test is begin dbms_output . put_line ( '---CLEANUP_FOR_A_TEST invoked ---' ); end ; procedure another_cleanup_for_a_test is begin dbms_output . put_line ( '---ANOTHER_CLEANUP_FOR_A_TEST invoked ---' ); end ; procedure some_test is begin dbms_output . put_line ( '---SOME_TEST invoked ---' ); end ; procedure other_test is begin dbms_output . put_line ( '---OTHER_TEST invoked ---' ); end ; end ; / exec ut . run ( 'test_package' ); Tests for a package Description of tested behavior [.008 sec] ---SOME_TEST invoked --- ---CLEANUP_FOR_A_TEST invoked --- ---ANOTHER_CLEANUP_FOR_A_TEST invoked --- Description of another behavior [.006 sec] ---OTHER_TEST invoked --- ---CLEANUP_FOR_A_TEST invoked --- ---ANOTHER_CLEANUP_FOR_A_TEST invoked --- Finished in .016873 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Aftertest"},{"location":"userguide/annotations.html#context","text":"In most of the cases, the code to be tested is consisting of PLSQL packages containing procedures and functions. When creating test suites, it's quite common to maintain one to one relationship between test suite packages and tested code. When it comes to test procedures themselves, it is best practice to have one test procedure for one tested behavior of the code that is tested. The relationship between test procedure and tested code will be therefore many to one or many to many in most of the cases. With this comes a challenge. How to group tests, related to one tested behavior, so that it is obvious that they relate to the same thing. This is where utPLSQL contexts come handy. Contexts allow for creating sub-suites within a suite package and they allow for grouping of tests that are somehow related. In essence, context behaves like a suite within a suite. Context have following characteristics: - context starts with the --%context annotation and ends with --%endcontext . Everything placed between those two annotations belongs to that context - can have a description provided as parameter for example --%context(Some interesting stuff) . - can have a name provided with --%name annotation. This is different than with suite and test annotations, where name is taken from package/procedure name. - contexts can be nested, you can place a context inside another context - when no name is provided for context, the context is named context_N where N is the number of the context in suite or parent context. - context name must be unique within it's parent (suite / parent context) - if context name is not unique within it's parent, context and it's entire content is excluded from execution - context name should not contain spaces or special characters - context name cannot contain a . (full stop/period) character - suite/context can have multiple nested sibling contexts in it - contexts can have their own --%beforeall , --%beforeeach , --%afterall and --%aftereach procedures - --%beforeall , --%beforeeach , --%afterall and --%aftereach procedures defined at ancestor level, propagate to context - if --%endcontext is missing for a context, the context spans to the end of package specification The below example illustrates usage of --%context for separating tests for individual procedures of package. Sample tables and code create table rooms ( room_key number primary key , name varchar2 ( 100 ) not null ); create table room_contents ( contents_key number primary key , room_key number not null , name varchar2 ( 100 ) not null , create_date timestamp default current_timestamp not null , constraint fk_rooms foreign key ( room_key ) references rooms ( room_key ) ); create or replace package rooms_management is procedure remove_rooms_by_name ( a_name rooms . name % type ); procedure add_rooms_content ( a_room_name rooms . name % type , a_content_name room_contents . name % type ); end ; / create or replace package body rooms_management is procedure remove_rooms_by_name ( a_name rooms . name % type ) is begin if a_name is null then raise program_error ; end if ; delete from rooms where name like a_name ; end ; procedure add_rooms_content ( a_room_name rooms . name % type , a_content_name room_contents . name % type ) is l_room_key rooms . room_key % type ; begin select room_key into l_room_key from rooms where name = a_room_name ; insert into room_contents ( contents_key , room_key , name ) select nvl ( max ( contents_key ) + 1 , 1 ) as contents_key , l_room_key , a_content_name from room_contents ; end ; end ; / Below test suite defines: - --%beforeall outside of context, that will be executed before all tests - --%context(remove_rooms_by_name) to group tests related to remove_rooms_by_name functionality - --%context(add_rooms_content) to group tests related to add_rooms_content functionality create or replace package test_rooms_management is gc_null_value_exception constant integer : = - 1400 ; --%suite(Rooms management) --%beforeall procedure setup_rooms ; --%context(remove_rooms_by_name) --%displayname(Remove rooms by name) --%test(Removes a room without content in it) procedure remove_empty_room ; --%test(Raises exception when null room name given) --%throws(-6501) procedure null_room_name ; --%endcontext --%context(add_rooms_content) --%displayname(Add content to a room) --%test(Fails when room name is not valid) --%throws(no_data_found) procedure fails_on_room_name_invalid ; --%test(Fails when content name is null) --%throws(test_rooms_management.gc_null_value_exception) procedure fails_on_content_null ; --%test(Adds a content to existing room) procedure add_content_success ; --%endcontext end ; / create or replace package body test_rooms_management is procedure setup_rooms is begin insert all into rooms values ( 1 , 'Dining Room' ) into rooms values ( 2 , 'Living Room' ) into rooms values ( 3 , 'Bathroom' ) select 1 from dual ; insert all into room_contents values ( 1 , 1 , 'Table' , sysdate ) into room_contents values ( 3 , 1 , 'Chair' , sysdate ) into room_contents values ( 4 , 2 , 'Sofa' , sysdate ) into room_contents values ( 5 , 2 , 'Lamp' , sysdate ) select 1 from dual ; dbms_output . put_line ( '---SETUP_ROOMS invoked ---' ); end ; procedure remove_empty_room is l_rooms_not_named_b sys_refcursor ; l_remaining_rooms sys_refcursor ; begin open l_rooms_not_named_b for select * from rooms where name not like 'B%' ; rooms_management . remove_rooms_by_name ( 'B%' ); open l_remaining_rooms for select * from rooms ; ut . expect ( l_remaining_rooms ). to_equal ( l_rooms_not_named_b ); end ; procedure room_with_content is begin rooms_management . remove_rooms_by_name ( 'Living Room' ); end ; procedure null_room_name is begin --Act rooms_management . remove_rooms_by_name ( NULL ); --Assert done by --%throws annotation end ; procedure fails_on_room_name_invalid is begin --Act rooms_management . add_rooms_content ( 'bad room name' , 'Chair' ); --Assert done by --%throws annotation end ; procedure fails_on_content_null is begin --Act rooms_management . add_rooms_content ( 'Dining Room' , null ); --Assert done by --%throws annotation end ; procedure add_content_success is l_expected room_contents . name % type ; l_actual room_contents . name % type ; begin --Arrange l_expected : = 'Table' ; --Act rooms_management . add_rooms_content ( 'Dining Room' , l_expected ); --Assert select name into l_actual from room_contents where contents_key = ( select max ( contents_key ) from room_contents ); ut . expect ( l_actual ). to_equal ( l_expected ); end ; end ; / When te tests are executed exec ut . run ( 'test_rooms_management' ); The following report is displayed Rooms management ---SETUP_ROOMS invoked --- remove_rooms_by_name Removes a room without content in it [.015 sec] Raises exception when null room name given [.002 sec] add_rooms_content Fails when room name is not valid [.003 sec] Fails when content name is null [.003 sec] Adds a content to existing room [.003 sec] Finished in .035261 seconds 5 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Example of nested contexts test suite specification. Source - slide 145 of Structure and Interpretation of Test Cases by Kevlin Henney create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%test(Is empty) procedure is_empty ; --%test(Preserves positive bounding capacity) procedure positive_bounding_capacity ; --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%test(Dequeues an empty value) procedure deq_empty_value ; --%test(Remains empty when null enqueued) procedure empty_with_null_enq ; --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%context(that is not full) --%test(Becomes longer when non null value enqueued) procedure grow_on_enq_non_null ; --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%test(Ignores further enqueued values) procedure full_ignore_enq ; --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%test(Dequeues values in order enqueued) procedure dequeue_ordered ; --%test(Remains unchanged when null enqueued) procedure no_change_on_null_enq ; --%endcontext end ; When such specification gets executed ut.run('queue_spec'') (without body created) you will see the nesting of tests within contexts. Queue specification An empty queue Dequeues an empty value [.014 sec] (FAILED - 1) Remains empty when null enqueued [.004 sec] (FAILED - 2) Becomes non empty when non null value enqueued [.005 sec] (FAILED - 3) A non empty queue that is not full Becomes longer when non null value enqueued [.005 sec] (FAILED - 4) Becomes full when enqueued up to capacity [.005 sec] (FAILED - 5) That is full Ignores further enqueued values [.004 sec] (FAILED - 6) Becomes non full when dequeued [.005 sec] (FAILED - 7) Dequeues values in order enqueued [.006 sec] (FAILED - 8) Remains unchanged when null enqueued [.004 sec] (FAILED - 9) A new queue Is empty [.007 sec] (FAILED - 10) Preserves positive bounding capacity [.006 sec] (FAILED - 11) Cannot be created with non positive bounding capacity [.005 sec] (FAILED - 12) Failures: 1) deq_empty_value ORA-04067: not executed, package body \"UT3.QUEUE_SPEC\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3.QUEUE_SPEC\" ORA-06512: at line 6 ... Finished in .088573 seconds 12 tests, 0 failed, 12 errored, 0 disabled, 0 warning(s) Suite nesting allows for organizing tests into human-readable specification of behavior.","title":"Context"},{"location":"userguide/annotations.html#name","text":"The --%name annotation is currently only used only for naming a context. If a context doesn't have explicit name specified, then the name is given automatically by framework. The automatic name will be context_#n where n is a context number within a suite/parent context. The --%name can be useful when you would like to run only a specific context or its items by suitepath . Consider the below example. create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%context(that is not full) --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%endcontext end ; In the above code, suitepaths, context names and context descriptions will be as follows. suitepath description name queue_spec Queue specification queue_spec queue_spec.context_#1 A new queue context_#1 queue_spec.context_#2 An empty queue context_#2 queue_spec.context_#3 A non empty queue context_#3 queue_spec.context_#3.context_#1 that is not full context_#1 queue_spec.context_#3.context_#2 that is full context_#2 In order to run only the tests for the context A non empty queue that is not full you will need to call utPLSQL as below: exec ut . run ( ':queue_spec.context_#3.context_#1' ); You can use --%name annotation to explicitly name contexts on suitepath. create or replace package queue_spec as --%suite(Queue specification) --%context(A new queue) --%name(a_new_queue) --%test(Cannot be created with non positive bounding capacity) procedure non_positive_bounding_cap ; --%endcontext --%context(An empty queue) --%name(an_empty_queue) --%test(Becomes non empty when non null value enqueued) procedure non_empty_after_enq ; --%endcontext --%context(A non empty queue) --%name(a_non_empty_queue) --%context(that is not full) --%name(that_is_not_full) --%test(Becomes full when enqueued up to capacity) procedure full_on_enq_to_cap ; --%endcontext --%context(that is full) --%name(that_is_full) --%test(Becomes non full when dequeued) procedure non_full_on_deq ; --%endcontext --%endcontext end ; In the above code, suitepaths, context names and context descriptions will be as follows. suitepath description name queue_spec Queue specification queue_spec queue_spec.a_new_queue A new queue a_new_queue queue_spec.an_empty_queue An empty queue an_empty_queue queue_spec.a_non_empty_queue A non empty queue a_non_empty_queue queue_spec.a_non_empty_queue.that_is_not_full that is not full that_is_not_full queue_spec.a_non_empty_queue.that_is_full that is full that_is_full The --%name annotation is only relevant for: - running subsets of tests by given context suitepath - some of test reports, like ut_junit_reporter that use suitepath or test-suite element names (not descriptions) for reporting","title":"Name"},{"location":"userguide/annotations.html#name-naming-convention","text":"The value of --%name annotation must follow the following naming rules: - cannot contain spaces - cannot contain a . (full stop/dot) - is case-insensitive","title":"Name naming convention"},{"location":"userguide/annotations.html#tags","text":"Tag is a label attached to the test or a suite. It is used for identification and execution of a group of tests / suites that share the same tag. It allows for grouping of tests / suites using various categorization and place tests / suites in multiple buckets. Same tests can be grouped with other tests based on the functionality , frequency, type of output etc. e.g. --%tags(batch,daily,csv) or --%tags(online,json) --%tags(api) Tags are defined as a comma separated list within the --%tags annotation. When executing a test run with tag filter applied, the framework will find all tests associated with the given tags and execute them. The framework applies OR logic to all specified tags so any test / suite that matches at least one tag will be included in the test run. When a suite/context is tagged, all of its children will automatically inherit the tag and get executed along with the parent. Parent suite tests are not executed, but a suitepath hierarchy is kept. Sample test suite package with tags. create or replace package ut_sample_test is --%suite(Sample Test Suite) --%tags(api) --%test(Compare Ref Cursors) --%tags(complex,fast) procedure ut_refcursors1 ; --%test(Run equality test) --%tags(simple,fast) procedure ut_test ; end ut_sample_test ; / create or replace package body ut_sample_test is procedure ut_refcursors1 is v_actual sys_refcursor ; v_expected sys_refcursor ; begin open v_expected for select 1 as test from dual ; open v_actual for select 2 as test from dual ; ut . expect ( v_actual ). to_equal ( v_expected ); end ; procedure ut_test is begin ut . expect ( 1 ). to_equal ( 0 ); end ; end ut_sample_test ; / Execution of the test is done by using the parameter a_tags select * from table ( ut . run ( a_path => 'ut_sample_test' , a_tags => 'api' )); The above call will execute all tests from ut_sample_test package as the whole suite is tagged with api select * from table ( ut . run ( a_tags => 'complex' )); The above call will execute only the ut_sample_test.ut_refcursors1 test, as only the test ut_refcursors1 is tagged with complex select * from table ( ut . run ( a_tags => 'fast' )); The above call will execute both ut_sample_test.ut_refcursors1 and ut_sample_test.ut_test tests, as both tests are tagged with fast","title":"Tags"},{"location":"userguide/annotations.html#tag-naming-convention","text":"Tags must follow the below naming convention: tag is case sensitive tag can contain special characters like $#/\\?-! etc. tag cannot be an empty string tag cannot start with a dash, e.g. -some-stuff is not a valid tag tag cannot contain spaces, e.g. test of batch . To create a multi-word tag use underscores or dashes, e.g. test_of_batch , test-of-batch leading and trailing spaces are ignored in tag name, e.g. --%tags( tag1 , tag2 ) becomes tag1 and tag2 tag names","title":"Tag naming convention"},{"location":"userguide/annotations.html#excluding-testssuites-by-tags","text":"It is possible to exclude parts of test suites with tags. In order to do so, prefix the tag name to exclude with a - (dash) sign when invoking the test run. Examples (based on above sample test suite) select * from table ( ut . run ( a_tags => 'api,fast,-complex' )); The above call will execute all suites/contexts/tests that are marked with any of tags api or fast except those suites/contexts/tests that are marked as complex . Given the above example package ut_sample_test , only ut_sample_test.ut_test will be executed.","title":"Excluding tests/suites by tags"},{"location":"userguide/annotations.html#suitepath","text":"It is very likely that the application for which you are going to introduce tests consists of many different packages, procedures and functions. Usually procedures can be logically grouped inside a package, there also might be several logical groups of procedures in a single package and packages might be grouped into modules and modules into subject areas. As your project grows, the codebase will grow to. utPLSQL allows you to group packages into modules and also allows for nesting modules. Let's say you have a complex insurance application that deals with policies, claims and payments. The payment module contains several packages for payment recognition, charging, planning etc. The payment recognition module among others contains a complex recognize_payment procedure that associates received money to the policies. If you want to create tests for your application it is recommended to structure your tests similarly to the logical structure of your application. So you end up with something like: * Integration tests * Policy tests * Claim tests * Payment tests * Payments recognition * Payments set off The --%suitepath annotation is used for such grouping. Even though test packages are defined in a flat structure the --%suitepath is used by the framework to form them into a hierarchical structure. Your payments recognition test package might look like: create or replace package test_payment_recognition as --%suite(Payment recognition tests) --%suitepath(payments) --%test(Recognize payment by policy number) procedure test_recognize_by_num ; --%test(Recognize payment by payment purpose) procedure test_recognize_by_purpose ; --%test(Recognize payment by customer) procedure test_recognize_by_customer ; end test_payment_recognition ; And payments set off test package: create or replace package test_payment_set_off as --%suite(Payment set off tests) --%suitepath(payments) --%test(Creates set off) procedure test_create_set_off ; --%test(Cancels set off) procedure test_cancel_set_off ; end test_payment_set_off ; When you execute tests for your application, the framework constructs a test suite for each test package. Then it combines suites into grouping suites by the --%suitepath annotation value so that the fully qualified path to the recognize_by_num procedure is USER:payments.test_payment_recognition.test_recognize_by_num . If any of its expectations fails then the test is marked as failed, also the test_payment_recognition suite, the parent suite payments and the whole run is marked as failed. The test report indicates which expectation has failed on the payments module. The payments recognition submodule is causing the failure as recognize_by_num has not met the expectations of the test. Grouping tests into modules and submodules using the --%suitepath annotation allows you to logically organize your project's flat structure of packages into functional groups. An additional advantage of such grouping is the fact that every element level of the grouping can be an actual unit test package containing a common module level setup for all of the submodules. So in addition to the packages mentioned above you could have the following package. create or replace package payments as --%suite(Payments) --%beforeall procedure set_common_payments_data ; --%afterall procedure reset_common_paymnets_data ; end payments ; When executing tests, path for executing tests can be provided in three ways: * schema - execute all tests in the schema * [schema]:suite1[.suite2][.suite3]...[.procedure] - execute all tests by suitepath in all suites on path suite1[.suite2][.suite3]...[.procedure]. If schema is not provided, then the current schema is used. Example: :all.rooms_tests * [schema.]package[.procedure] - execute all tests in the specified test package. The whole hierarchy of suites in the schema is built before all before/after hooks or part suites for the provided suite package are executed as well. Example: tests.test_contact.test_last_name_validator or simply test_contact.test_last_name_validator if tests is the current schema.","title":"Suitepath"},{"location":"userguide/annotations.html#rollback","text":"By default, changes performed by every setup, cleanup and test procedure are isolated by savepoints. This solution is suitable for use-cases where the code that is being tested as well as the unit tests themselves do not use transaction control (commit/rollback) or DDL commands. In general, your unit tests should not use transaction control as long as the code you are testing is not using it too. Keeping the transactions uncommitted allows your changes to be isolated and the execution of tests does not impact others who might be using a shared development database. If you are in a situation where the code you are testing uses transaction control (common case with ETL code), then your tests probably should not use the default automatic transaction control. In that case use the annotation --%rollback(manual) on the suite level to disable automatic transaction control for the entire suite. If you are using nested suites, you need to make sure that the entire suite all the way to the root is using manual transaction control. It is possible with utPLSQL to change the transaction control on individual suites or tests that are part of complex suite. It is strongly recommended not to have mixed transaction control in a suite. Mixed transaction control settings will not work properly when your suites are using shared setup/cleanup with beforeall, afterall, beforeeach or aftereach annotations. Your suite will most likely fail with error or warning on execution. Some of the automatic rollbacks will probably fail to execute depending on the configuration you have. In some cases it is necessary to perform DDL as part of setup or cleanup for the tests. It is recommended to move such DDL statements to a procedure with pragma autonomous_transaction to eliminate implicit commits in the main session that is executing all your tests. Doing so allows your tests to use the framework's automatic transaction control and releases you from the burden of manual cleanup of data that was created or modified by test execution. When you are testing code that performs explicit or implicit commits, you may set the test procedure to run as an autonomous transaction with pragma autonomous_transaction . Keep in mind that when your test runs as autonomous transaction it will not see the data prepared in a setup procedure unless the setup procedure committed the changes. Note The --%suitepath annotation, when used, must be provided with a value of path. The path in suitepath cannot contain spaces. Dot (.) identifies individual elements of the path. Example: --%suitepath(org.utplsql.core.utils)","title":"Rollback"},{"location":"userguide/annotations.html#throws","text":"The --%throws annotation allows you to specify a list of exceptions as one of: - number literals - example --%throws(-20134) - variables of type exception defined in a package specification - example --%throws(exc_pkg.c_exception_No_variable) - variables of type number defined in a package specification - example --%throws(exc_pkg.c_some_exception) - predefined oracle exceptions - example --%throws(no_data_found) The annotation is ignored, when no valid arguments are provided. Examples of invalid annotations --%throws() , --%throws , --%throws(abe, 723pf) . If --%throws annotation is specified with arguments and no exception is raised, the test is marked as failed. If --%throws annotation is specified with arguments and exception raised is not on the list of provided exceptions, the test is marked as failed. The framework will raise a warning, when --%throws annotation has invalid arguments or when no arguments were provided. Annotation --%throws(7894562, operaqk, -=1, -20496, pow74d, posdfk3) will be interpreted as --%throws(-20496) . Please note that NO_DATA_FOUND exception is a special case in Oracle. To capture it use NO_DATA_FOUND named exception or -1403 exception No. \u200b Example: create or replace package exc_pkg is c_e_option1 constant number : = - 20200 ; c_e_option2 constant varchar2 ( 10 ) : = '-20201' ; c_e_option3 number : = - 20202 ; e_option4 exception ; pragma exception_init ( e_option4 , - 20203 ); end ; / create or replace package example_pgk as --%suite(Example Throws Annotation) --%test(Throws one of the listed exceptions) --%throws(-20145,bad,-20146, -20189 ,-20563) procedure raised_one_listed_exception ; --%test(Throws different exception than expected) --%throws(-20144) procedure raised_different_exception ; --%test(Throws different exception than listed) --%throws(-20144,-00001,-20145) procedure raised_unlisted_exception ; --%test(Gives failure when an exception is expected and nothing is thrown) --%throws(-20459, -20136, -20145) procedure nothing_thrown ; --%test(Throws package exception option1) --%throws(exc_pkg.c_e_option1) procedure raised_option1_exception ; --%test(Throws package exception option2) --%throws(exc_pkg.c_e_option2) procedure raised_option2_exception ; --%test(Throws package exception option3) --%throws(exc_pkg.c_e_option3) procedure raised_option3_exception ; --%test(Throws package exception option4) --%throws(exc_pkg.e_option4) procedure raised_option4_exception ; --%test(Raise name exception) --%throws(DUP_VAL_ON_INDEX) procedure raise_named_exc ; --%test(Invalid throws annotation) --%throws procedure bad_throws_annotation ; end ; / create or replace package body example_pgk is procedure raised_one_listed_exception is begin raise_application_error ( - 20189 , 'Test error' ); end ; procedure raised_different_exception is begin raise_application_error ( - 20143 , 'Test error' ); end ; procedure raised_unlisted_exception is begin raise_application_error ( - 20143 , 'Test error' ); end ; procedure nothing_thrown is begin ut . expect ( 1 ). to_equal ( 1 ); end ; procedure raised_option1_exception is begin raise_application_error ( exc_pkg . c_e_option1 , 'Test error' ); end ; procedure raised_option2_exception is begin raise_application_error ( exc_pkg . c_e_option2 , 'Test error' ); end ; procedure raised_option3_exception is begin raise_application_error ( exc_pkg . c_e_option3 , 'Test error' ); end ; procedure raised_option4_exception is begin raise exc_pkg . e_option4 ; end ; procedure raise_named_exc is begin raise DUP_VAL_ON_INDEX ; end ; procedure bad_throws_annotation is begin null ; end ; end ; / exec ut3 . ut . run ( 'example_pgk' ); Running the test will give report: Example Throws Annotation Throws one of the listed exceptions [.002 sec] Throws different exception than expected [.002 sec] (FAILED - 1) Throws different exception than listed [.003 sec] (FAILED - 2) Gives failure when an exception is expected and nothing is thrown [.002 sec] (FAILED - 3) Throws package exception option1 [.003 sec] Throws package exception option2 [.002 sec] Throws package exception option3 [.002 sec] Throws package exception option4 [.002 sec] Raise name exception [.002 sec] Invalid throws annotation [.002 sec] Failures: 1) raised_different_exception Actual: -20143 was expected to equal: -20144 ORA-20143: Test error ORA-06512: at \"UT3.EXAMPLE_PGK\", line 9 ORA-06512: at \"UT3.EXAMPLE_PGK\", line 9 ORA-06512: at line 6 2) raised_unlisted_exception Actual: -20143 was expected to be one of: (-20144, -1, -20145) ORA-20143: Test error ORA-06512: at \"UT3.EXAMPLE_PGK\", line 14 ORA-06512: at \"UT3.EXAMPLE_PGK\", line 14 ORA-06512: at line 6 3) nothing_thrown Expected one of exceptions (-20459, -20136, -20145) but nothing was raised. Warnings: 1) example_pgk Invalid parameter value \"bad\" for \"--%throws\" annotation. Parameter ignored. at \"UT3.EXAMPLE_PGK.RAISED_ONE_LISTED_EXCEPTION\", line 6 2) example_pgk \"--%throws\" annotation requires a parameter. Annotation ignored. at \"UT3.EXAMPLE_PGK.BAD_THROWS_ANNOTATION\", line 42 Finished in .025784 seconds 10 tests, 3 failed, 0 errored, 0 disabled, 2 warning(s)","title":"Throws"},{"location":"userguide/annotations.html#order-of-execution","text":"create or replace package test_employee_pkg is --%suite(Employee management) --%suitepath(com.my_company.hr) --%rollback(auto) --%beforeall procedure setup_employees ; --%beforeall procedure setup_departments ; --%afterall procedure cleanup_log_table ; --%context(add_employee) --%beforeeach procedure setup_for_add_employees ; --%test(Raises exception when employee already exists) --%throws(-20145) procedure add_existing_employee ; --%test(Inserts employee to emp table) procedure add_employee ; --%endcontext --%context(remove_employee) --%beforeall procedure setup_for_remove_employee ; --%test(Removed employee from emp table) procedure del_employee ; --%endcontext --%test(Test without context) --%beforetest(setup_another_test) --%aftertest(cleanup_another_test) procedure some_test ; --%test(Name of test) --%disabled procedure disabled_test ; --%test(Name of test) --%rollback(manual) procedure no_transaction_control_test ; procedure setup_another_test ; procedure cleanup_another_test ; --%beforeeach procedure set_session_context ; --%aftereach procedure cleanup_session_context ; end test_employee_pkg ; When processing the test suite test_employee_pkg defined in Example of annotated test package , the order of execution will be as follows. create a savepoint 'before-suite' execute setup_employees (--%beforeall) execute setup_departments (--%beforeall) create a savepoint 'before-context' create savepoint 'before-test' execute test_setup (--%beforeeach) execute setup_for_add_employees (--%beforeeach from context) execute add_existing_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' create savepoint 'before-test' (--%suite) execute test_setup (--%beforeeach) execute setup_for_add_employees (--%beforeeach from context) execute add_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' rollback to savepoint 'before-context' create a savepoint 'before-context' execute setup_for_remove_employee (--%beforeall from context) create savepoint 'before-test' execute test_setup (--%beforeeach) execute add_existing_employee (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' rollback to savepoint 'before-context' create savepoint 'before-test' execute test_setup (--%beforeeach) execute some_test (--%test) execute test_cleanup (--%aftereach) rollback to savepoint 'before-test' create savepoint 'before-test' execute test_setup (--%beforeeach) execute setup_another_test (--%beforetest) execute another_test (--%test) execute cleanup_another_test (--%aftertest) execute test_cleanup (--%beforeeach) rollback to savepoint 'before-test' mark disabled_test as disabled (--%test --%disabled) execute test_setup (--%beforeeach) execute no_transaction_control_test (--%test) execute test_cleanup (--%aftertest) execute global_cleanup (--%afterall) rollback to savepoint 'before-suite' Note utPLSQL does not guarantee ordering of tests in suite. On contrary utPLSQL might give random order of tests/contexts in suite. Order of execution within multiple occurrences of before / after procedures is determined by the order of annotations in specific block (context/suite) of package specification.","title":"Order of execution"},{"location":"userguide/annotations.html#sys_context","text":"It is possible to access information about currently running suite. The information is available by calling sys_context( 'UT3_INFO', attribute ) . It can be accessed from any procecure invoked as part of utPLSQL test execution. Note: Context name is derived from schema name where utPLSQL is installed. The context name in below examples represents the default install schema -> UT3 If you install utPLSQL into another schema the context name will be different. For example if utPLSQL is installed into HR schema, the context name will be HR_INFO Following attributes are populated: - For entire duration of the test-run: - sys_context( 'UT3_INFO', 'COVERAGE_RUN_ID' ); - Value of COVERAGE_RUN_ID used by utPLSQL internally for coverage gathering - sys_context( 'UT3_INFO', 'RUN_PATHS' ); - list of suitepaths / suitenames used as input parameters for call to ut.run(...) or ut_runner.run(...) - sys_context( 'UT3_INFO', 'SUITE_DESCRIPTION' ); - the description of test suite that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_PACKAGE' ); - the owner and name of test suite package that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_PATH' ); - the suitepath for the test suite package that is currently being executed - sys_context( 'UT3_INFO', 'SUITE_START_TIME' ); - the execution start timestamp of test suite package that is currently being executed - sys_context( 'UT3_INFO', 'CURRENT_EXECUTABLE_NAME' ); - the owner.package.procedure of currently running test suite executable - sys_context( 'UT3_INFO', 'CURRENT_EXECUTABLE_TYPE' ); - the type of currently running test suite executable (one of: beforeall , beforeeach , beforetest , test , aftertest , aftereach , afterall When running in suite context sys_context( 'UT3_INFO', 'CONTEXT_DESCRIPTION' ); - the description of test suite context that is currently being executed sys_context( 'UT3_INFO', 'CONTEXT_NAME' ); - the name of test suite context that is currently being executed sys_context( 'UT3_INFO', 'CONTEXT_PATH' ); - the suitepath for the currently executed test suite context sys_context( 'UT3_INFO', 'CONTEXT_START_TIME' ); - the execution start timestamp for the currently executed test suite context When running a suite executable procedure that is a test or beforeeach , aftereach , beforetest , aftertest sys_context( 'UT3_INFO', 'TEST_DESCRIPTION' ); - the description of test for which the current executable is being invoked sys_context( 'UT3_INFO', 'TEST_NAME' ); - the name of test for which the current executable is being invoked sys_context( 'UT3_INFO', 'TEST_START_TIME' ); - the execution start timestamp of test that is currently being executed (the time when first beforeeach / beforetest was called for that test) Example: create or replace procedure which_procecure_called_me is begin dbms_output . put_line ( 'Currently running utPLSQL ' || sys_context ( 'ut3_info' , 'current_executable_type' ) || ' ' || sys_context ( 'ut3_info' , 'current_executable_name' ) ); end ; / create or replace package test_call is --%suite --%beforeall procedure beforeall ; --%beforeeach procedure beforeeach ; --%test procedure test1 ; --%test procedure test2 ; end ; / create or replace package body test_call is procedure beforeall is begin which_procecure_called_me (); dbms_output . put_line ( 'Current test procedure is: ' || sys_context ( 'ut3_info' , 'test_name' )); end ; procedure beforeeach is begin which_procecure_called_me (); dbms_output . put_line ( 'Current test procedure is: ' || sys_context ( 'ut3_info' , 'test_name' )); end ; procedure test1 is begin which_procecure_called_me (); ut . expect ( sys_context ( 'ut3_info' , 'suite_package' )). to_equal ( user || '.test_call' ); end ; procedure test2 is begin which_procecure_called_me (); ut . expect ( sys_context ( 'ut3_info' , 'test_name' )). to_equal ( user || '.test_call.test2' ); end ; end ; / exec ut . run ( 'test_call' ); test_call Currently running utPLSQL beforeall UT3.test_call.beforeall Current test procedure is: test1 [.008 sec] Currently running utPLSQL beforeeach UT3.test_call.beforeeach Current test procedure is: UT3.test_call.test1 Currently running utPLSQL test UT3.test_call.test1 test2 [.004 sec] Currently running utPLSQL beforeeach UT3.test_call.beforeeach Current test procedure is: UT3.test_call.test2 Currently running utPLSQL test UT3.test_call.test2 Finished in .021295 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"sys_context"},{"location":"userguide/annotations.html#annotation-cache","text":"utPLSQL needs to scan the source of package specifications to identify and parse annotations. To improve framework startup time, especially when dealing with database users owning large amounts of packages, the framework has a built-in persistent cache for annotations. The annotation cache is checked for staleness and refreshed automatically on every run. The initial startup of utPLSQL for a schema will take longer than consecutive executions. If you are in a situation where your database is controlled via CI/CD server and is refreshed/wiped before each run of your tests, consider building the annotation cache upfront and taking a snapshot of the database after the cache has been refreshed. To build the annotation cache without actually invoking any tests, call ut_runner.rebuild_annotation_cache(a_object_owner) for every unit test owner for which you want to have the annotation cache prebuilt. Example: exec ut_runner . rebuild_annotation_cache ( 'HR' ); To purge the annotation cache call ut_runner.purge_cache(a_object_owner, a_object_type) . Both parameters are optional and if not provided, all owners/object_types will be purged. Example: exec ut_runner . purge_cache ( 'HR' , 'PACKAGE' );","title":"Annotation cache"},{"location":"userguide/best-practices.html","text":"The following are best practices we at utPLSQL have learned about PL/SQL and Unit Testing. Test Isolation and Dependency \u00b6 Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before being run Tests should keep the environment unchanged post execution Writing tests \u00b6 Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be built so that it can fail, tests that do not fail when needed are useless Gaining value from the tests \u00b6 Tests are only valuable if they are executed frequently; ideally with every change to the project code Tests need to run very fast; the slower the tests, the longer you wait. Build tests with performance in mind (do you really need to have 10k rows to run the tests?) Tests that are executed infrequently can quickly become stale and end up adding overhead rather than value. Maintain tests as you would maintain code. Tests that are failing need to be addressed immediately. How can you trust your tests when 139 of 1000 tests are failing for a month? Will you recognise each time that it is still the same 139 tests? Tests are not for production \u00b6 Tests will generate and operate on fake data. They might insert, update and delete data. You don't want tests to run on a production database and affect real life data. Tests and their relationship to code under test \u00b6 Tests and the code under test should be in separate packages. This is a fundamental separation of responsibilities. It is common for test code to be in the same schema as the tested code. This removes the need to manage privileges for the tests. Version Control \u00b6 Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat the database as a target/destination for your code, not as a source of it.","title":"Testing best practices"},{"location":"userguide/best-practices.html#test-isolation-and-dependency","text":"Tests should not depend on a specific order to run Tests should not depend on other tests to execute Tests should not depend on specific database state, they should setup the expected state before being run Tests should keep the environment unchanged post execution","title":"Test Isolation and Dependency"},{"location":"userguide/best-practices.html#writing-tests","text":"Tests should not mimic / duplicate the logic of tested code Tests should contain zero logic (or as close to zero as possible) The 3A rule: Arrange (setup inputs/data/environment for the tested code) Act (execute code under test) Assert (validate the outcomes of the execution) Each tested procedure/function/trigger (code block) should have more than one test Each test should check only one behavior (one requirement) of the code block under test Tests should be maintained as thoroughly as production code Every test needs to be built so that it can fail, tests that do not fail when needed are useless","title":"Writing tests"},{"location":"userguide/best-practices.html#gaining-value-from-the-tests","text":"Tests are only valuable if they are executed frequently; ideally with every change to the project code Tests need to run very fast; the slower the tests, the longer you wait. Build tests with performance in mind (do you really need to have 10k rows to run the tests?) Tests that are executed infrequently can quickly become stale and end up adding overhead rather than value. Maintain tests as you would maintain code. Tests that are failing need to be addressed immediately. How can you trust your tests when 139 of 1000 tests are failing for a month? Will you recognise each time that it is still the same 139 tests?","title":"Gaining value from the tests"},{"location":"userguide/best-practices.html#tests-are-not-for-production","text":"Tests will generate and operate on fake data. They might insert, update and delete data. You don't want tests to run on a production database and affect real life data.","title":"Tests are not for production"},{"location":"userguide/best-practices.html#tests-and-their-relationship-to-code-under-test","text":"Tests and the code under test should be in separate packages. This is a fundamental separation of responsibilities. It is common for test code to be in the same schema as the tested code. This removes the need to manage privileges for the tests.","title":"Tests and their relationship to code under test"},{"location":"userguide/best-practices.html#version-control","text":"Use a version control system for your code. Don't just trust the database for code storage. This includes both the code under test, and the unit tests you develop as well. Treat the database as a target/destination for your code, not as a source of it.","title":"Version Control"},{"location":"userguide/coverage.html","text":"utPLSQL comes with a built-in coverage reporting engine. The code coverage reporting uses package DBMS_PROFILER (and DBMS_PLSQL_CODE_COVERAGE on Oracle database version 12.2 and above) provided with Oracle database. Code coverage is gathered for the following source types: package bodies type bodies triggers procedures functions Note The package and type specifications are excluded from code coverage analysis. This limitation is introduced to avoid false-negatives. Typically package specifications contain no executable code. The only exception is initialization of global constants and variables in package specification. Since most package specifications are not executable at all, there is no information available on the number of lines covered and those would be reported as 0% covered, which is not desirable. To obtain information about code coverage for unit tests, run utPLSQL with one of built-in code coverage reporters. The following code coverage reporters are supplied with utPLSQL: ut_coverage_html_reporter - generates a HTML coverage report providing summary and detailed information on code coverage. The HTML reporter is based on the open-source simplecov-html reporter for Ruby. It includes source code of the code that was covered (if the code is accessible for test user) ut_coveralls_reporter - generates a Coveralls compatible JSON coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by cloud services like Coveralls ut_coverage_sonar_reporter - generates a Sonar Compatible XML coverage report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by services like SonarQube and SonarCloud ut_coverage_cobertura_reporter - generates a basic Cobertura coverage (http://cobertura.sourceforge.net/xml/coverage-04.dtd) report providing detailed information on code coverage with line numbers. This coverage report is designed to be consumed by services like TFS and Jenkins. Check this link for an example of XML generated by Java: https://raw.githubusercontent.com/jenkinsci/cobertura-plugin/master/src/test/resources/hudson/plugins/cobertura/coverage-with-data.xml Security model \u00b6 utPLSQL code coverage uses DBMS_PROFILER to gather information about the execution of code under test and therefore follows the DBMS_PROFILER's Security Model . In order to be able to gather coverage information, the user executing unit tests needs to be either: The owner of the code that is being tested Have the following privileges to be able to gather coverage on code owned by other users: create any procedure system privilege execute privilege on the code that is being tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that is being tested, but do not have create any procedure system privilege, then the code that is being tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is being tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is being tested is compiled as NATIVE, the code coverage will not be reported as well. Manually running unit tests with coverage \u00b6 Using the code coverage functionality is as easy as using any other reporter for the utPLSQL test-run. Run your tests from your preferred SQL tool and save the reporter results to a file. All you need to do, is pass the constructor of the reporter to the ut.run procedure call. Example: set serveroutput on begin ut . run ( ut_coverage_html_reporter ()); end ; / The above command executes all unit tests in the current schema , gathers information about code coverage for all sources in that schema and outputs the HTML report as text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce an interactive HTML report. You can see a sample of code coverage for the utPLSQL project here The report provides summary information with a list of source code that should be covered. The report allow you to navigate to each source file and inspect line by line coverage. Oracle 12.2 extended coverage with profiler and block coverage \u00b6 Using data collected from profiler and block coverage running parallel we are able to enrich information about coverage. For every line recorded by the profiler if we have a partially covered same line in block coverage we will display that information presenting line as partially covered, displaying number of block and how many blocks have been covered in that line.The feature will be automatically enabled in the Oracle database version 12.2 and higher, for older versions current profiler will be used. utPLSQL installation automatically creates tables needed by dbms_plsql_code_coverage on databases in versions above 12c Release 1. Due to security model of dbms_plsql_code_coverage package, utPLSQL grants access to those tables and creates synonyms for those tables. The access and synonyms will be public when using the headless installation. This approach avoids complexity of forcing every user of utPLSQL framework to create tables on their own. Sample output: Coverage reporting options \u00b6 There are two distinct ways to gather code coverage: - Coverage on database schema(s) - Coverage on project files Those two options are mutually exclusive and cannot be mixed. By default, when using one of coverage reporters, coverage is gathered on schema(s). The database schema(s) containing the tests that were executed during the run will be reported on by coverage reporter. The parameters used to execute tests determine if utPLSQL will be using one approach or the other. If parameter a_source_file_mappings or a_source_files is provided, then coverage is gathered on project files provided, otherwise coverage is gathered on schemas. Note Regardless of the options provided, all unit test packages are excluded from the coverage report. Coverage reports provide information only about the tested code. The default behavior of coverage reporting can be altered using invocation parameters. Schema based Coverage \u00b6 To gather coverage for all objects in the current schema execute tests with coverage report as argument. This is the default reporting option and therefore additional coverage options don't need to be provided. exec ut . run ( ut_coverage_html_reporter ()); Note When no filters are used, the size of the coverage report will depend two factors: - the type of report (does the report include source code or not) - the amount of source code in the database schema Keep in mind that for schemas containing a lot of code, it can take quite some time to produce the coverage report. Setting coverage schema(s) \u00b6 By default, coverage is gathered on the schema(s) derived from suite paths provided to execute tests. This is a valid approach as long as your test packages and tested code share the same schema. So when you run: exec ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter ()); Coverage will be gathered on both user_1 and user_2 objects. If your tests live in a different schema from the tested code you may override the default behavior by providing an explicit list of coverage schema names. In the example below, coverage will still be gathered for user_1 and user_2 objects, even thought we run the tests located in schema unit_test_schema exec ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'user_1' , 'user_2' ) ); Filtering objects in coverage reports \u00b6 Multiple parameters can be used to define the scope of coverage report. - a_source_file_mappings ( ut_file_mappings ) - map of filenames to database objects. It is used for file-based coverage - see below. - a_include_schema_expr ( varchar(4000) ) - string of regex expression of schemas to be included in the coverage report. Case-insensitive. - a_include_object_expr ( varchar(4000) ) - string of regex expression of objects ( without schema name ) to be included in the coverage report. Case-insensitive. - a_exclude_schema_expr ( varchar(4000) ) - string of regex expression of schemas to be excluded from the coverage report. Case-insensitive. - a_exclude_object_expr ( varchar(4000) ) - string of regex expression of objects ( without schema name ) to be excluded from the coverage report. Case-insensitive. - a_coverage_schemes ( ut_varchar2_list ) - List of database schema names to gather coverage on. - a_include_objects ( ut_varchar2_list ) - list of [object_owner.]object_name to be included in the coverage report. - a_exclude_objects ( ut_varchar2_list ) - list of [object_owner.]object_name to be excluded from the coverage report. You may specify both include and exclude options to gain more control over what needs to be included / excluded from the coverage report. Important notes The order of priority is for evaluation of include/exclude filter parameters is as follows. if a_source_file_mappings is defined then all include/exclude parameters are ignored (see section below for usage of a_source_file_mappings parameter ) else if a_include_schema_expr or a_include_object_expr parameter is specified then parameters a_coverage_schemes and a_include_objects are ignored else if a_include_objects is specified then the coverage is gathered only on specified database objects. if a_coverage_schemes is specified then those schemas are used for objects in a_include_objects without schema name if a_coverage_schemes is not specified then schema from paths ( a_paths ) parameter are used for objects in a_include_objects without schema name else if, only the a_coverage_schemes is specified then the coverage is gathered only on specified database schemas else if no coverage specific parameters are provided coverage is gathered on all schemas specified in paths passed to run procedure else if no paths were specified, the coverage is gathered on current schema of the session running the tests The exclude parameters are not mutually-exclusive and can be mixed together. All of exclude parameters are always applied. Example: Limiting coverage by schema regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_schema_expr => '^ut3_develop' ); end ; Will result in showing coverage for all schemas that match regular expression ^ut3_develop Example: Limiting coverage by schema regex with parameter a_include_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_schema_expr => '^ut3_develop' , a_include_objects => ut_varchar2_list ( 'ut3_tester_helper.regex_dummy_cov' ) ); end ; Will result in showing coverage for all schemas that match regular expression ^ut3_develop . Example: Limiting coverage by object regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_object_expr => 'regex123' ); end ; Will result in showing coverage for all objects that name match regular expression regex123 . Example: Limiting coverage by object regex with parameter a_include_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_object_expr => 'utl' , a_include_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for all objects that name match regular expression utl . Example: Limiting coverage by excluding schema with regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_schema_expr => 'er_1$' ); end ; Will result in showing coverage for objects in all schema except schemas that are matching regular expression er_1$ Example: Limiting coverage by excluding schema with regex and excluding specific object. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_schema_expr => 'er_1$' , a_exclude_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for objects in all schemas except schemas that are matching regular expression er_1$ Will also exclude object user_2.utils_package from coverage report Example: Limiting coverage by excluding objects with regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_object_expr => 'utl' ); end ; Will result in showing coverage for all objects that name is not matching regular expression utl . Example: Limiting coverage by excluding objects with regex with parameter a_exclude_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_object_expr => 'utl' , a_exclude_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for all objects that name is not matching regular expression utl . Will also exclude object user_2.utils_package from coverage report Example: Limiting coverage by object name, for tested code located in the same schema as the unit tests. exec ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'award_bonus' )); Executes all tests in schemas: user_1 and user_2 . Coverage will only be reported on objects user_1.award_bonus , user_2.award_bonus Example: Limiting coverage by object name, for tested code located in different schemas than the unit tests. begin ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'user_1' , 'user_2' ), a_include_objects => ut_varchar2_list ( 'award_bonus' , 'betwnstr' ) ); end ; Executes all tests in schema unit_test_schema . Coverage will only be reported on objects user_1.award_bonus , user_2.award_bonus , user_1.betwnstr , user_2.betwnstr . Objects that do not exist in the database but were specified in a_include_objects will be ignored. Example: Limiting coverage by object owner and name. begin ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'user_1.award_bonus' , 'user_2.betwnstr' ) ); end ; Executes all tests in schema unit_test_schema . Coverage will only be reported on objects user_1.award_bonus , user_2.betwnstr The a_exclude_objects can be used in the same way as a_include_objects . Example: Excluding objects from coverage report by providing a list of object owner/name to be excluded. begin ut . run ( 'unit_test_schema.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' ) ); end ; Executes test test_award_bonus in schema unit_test_schema . Coverage will be reported on all objects in schema ut3_user except the betwnstr object. Note Filtering using a_include_objects and a_exclude_objects is only applicable when gathering coverage for a schema. Those filters are not applied when reporting coverage on project files. Note When running coverage on schema objects, all source code of package bodies, functions, procedures, type bodies and triggers that were not executed will be reported as having 0% code coverage and all source code lines will show as uncovered. This is different from the behavior when gathering coverage on project files. Project based Coverage \u00b6 utPLSQL provides reporters that produce reports consumable by external tools like Sonar / SonarCloud & Coveralls . Services like Sonar, Coveralls and others perform analysis based on source code in project files. They are abstracted from database, schema names, packages, procedures and functions, and operate on a more generic concept of project source code. To be able to effectively use reporters dedicated for those tools, utPLSQL provides functionality for mapping database object names to project files. There are a few significant differences when running coverage on project files compared to running coverage on schema(s). Coverage is only reported on objects that were successfully mapped to project files. Project files (database objects) that were not executed at all are not reported as fully uncovered. It is up to the consumer (Sonar/Coveralls) to determine if project file should be considered as 0% coverage or just ignored. In order to successfully use coverage on project files, those files must be mapped to database objects. Though you can gather project based code coverage directly using exec ut.run(...) , it is highly recommended to use utPLSQL-cli command line client. The examples below are using utPLSQL-cli to execute tests and gather coverage information. File mapping using default parameters \u00b6 The example below illustrates a directory structure supported by the default parameters of utPLSQL. The structure represents a multi-schema project with file names indicating object owner. C: \\my_project \\sources \\hotel.add_rooms_content.prc \\hotel.remove_rooms_by_name.prc \\hotel.rooms.tbl \\hr.award_bonus.prc \\hr.betwnstr.fnc \\hr.employees_test.tbl \\tests \\hotel.test_add_room_content.pkb \\hotel.test_add_room_content.pks \\hotel.test_remove_rooms_by_name.pkb \\hotel.test_remove_rooms_by_name.pks \\hr.test_award_bonus.pkb \\hr.test_award_bonus.pks \\hr.test_betwnstr.pkb \\hr.test_betwnstr.pks By default, utPLSQL will convert file paths into database objects using the following regular expression /(((\\w|[$#])+)\\.)?((\\w|[$#])+)\\.(\\w{3})$ object owner (if it is present) is identified by the expression in the second set of brackets object name is identified by the expression in the fourth set of brackets object type is identified by the expression in the sixth set of brackets Note utPLSQL will replace any '\\' with '/' for the purpose of mapping files to objects. The paths shown in the results will remain (contain '\\' where it was present). This is done to simplify the syntax of regular expressions. Regular expression will always use '/' as a directory separator on a file path regardless of whether you're on a Windows or Unix system. Note Below examples assume that you have downloaded latest version of utPLSQL-cli and extracted it into your projects root directory (my_project). The examples assume that you run the utPLSQL-cli from my_project directory. Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_host:db_port/db_service_name ^ -p=hr,hotel ^ -source_path=sources ^ -test_path=tests ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_host:db_port/db_service_name \\ -p = hr,hotel \\ -source_path = sources \\ -test_path = tests \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml The above commands will: - connect as user test_runner - run all utPLSQL v3 tests for users hr , hotel - map database code to project files in sources directory and save code coverage results into coverage.html - map test packages to project files in tests directory and save test results into test_results.xml To better understand the default regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml Using custom regular expressions \u00b6 If your project directory structure is different, you can use additional configuration parameters to tell utPLSQL how the project files are to be mapped into database objects. Example: Using custom regular expressions on a multi-schema project with separate directories for each object owner. C: \\my_project \\sources \\hotel \\add_rooms_content.prc \\remove_rooms_by_name.prc \\rooms.tbl \\hr \\award_bonus.prc \\betwnstr.fnc \\employees_test.tbl \\tests \\hotel \\test_add_room_content.pkb \\test_add_room_content.pks \\test_remove_rooms_by_name.pkb \\test_remove_rooms_by_name.pks \\hr \\test_award_bonus.pkb \\test_award_bonus.pks \\test_betwnstr.pkb \\test_betwnstr.pks The command below will gather coverage and map files to database objects using custom regular expression. Note that the owner/name/type subexpressions don't need to be explicitly specified if they are same as default values ( 2/3/4 ). In the below example, they were specified explicitly only for source_path , test_path doesn't have subexpressions specified and so they are default (2/3/4). Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=hr,hotel ^ -source_path=sources ^ -regex_expression=\"/((\\w+)/)?(\\w+)\\.(\\w{3})$\" ^ -owner_subexpression=2 ^ -name_subexpression=3 ^ -type_subexpression=4 ^ -test_path=tests -regex_expression=\"/((\\w+)/)?(\\w+)\\.(\\w{3})$\" ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml ^ Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_url \\ -source_path = sources \\ -regex_expression = \"/((\\w+)/)?(\\w+)\\.(\\w{3}) $ \" \\ -owner_subexpression = 2 \\ -name_subexpression = 3 \\ -type_subexpression = 4 \\ -test_path = tests -regex_expression = \"/((\\w+)/)?(\\w+)\\.(\\w{3}) $ \" \\ -owner_subexpression = 2 \\ -name_subexpression = 3 \\ -type_subexpression = 4 \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml You can specify different mapping rules for source files and for test files - see utPLSQL-cli readme for details. To better understand the regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml Explicitly specifying object owner \u00b6 When dealing with projects that operate within a single schema the project structure probably doesn't indicate the owner. In such scenarios, you can explicitly specify the object owner for both tests and source code. Example: Single-schema project - no indication of object owner C: \\my_project \\sources \\betwnstr.fnc \\tests \\test_betwnstr.pkb \\test_betwnstr.pks The command below will gather coverage and map files to database objects. For the database objects mapped to souces directory user code_owner will be used. For the database objects mapped to tests directory user tests_owner will be used. Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=tests_owner ^ -source_path=sources -owner=code_owner ^ -test_path=tests -owner=tests_owner ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_url \\ -p = tests_owner \\ -source_path = sources -owner = code_owner \\ -test_path = tests -owner = tests_owner \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml Note When the project folder structure does not provide any information about source code owner and test owner, you can specify the owner for tests and owner for code explicitly. Such project configuration supports only single-owner for source code and single owner for tests. Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml Custom mapping of object types \u00b6 By default, when mapping project files to database objects, utPLSQL will identify the object type by file extension. The table below represents the default mapping of file extensions to database object types. file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure If your project naming convention differs and your file extensions do not match the above, or you simply name all of your files with .sql suffix, you can still use utPLSQL, but you need to provide custom mapping for object types. Example: Multi-schema project with separate directories for each object owner and object type C: \\my_project \\sources \\hotel \\functions \\packages \\packages_bodies \\procedures \\add_rooms_content.sql \\remove_rooms_by_name.sql \\tables \\rooms.sql \\triggers \\types \\type_bodies \\hr \\functions \\betwnstr.sql \\packages \\package_bodies \\procedures \\award_bonus.sql \\tables \\employees_test.sql \\triggers \\types \\types_bodies \\tests \\hotel \\packages \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\packages_bodies \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\hr \\packages \\test_award_bonus.sql \\test_betwnstr.sql \\packages_bodies \\test_award_bonus.sql \\test_betwnstr.sql Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=hr,hotel ^ -source_path=sources ^ -regex_expression=\"/(\\w+)/(\\w+)/(\\w+)\\..{3}$\" ^ -type_mapping=\"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" ^ -owner_subexpression=1 ^ -name_subexpression=3 ^ -type_subexpression=2 ^ -test_path=tests -regex_expression=\"/(\\w+)/(\\w+)/(\\w+)\\..{3}$\" ^ -type_mapping=\"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" ^ -owner_subexpression=1 ^ -name_subexpression=3 ^ -type_subexpression=2 ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_urll \\ -p = hr,hotel \\ -source_path = sources \\ -regex_expression = \"/(\\w+)/(\\w+)/(\\w+)\\..{3} $ \" \\ -type_mapping = \"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" \\ -owner_subexpression = 1 \\ -name_subexpression = 3 \\ -type_subexpression = 2 \\ -test_path = tests -regex_expression = \"/(\\w+)/(\\w+)/(\\w+)\\..{3} $ \" \\ -type_mapping = \"body=PACKAGE BODY/type_body=TYPE BODY/trigger=TRIGGER\" \\ -owner_subexpression = 1 \\ -name_subexpression = 3 \\ -type_subexpression = 2 \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml The parameter type_mapping accepts a list of a key-value pairs representing a mapping of regex subexpression to database object type. To better understand the regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml Object-file mapping rules \u00b6 In order to allow deterministic and accurate mapping of database source-code into project files, the project directory and file structure needs to meet certain criteria. - Source code is kept separate from test code (separate directories) - Each database (source-code) object is stored in an individual file. Package/type specification is kept separate from its body. - File name (file path) contains the name of database object - Each file-path clearly identifies object type (by file extension) - Each file contains representation of database object \"as is\". No extra commands (like set echo off ALTER SESSION SET PLSQL_CCFLAGS = 'debug:TRUE'; ) or blank lines are present before CREATE TYPE , CREATE TYPE etc. - When project is spanning across multiple database schemes, each file-path clearly and uniformly identifies object owner File mapping from SQL \u00b6 The ut.run command provides interface to map project into database objects when executing tests. While it is much easier to perform mapping directly from command line, it is possible to achieve similar functionality from any SQL client. The main differences when using the ut.run(...) command, will be: - you can only use single reporter and therefore will get only one report from test execution - you need to provide fill list of project files rather than point to sources and tests directories Example project directory structure. C: \\my_project \\sources \\hotel \\functions \\packages \\packages_bodies \\procedures \\add_rooms_content.sql \\remove_rooms_by_name.sql \\tables \\rooms.sql \\triggers \\types \\type_bodies \\hr \\functions \\betwnstr.sql \\packages \\package_bodies \\procedures \\award_bonus.sql \\tables \\employees_test.sql \\triggers \\types \\types_bodies \\tests \\hotel \\packages \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\packages_bodies \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\hr \\packages \\test_award_bonus.sql \\test_betwnstr.sql \\packages_bodies \\test_award_bonus.sql \\test_betwnstr.sql To execute all tests and map database source code into source file names you could use the following command in any SQL client: begin ut . run ( ut_varchar2_list ( 'hr' , 'hotel' ), ut_coverage_html_reporter (), a_source_file_mappings => ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources\\hotel\\procedures\\add_rooms_content.sql' , 'sources\\hotel\\procedures\\remove_rooms_by_name.sql' , 'sources\\hotel\\tables\\rooms.sql' , 'sources\\hr\\functions\\betwnstr.sql' , 'sources\\hr\\procedures\\award_bonus.sql' , 'sources\\hr\\tables\\employees_test.sql' ), a_regex_pattern => '/(\\w+)/(\\w+)/(\\w+)\\..{3}$' , a_object_owner_subexpression => 1 , a_object_name_subexpression => 3 , a_object_type_subexpression => 2 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'packages_bodies' , 'PACKAGE BODY' ), ut_key_value_pair ( 'types_bodies' , 'TYPE BODY' ), ut_key_value_pair ( 'triggers' , 'TRIGGER' ), ut_key_value_pair ( 'procedures' , 'PROCEDURE' ), ut_key_value_pair ( 'functions' , 'FUNCTION' ) ) ) ); end ; To execute all tests and map database tests code into test file names you could use the following command in any SQL client: begin ut . run ( ut_varchar2_list ( 'hr' , 'hotel' ), ut_sonar_test_reporter (), a_test_file_mappings => ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'tests\\hotel\\packages\\test_add_room_content.sql' , 'tests\\hotel\\packages\\test_remove_rooms_by_name.sql' , 'tests\\hotel\\packages_bodies\\test_add_room_content.sql' , 'tests\\hotel\\packages_bodies\\test_remove_rooms_by_name.sql' , 'tests\\hr\\packages\\test_award_bonus.sql' , 'tests\\hr\\packages\\test_betwnstr.sql' , 'tests\\hr\\packages_bodies\\test_award_bonus.sql' , 'tests\\hr\\packages_bodies\\test_betwnstr.sql' ), a_regex_pattern => '/(\\w+)/(\\w+)/(\\w+)\\..{3}$' , a_object_owner_subexpression => 1 , a_object_name_subexpression => 3 , a_object_type_subexpression => 2 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'packages_bodies' , 'PACKAGE BODY' ), ut_key_value_pair ( 'types_bodies' , 'TYPE BODY' ), ut_key_value_pair ( 'triggers' , 'TRIGGER' ), ut_key_value_pair ( 'procedures' , 'PROCEDURE' ), ut_key_value_pair ( 'functions' , 'FUNCTION' ) ) ) ); end ; Reporting coverage outside utPLSQL and in parallel sessions \u00b6 utPSLQL allows fo standalone reporting code coverage across multiple database sessions. This functionality enables coverage reporting for external testing tools. Following API calls enable the standalone coverage reporting. ut_runner.coverage_start( coverage_run_id ); - initiates code coverage within a session ut_runner.coverage_stop(); - stops gathering of code coverage within a session .get_report( ... ) - coverage reporters function producing coverage report as pipelined data-set (to be used in SQL query) .get_report_cursor( ... ) - coverage reporters function producing coverage report as ref-cursor Example: --SESSION 1 -- gather coverage on code using specific coverage_run_id value declare l_coverage_run_id raw ( 32 ); begin l_coverage_run_id : = 'A6AA5B7361251CE6E053020011ACA055' ; -- l_coverage_run_id := sys_guid; ut_runner . coverage_start ( l_coverage_run_id ); --The code to gather coverage on goes here ut_runner . coverage_stop (); end ; / --SESSION 2 -- alternative approach -- gather coverage on code using specific coverage_run_id value exec ut_runner . coverage_start ( 'A6AA5B7361251CE6E053020011ACA055' ); --The code to gather coverage on goes here exec ut_runner . coverage_stop (); --SESSION 1 or SESSION2 2 or SESSION 3 -- run after calls in SESSION 1 & 2 are finished -- retrieve coverage report in HTML format coverage_run_id value select * from table ( ut_coverage_html_reporter (). get_report ( a_coverage_options => ut_coverage_options ( coverage_run_id => 'A6AA5B7361251CE6E053020011ACA055' ) ) ); --SESSION 1 or SESSION2 2 or SESSION 3 -- run after calls in SESSION 1 & 2 are finished declare l_results_cursor sys_refcursor ; begin l_results_cursor : = ut_coverage_html_reporter (). get_report_cursor ( a_coverage_options => ut_coverage_options ( coverage_run_id => 'A6AA5B7361251CE6E053020011ACA055' ) ); --fetch and process the cursor results close l_results_cursor ; end ; / Specification of parameters for get_report and get_report_cursor function get_report ( a_coverage_options ut_coverage_options , a_client_character_set varchar2 : = null ) return ut_varchar2_rows pipelined function get_report_cursor ( a_coverage_options ut_coverage_options , a_client_character_set varchar2 : = null ) return sys_refcursor ut_coverage_options ( coverage_run_id raw , schema_names ut_varchar2_rows : = null , exclude_objects ut_varchar2_rows : = null , include_objects ut_varchar2_rows : = null , file_mappings ut_file_mappings : = null include_schema_expr varchar2 ( 4000 ) : = null , include_object_expr varchar2 ( 4000 ) : = null , exclude_schema_expr varchar2 ( 4000 ) : = null , exclude_object_expr varchar2 ( 4000 ) : = null ); The a_client_character_set is used to provide character set to the report. Coverage reports in XML and HTML format include this information to assure that HMTL/XML encoding tag is aligned with encoding of the report produced. Use this parameter to provide encoding of your client application. The a_coverage_options parameter is used to control the scope and formatting of data returned by report. ut_coverage_options object accepts the following arguments coverage_run_id - identifier of coverage run to generate report for - data-type RAW(32) schema_names - optional - list of schema names to include in coverage report - data-type UT_VARCHAR2_ROWS exclude_objects - optional - list of object names to exclude from report - data-type UT_VARCHAR2_ROWS include_objects - optional - list of object names to gather coverage on - data-type UT_VARCHAR2_ROWS file_mappings - optional - list of schema names to gather coverage on - data-type UT_FILE_MAPPINGS include_schema_expr - optional - regular expression to match against schema name to include in coverage - data-type VARCHAR2(4000) include_object_expr - optional - regular expression to match against object name to include in coverage - data-type VARCHAR2(4000) exclude_schema_expr - optional - regular expression to match against schema name to exclude in coverage - data-type VARCHAR2(4000) exclude_object_expr - optional - regular expression to match against object name to exclude in coverage - data-type VARCHAR2(4000) coverage_run_id parameter identifies a common coverage run. The valid value type for that parameter is RAW(32). It is recommended to use sys_guid() to generate a common, unique identifier for a specific coverage run. If the identifier is not unique, previous runs of coverage that used the same coverage_run_id will be aggregated to the resulting coverage report. For details on the meaning of schema_names , exclude_objects , include_objects , file_mappings see sections above. Note that data-types of include/exclude/schema lists are different when calling ut.run vs. calling get_report/get_report_cursor .","title":"Code coverage"},{"location":"userguide/coverage.html#security-model","text":"utPLSQL code coverage uses DBMS_PROFILER to gather information about the execution of code under test and therefore follows the DBMS_PROFILER's Security Model . In order to be able to gather coverage information, the user executing unit tests needs to be either: The owner of the code that is being tested Have the following privileges to be able to gather coverage on code owned by other users: create any procedure system privilege execute privilege on the code that is being tested (not only the unit tests) or execute any procedure system privilege If you have execute privilege on the code that is being tested, but do not have create any procedure system privilege, then the code that is being tested will be reported as not covered (coverage = 0%). If you have execute privilege only on the unit tests, but do not have execute privilege on the code that is being tested, the code will not be reported by coverage - as if it did not exist in the database. If the code that is being tested is compiled as NATIVE, the code coverage will not be reported as well.","title":"Security model"},{"location":"userguide/coverage.html#manually-running-unit-tests-with-coverage","text":"Using the code coverage functionality is as easy as using any other reporter for the utPLSQL test-run. Run your tests from your preferred SQL tool and save the reporter results to a file. All you need to do, is pass the constructor of the reporter to the ut.run procedure call. Example: set serveroutput on begin ut . run ( ut_coverage_html_reporter ()); end ; / The above command executes all unit tests in the current schema , gathers information about code coverage for all sources in that schema and outputs the HTML report as text into DBMS_OUTPUT. The ut_coverage_html_reporter will produce an interactive HTML report. You can see a sample of code coverage for the utPLSQL project here The report provides summary information with a list of source code that should be covered. The report allow you to navigate to each source file and inspect line by line coverage.","title":"Manually running unit tests with coverage"},{"location":"userguide/coverage.html#oracle-122-extended-coverage-with-profiler-and-block-coverage","text":"Using data collected from profiler and block coverage running parallel we are able to enrich information about coverage. For every line recorded by the profiler if we have a partially covered same line in block coverage we will display that information presenting line as partially covered, displaying number of block and how many blocks have been covered in that line.The feature will be automatically enabled in the Oracle database version 12.2 and higher, for older versions current profiler will be used. utPLSQL installation automatically creates tables needed by dbms_plsql_code_coverage on databases in versions above 12c Release 1. Due to security model of dbms_plsql_code_coverage package, utPLSQL grants access to those tables and creates synonyms for those tables. The access and synonyms will be public when using the headless installation. This approach avoids complexity of forcing every user of utPLSQL framework to create tables on their own. Sample output:","title":"Oracle 12.2 extended coverage with profiler and block coverage"},{"location":"userguide/coverage.html#coverage-reporting-options","text":"There are two distinct ways to gather code coverage: - Coverage on database schema(s) - Coverage on project files Those two options are mutually exclusive and cannot be mixed. By default, when using one of coverage reporters, coverage is gathered on schema(s). The database schema(s) containing the tests that were executed during the run will be reported on by coverage reporter. The parameters used to execute tests determine if utPLSQL will be using one approach or the other. If parameter a_source_file_mappings or a_source_files is provided, then coverage is gathered on project files provided, otherwise coverage is gathered on schemas. Note Regardless of the options provided, all unit test packages are excluded from the coverage report. Coverage reports provide information only about the tested code. The default behavior of coverage reporting can be altered using invocation parameters.","title":"Coverage reporting options"},{"location":"userguide/coverage.html#schema-based-coverage","text":"To gather coverage for all objects in the current schema execute tests with coverage report as argument. This is the default reporting option and therefore additional coverage options don't need to be provided. exec ut . run ( ut_coverage_html_reporter ()); Note When no filters are used, the size of the coverage report will depend two factors: - the type of report (does the report include source code or not) - the amount of source code in the database schema Keep in mind that for schemas containing a lot of code, it can take quite some time to produce the coverage report.","title":"Schema based Coverage"},{"location":"userguide/coverage.html#setting-coverage-schemas","text":"By default, coverage is gathered on the schema(s) derived from suite paths provided to execute tests. This is a valid approach as long as your test packages and tested code share the same schema. So when you run: exec ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter ()); Coverage will be gathered on both user_1 and user_2 objects. If your tests live in a different schema from the tested code you may override the default behavior by providing an explicit list of coverage schema names. In the example below, coverage will still be gathered for user_1 and user_2 objects, even thought we run the tests located in schema unit_test_schema exec ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'user_1' , 'user_2' ) );","title":"Setting coverage schema(s)"},{"location":"userguide/coverage.html#filtering-objects-in-coverage-reports","text":"Multiple parameters can be used to define the scope of coverage report. - a_source_file_mappings ( ut_file_mappings ) - map of filenames to database objects. It is used for file-based coverage - see below. - a_include_schema_expr ( varchar(4000) ) - string of regex expression of schemas to be included in the coverage report. Case-insensitive. - a_include_object_expr ( varchar(4000) ) - string of regex expression of objects ( without schema name ) to be included in the coverage report. Case-insensitive. - a_exclude_schema_expr ( varchar(4000) ) - string of regex expression of schemas to be excluded from the coverage report. Case-insensitive. - a_exclude_object_expr ( varchar(4000) ) - string of regex expression of objects ( without schema name ) to be excluded from the coverage report. Case-insensitive. - a_coverage_schemes ( ut_varchar2_list ) - List of database schema names to gather coverage on. - a_include_objects ( ut_varchar2_list ) - list of [object_owner.]object_name to be included in the coverage report. - a_exclude_objects ( ut_varchar2_list ) - list of [object_owner.]object_name to be excluded from the coverage report. You may specify both include and exclude options to gain more control over what needs to be included / excluded from the coverage report. Important notes The order of priority is for evaluation of include/exclude filter parameters is as follows. if a_source_file_mappings is defined then all include/exclude parameters are ignored (see section below for usage of a_source_file_mappings parameter ) else if a_include_schema_expr or a_include_object_expr parameter is specified then parameters a_coverage_schemes and a_include_objects are ignored else if a_include_objects is specified then the coverage is gathered only on specified database objects. if a_coverage_schemes is specified then those schemas are used for objects in a_include_objects without schema name if a_coverage_schemes is not specified then schema from paths ( a_paths ) parameter are used for objects in a_include_objects without schema name else if, only the a_coverage_schemes is specified then the coverage is gathered only on specified database schemas else if no coverage specific parameters are provided coverage is gathered on all schemas specified in paths passed to run procedure else if no paths were specified, the coverage is gathered on current schema of the session running the tests The exclude parameters are not mutually-exclusive and can be mixed together. All of exclude parameters are always applied. Example: Limiting coverage by schema regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_schema_expr => '^ut3_develop' ); end ; Will result in showing coverage for all schemas that match regular expression ^ut3_develop Example: Limiting coverage by schema regex with parameter a_include_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_schema_expr => '^ut3_develop' , a_include_objects => ut_varchar2_list ( 'ut3_tester_helper.regex_dummy_cov' ) ); end ; Will result in showing coverage for all schemas that match regular expression ^ut3_develop . Example: Limiting coverage by object regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_object_expr => 'regex123' ); end ; Will result in showing coverage for all objects that name match regular expression regex123 . Example: Limiting coverage by object regex with parameter a_include_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_object_expr => 'utl' , a_include_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for all objects that name match regular expression utl . Example: Limiting coverage by excluding schema with regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_schema_expr => 'er_1$' ); end ; Will result in showing coverage for objects in all schema except schemas that are matching regular expression er_1$ Example: Limiting coverage by excluding schema with regex and excluding specific object. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_schema_expr => 'er_1$' , a_exclude_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for objects in all schemas except schemas that are matching regular expression er_1$ Will also exclude object user_2.utils_package from coverage report Example: Limiting coverage by excluding objects with regex. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_object_expr => 'utl' ); end ; Will result in showing coverage for all objects that name is not matching regular expression utl . Example: Limiting coverage by excluding objects with regex with parameter a_exclude_objects ignored. begin ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_exclude_object_expr => 'utl' , a_exclude_objects => ut_varchar2_list ( 'user_2.utils_package' ) ); end ; Will result in showing coverage for all objects that name is not matching regular expression utl . Will also exclude object user_2.utils_package from coverage report Example: Limiting coverage by object name, for tested code located in the same schema as the unit tests. exec ut . run ( ut_varchar2_list ( 'user_1' , 'user_2' ), ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'award_bonus' )); Executes all tests in schemas: user_1 and user_2 . Coverage will only be reported on objects user_1.award_bonus , user_2.award_bonus Example: Limiting coverage by object name, for tested code located in different schemas than the unit tests. begin ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_coverage_schemes => ut_varchar2_list ( 'user_1' , 'user_2' ), a_include_objects => ut_varchar2_list ( 'award_bonus' , 'betwnstr' ) ); end ; Executes all tests in schema unit_test_schema . Coverage will only be reported on objects user_1.award_bonus , user_2.award_bonus , user_1.betwnstr , user_2.betwnstr . Objects that do not exist in the database but were specified in a_include_objects will be ignored. Example: Limiting coverage by object owner and name. begin ut . run ( 'unit_test_schema' , ut_coverage_html_reporter (), a_include_objects => ut_varchar2_list ( 'user_1.award_bonus' , 'user_2.betwnstr' ) ); end ; Executes all tests in schema unit_test_schema . Coverage will only be reported on objects user_1.award_bonus , user_2.betwnstr The a_exclude_objects can be used in the same way as a_include_objects . Example: Excluding objects from coverage report by providing a list of object owner/name to be excluded. begin ut . run ( 'unit_test_schema.test_award_bonus' , ut_coverage_html_reporter (), a_exclude_objects => ut_varchar2_list ( 'ut3_user.betwnstr' ) ); end ; Executes test test_award_bonus in schema unit_test_schema . Coverage will be reported on all objects in schema ut3_user except the betwnstr object. Note Filtering using a_include_objects and a_exclude_objects is only applicable when gathering coverage for a schema. Those filters are not applied when reporting coverage on project files. Note When running coverage on schema objects, all source code of package bodies, functions, procedures, type bodies and triggers that were not executed will be reported as having 0% code coverage and all source code lines will show as uncovered. This is different from the behavior when gathering coverage on project files.","title":"Filtering objects in coverage reports"},{"location":"userguide/coverage.html#project-based-coverage","text":"utPLSQL provides reporters that produce reports consumable by external tools like Sonar / SonarCloud & Coveralls . Services like Sonar, Coveralls and others perform analysis based on source code in project files. They are abstracted from database, schema names, packages, procedures and functions, and operate on a more generic concept of project source code. To be able to effectively use reporters dedicated for those tools, utPLSQL provides functionality for mapping database object names to project files. There are a few significant differences when running coverage on project files compared to running coverage on schema(s). Coverage is only reported on objects that were successfully mapped to project files. Project files (database objects) that were not executed at all are not reported as fully uncovered. It is up to the consumer (Sonar/Coveralls) to determine if project file should be considered as 0% coverage or just ignored. In order to successfully use coverage on project files, those files must be mapped to database objects. Though you can gather project based code coverage directly using exec ut.run(...) , it is highly recommended to use utPLSQL-cli command line client. The examples below are using utPLSQL-cli to execute tests and gather coverage information.","title":"Project based Coverage"},{"location":"userguide/coverage.html#file-mapping-using-default-parameters","text":"The example below illustrates a directory structure supported by the default parameters of utPLSQL. The structure represents a multi-schema project with file names indicating object owner. C: \\my_project \\sources \\hotel.add_rooms_content.prc \\hotel.remove_rooms_by_name.prc \\hotel.rooms.tbl \\hr.award_bonus.prc \\hr.betwnstr.fnc \\hr.employees_test.tbl \\tests \\hotel.test_add_room_content.pkb \\hotel.test_add_room_content.pks \\hotel.test_remove_rooms_by_name.pkb \\hotel.test_remove_rooms_by_name.pks \\hr.test_award_bonus.pkb \\hr.test_award_bonus.pks \\hr.test_betwnstr.pkb \\hr.test_betwnstr.pks By default, utPLSQL will convert file paths into database objects using the following regular expression /(((\\w|[$#])+)\\.)?((\\w|[$#])+)\\.(\\w{3})$ object owner (if it is present) is identified by the expression in the second set of brackets object name is identified by the expression in the fourth set of brackets object type is identified by the expression in the sixth set of brackets Note utPLSQL will replace any '\\' with '/' for the purpose of mapping files to objects. The paths shown in the results will remain (contain '\\' where it was present). This is done to simplify the syntax of regular expressions. Regular expression will always use '/' as a directory separator on a file path regardless of whether you're on a Windows or Unix system. Note Below examples assume that you have downloaded latest version of utPLSQL-cli and extracted it into your projects root directory (my_project). The examples assume that you run the utPLSQL-cli from my_project directory. Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_host:db_port/db_service_name ^ -p=hr,hotel ^ -source_path=sources ^ -test_path=tests ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_host:db_port/db_service_name \\ -p = hr,hotel \\ -source_path = sources \\ -test_path = tests \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml The above commands will: - connect as user test_runner - run all utPLSQL v3 tests for users hr , hotel - map database code to project files in sources directory and save code coverage results into coverage.html - map test packages to project files in tests directory and save test results into test_results.xml To better understand the default regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml","title":"File mapping using default parameters"},{"location":"userguide/coverage.html#using-custom-regular-expressions","text":"If your project directory structure is different, you can use additional configuration parameters to tell utPLSQL how the project files are to be mapped into database objects. Example: Using custom regular expressions on a multi-schema project with separate directories for each object owner. C: \\my_project \\sources \\hotel \\add_rooms_content.prc \\remove_rooms_by_name.prc \\rooms.tbl \\hr \\award_bonus.prc \\betwnstr.fnc \\employees_test.tbl \\tests \\hotel \\test_add_room_content.pkb \\test_add_room_content.pks \\test_remove_rooms_by_name.pkb \\test_remove_rooms_by_name.pks \\hr \\test_award_bonus.pkb \\test_award_bonus.pks \\test_betwnstr.pkb \\test_betwnstr.pks The command below will gather coverage and map files to database objects using custom regular expression. Note that the owner/name/type subexpressions don't need to be explicitly specified if they are same as default values ( 2/3/4 ). In the below example, they were specified explicitly only for source_path , test_path doesn't have subexpressions specified and so they are default (2/3/4). Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=hr,hotel ^ -source_path=sources ^ -regex_expression=\"/((\\w+)/)?(\\w+)\\.(\\w{3})$\" ^ -owner_subexpression=2 ^ -name_subexpression=3 ^ -type_subexpression=4 ^ -test_path=tests -regex_expression=\"/((\\w+)/)?(\\w+)\\.(\\w{3})$\" ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml ^ Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_url \\ -source_path = sources \\ -regex_expression = \"/((\\w+)/)?(\\w+)\\.(\\w{3}) $ \" \\ -owner_subexpression = 2 \\ -name_subexpression = 3 \\ -type_subexpression = 4 \\ -test_path = tests -regex_expression = \"/((\\w+)/)?(\\w+)\\.(\\w{3}) $ \" \\ -owner_subexpression = 2 \\ -name_subexpression = 3 \\ -type_subexpression = 4 \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml You can specify different mapping rules for source files and for test files - see utPLSQL-cli readme for details. To better understand the regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml","title":"Using custom regular expressions"},{"location":"userguide/coverage.html#explicitly-specifying-object-owner","text":"When dealing with projects that operate within a single schema the project structure probably doesn't indicate the owner. In such scenarios, you can explicitly specify the object owner for both tests and source code. Example: Single-schema project - no indication of object owner C: \\my_project \\sources \\betwnstr.fnc \\tests \\test_betwnstr.pkb \\test_betwnstr.pks The command below will gather coverage and map files to database objects. For the database objects mapped to souces directory user code_owner will be used. For the database objects mapped to tests directory user tests_owner will be used. Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=tests_owner ^ -source_path=sources -owner=code_owner ^ -test_path=tests -owner=tests_owner ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_url \\ -p = tests_owner \\ -source_path = sources -owner = code_owner \\ -test_path = tests -owner = tests_owner \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml Note When the project folder structure does not provide any information about source code owner and test owner, you can specify the owner for tests and owner for code explicitly. Such project configuration supports only single-owner for source code and single owner for tests. Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml","title":"Explicitly specifying object owner"},{"location":"userguide/coverage.html#custom-mapping-of-object-types","text":"By default, when mapping project files to database objects, utPLSQL will identify the object type by file extension. The table below represents the default mapping of file extensions to database object types. file extension object type tpb type body pkb package body bdy package body trg trigger fnc function prc procedure If your project naming convention differs and your file extensions do not match the above, or you simply name all of your files with .sql suffix, you can still use utPLSQL, but you need to provide custom mapping for object types. Example: Multi-schema project with separate directories for each object owner and object type C: \\my_project \\sources \\hotel \\functions \\packages \\packages_bodies \\procedures \\add_rooms_content.sql \\remove_rooms_by_name.sql \\tables \\rooms.sql \\triggers \\types \\type_bodies \\hr \\functions \\betwnstr.sql \\packages \\package_bodies \\procedures \\award_bonus.sql \\tables \\employees_test.sql \\triggers \\types \\types_bodies \\tests \\hotel \\packages \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\packages_bodies \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\hr \\packages \\test_award_bonus.sql \\test_betwnstr.sql \\packages_bodies \\test_award_bonus.sql \\test_betwnstr.sql Windows: utPLSQL-cli\\bin\\utplsql run test_runner/pass@db_url ^ -p=hr,hotel ^ -source_path=sources ^ -regex_expression=\"/(\\w+)/(\\w+)/(\\w+)\\..{3}$\" ^ -type_mapping=\"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" ^ -owner_subexpression=1 ^ -name_subexpression=3 ^ -type_subexpression=2 ^ -test_path=tests -regex_expression=\"/(\\w+)/(\\w+)/(\\w+)\\..{3}$\" ^ -type_mapping=\"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" ^ -owner_subexpression=1 ^ -name_subexpression=3 ^ -type_subexpression=2 ^ -f=ut_coverage_html_reporter -o=coverage.html ^ -f=ut_sonar_test_reporter -o=test_results.xml Bash: utPLSQL-cli/bin/utplsql run test_runner/pass@db_urll \\ -p = hr,hotel \\ -source_path = sources \\ -regex_expression = \"/(\\w+)/(\\w+)/(\\w+)\\..{3} $ \" \\ -type_mapping = \"packages_bodies=PACKAGE BODY/types_bodies=TYPE BODY/triggers=TRIGGER/procedures=PROCEDURE/functions=FUNCTION\" \\ -owner_subexpression = 1 \\ -name_subexpression = 3 \\ -type_subexpression = 2 \\ -test_path = tests -regex_expression = \"/(\\w+)/(\\w+)/(\\w+)\\..{3} $ \" \\ -type_mapping = \"body=PACKAGE BODY/type_body=TYPE BODY/trigger=TRIGGER\" \\ -owner_subexpression = 1 \\ -name_subexpression = 3 \\ -type_subexpression = 2 \\ -f = ut_coverage_html_reporter -o = coverage.html \\ -f = ut_sonar_test_reporter -o = test_results.xml The parameter type_mapping accepts a list of a key-value pairs representing a mapping of regex subexpression to database object type. To better understand the regular expression used, have a look here . Tested code is mapped to files in coverage.html Unit test code is mapped to files in test_results.xml","title":"Custom mapping of object types"},{"location":"userguide/coverage.html#object-file-mapping-rules","text":"In order to allow deterministic and accurate mapping of database source-code into project files, the project directory and file structure needs to meet certain criteria. - Source code is kept separate from test code (separate directories) - Each database (source-code) object is stored in an individual file. Package/type specification is kept separate from its body. - File name (file path) contains the name of database object - Each file-path clearly identifies object type (by file extension) - Each file contains representation of database object \"as is\". No extra commands (like set echo off ALTER SESSION SET PLSQL_CCFLAGS = 'debug:TRUE'; ) or blank lines are present before CREATE TYPE , CREATE TYPE etc. - When project is spanning across multiple database schemes, each file-path clearly and uniformly identifies object owner","title":"Object-file mapping rules"},{"location":"userguide/coverage.html#file-mapping-from-sql","text":"The ut.run command provides interface to map project into database objects when executing tests. While it is much easier to perform mapping directly from command line, it is possible to achieve similar functionality from any SQL client. The main differences when using the ut.run(...) command, will be: - you can only use single reporter and therefore will get only one report from test execution - you need to provide fill list of project files rather than point to sources and tests directories Example project directory structure. C: \\my_project \\sources \\hotel \\functions \\packages \\packages_bodies \\procedures \\add_rooms_content.sql \\remove_rooms_by_name.sql \\tables \\rooms.sql \\triggers \\types \\type_bodies \\hr \\functions \\betwnstr.sql \\packages \\package_bodies \\procedures \\award_bonus.sql \\tables \\employees_test.sql \\triggers \\types \\types_bodies \\tests \\hotel \\packages \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\packages_bodies \\test_add_room_content.sql \\test_remove_rooms_by_name.sql \\hr \\packages \\test_award_bonus.sql \\test_betwnstr.sql \\packages_bodies \\test_award_bonus.sql \\test_betwnstr.sql To execute all tests and map database source code into source file names you could use the following command in any SQL client: begin ut . run ( ut_varchar2_list ( 'hr' , 'hotel' ), ut_coverage_html_reporter (), a_source_file_mappings => ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'sources\\hotel\\procedures\\add_rooms_content.sql' , 'sources\\hotel\\procedures\\remove_rooms_by_name.sql' , 'sources\\hotel\\tables\\rooms.sql' , 'sources\\hr\\functions\\betwnstr.sql' , 'sources\\hr\\procedures\\award_bonus.sql' , 'sources\\hr\\tables\\employees_test.sql' ), a_regex_pattern => '/(\\w+)/(\\w+)/(\\w+)\\..{3}$' , a_object_owner_subexpression => 1 , a_object_name_subexpression => 3 , a_object_type_subexpression => 2 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'packages_bodies' , 'PACKAGE BODY' ), ut_key_value_pair ( 'types_bodies' , 'TYPE BODY' ), ut_key_value_pair ( 'triggers' , 'TRIGGER' ), ut_key_value_pair ( 'procedures' , 'PROCEDURE' ), ut_key_value_pair ( 'functions' , 'FUNCTION' ) ) ) ); end ; To execute all tests and map database tests code into test file names you could use the following command in any SQL client: begin ut . run ( ut_varchar2_list ( 'hr' , 'hotel' ), ut_sonar_test_reporter (), a_test_file_mappings => ut_file_mapper . build_file_mappings ( a_file_paths => ut_varchar2_list ( 'tests\\hotel\\packages\\test_add_room_content.sql' , 'tests\\hotel\\packages\\test_remove_rooms_by_name.sql' , 'tests\\hotel\\packages_bodies\\test_add_room_content.sql' , 'tests\\hotel\\packages_bodies\\test_remove_rooms_by_name.sql' , 'tests\\hr\\packages\\test_award_bonus.sql' , 'tests\\hr\\packages\\test_betwnstr.sql' , 'tests\\hr\\packages_bodies\\test_award_bonus.sql' , 'tests\\hr\\packages_bodies\\test_betwnstr.sql' ), a_regex_pattern => '/(\\w+)/(\\w+)/(\\w+)\\..{3}$' , a_object_owner_subexpression => 1 , a_object_name_subexpression => 3 , a_object_type_subexpression => 2 , a_file_to_object_type_mapping => ut_key_value_pairs ( ut_key_value_pair ( 'packages_bodies' , 'PACKAGE BODY' ), ut_key_value_pair ( 'types_bodies' , 'TYPE BODY' ), ut_key_value_pair ( 'triggers' , 'TRIGGER' ), ut_key_value_pair ( 'procedures' , 'PROCEDURE' ), ut_key_value_pair ( 'functions' , 'FUNCTION' ) ) ) ); end ;","title":"File mapping from SQL"},{"location":"userguide/coverage.html#reporting-coverage-outside-utplsql-and-in-parallel-sessions","text":"utPSLQL allows fo standalone reporting code coverage across multiple database sessions. This functionality enables coverage reporting for external testing tools. Following API calls enable the standalone coverage reporting. ut_runner.coverage_start( coverage_run_id ); - initiates code coverage within a session ut_runner.coverage_stop(); - stops gathering of code coverage within a session .get_report( ... ) - coverage reporters function producing coverage report as pipelined data-set (to be used in SQL query) .get_report_cursor( ... ) - coverage reporters function producing coverage report as ref-cursor Example: --SESSION 1 -- gather coverage on code using specific coverage_run_id value declare l_coverage_run_id raw ( 32 ); begin l_coverage_run_id : = 'A6AA5B7361251CE6E053020011ACA055' ; -- l_coverage_run_id := sys_guid; ut_runner . coverage_start ( l_coverage_run_id ); --The code to gather coverage on goes here ut_runner . coverage_stop (); end ; / --SESSION 2 -- alternative approach -- gather coverage on code using specific coverage_run_id value exec ut_runner . coverage_start ( 'A6AA5B7361251CE6E053020011ACA055' ); --The code to gather coverage on goes here exec ut_runner . coverage_stop (); --SESSION 1 or SESSION2 2 or SESSION 3 -- run after calls in SESSION 1 & 2 are finished -- retrieve coverage report in HTML format coverage_run_id value select * from table ( ut_coverage_html_reporter (). get_report ( a_coverage_options => ut_coverage_options ( coverage_run_id => 'A6AA5B7361251CE6E053020011ACA055' ) ) ); --SESSION 1 or SESSION2 2 or SESSION 3 -- run after calls in SESSION 1 & 2 are finished declare l_results_cursor sys_refcursor ; begin l_results_cursor : = ut_coverage_html_reporter (). get_report_cursor ( a_coverage_options => ut_coverage_options ( coverage_run_id => 'A6AA5B7361251CE6E053020011ACA055' ) ); --fetch and process the cursor results close l_results_cursor ; end ; / Specification of parameters for get_report and get_report_cursor function get_report ( a_coverage_options ut_coverage_options , a_client_character_set varchar2 : = null ) return ut_varchar2_rows pipelined function get_report_cursor ( a_coverage_options ut_coverage_options , a_client_character_set varchar2 : = null ) return sys_refcursor ut_coverage_options ( coverage_run_id raw , schema_names ut_varchar2_rows : = null , exclude_objects ut_varchar2_rows : = null , include_objects ut_varchar2_rows : = null , file_mappings ut_file_mappings : = null include_schema_expr varchar2 ( 4000 ) : = null , include_object_expr varchar2 ( 4000 ) : = null , exclude_schema_expr varchar2 ( 4000 ) : = null , exclude_object_expr varchar2 ( 4000 ) : = null ); The a_client_character_set is used to provide character set to the report. Coverage reports in XML and HTML format include this information to assure that HMTL/XML encoding tag is aligned with encoding of the report produced. Use this parameter to provide encoding of your client application. The a_coverage_options parameter is used to control the scope and formatting of data returned by report. ut_coverage_options object accepts the following arguments coverage_run_id - identifier of coverage run to generate report for - data-type RAW(32) schema_names - optional - list of schema names to include in coverage report - data-type UT_VARCHAR2_ROWS exclude_objects - optional - list of object names to exclude from report - data-type UT_VARCHAR2_ROWS include_objects - optional - list of object names to gather coverage on - data-type UT_VARCHAR2_ROWS file_mappings - optional - list of schema names to gather coverage on - data-type UT_FILE_MAPPINGS include_schema_expr - optional - regular expression to match against schema name to include in coverage - data-type VARCHAR2(4000) include_object_expr - optional - regular expression to match against object name to include in coverage - data-type VARCHAR2(4000) exclude_schema_expr - optional - regular expression to match against schema name to exclude in coverage - data-type VARCHAR2(4000) exclude_object_expr - optional - regular expression to match against object name to exclude in coverage - data-type VARCHAR2(4000) coverage_run_id parameter identifies a common coverage run. The valid value type for that parameter is RAW(32). It is recommended to use sys_guid() to generate a common, unique identifier for a specific coverage run. If the identifier is not unique, previous runs of coverage that used the same coverage_run_id will be aggregated to the resulting coverage report. For details on the meaning of schema_names , exclude_objects , include_objects , file_mappings see sections above. Note that data-types of include/exclude/schema lists are different when calling ut.run vs. calling get_report/get_report_cursor .","title":"Reporting coverage outside utPLSQL and in parallel sessions"},{"location":"userguide/exception-reporting.html","text":"The utPLSQL is responsible for handling exceptions wherever they occur in the test run. utPLSQL is trapping most of the exceptions so that the test execution is not affected by individual tests or test packages throwing an exception. The framework provides a full stacktrace for every exception that was thrown. The stacktrace is clean and does not include any utPLSQL library calls in it. To achieve rerunability, the package state invalidation exceptions (ORA-04068, ORA-04061) are not handled and test execution will be interrupted if such exceptions are encountered. This is because of how Oracle behaves on those exceptions. Test execution can fail for different reasons. The failures on different exceptions are handled as follows: A test package without body - each --%test is reported as failed with exception, nothing is executed A test package with invalid body - each --%test is reported as failed with exception, nothing is executed A test package with invalid spec - package is not considered a valid unit test package and is excluded from execution. When trying to run a test package with invalid spec explicitly, exception is raised. Only valid specifications are parsed for annotations A test package that is raising an exception in --%beforeall - each --%test is reported as failed with exception, --%test , --%beforeeach , --%beforetest , --%aftertest and --%aftereach are not executed. --%afterall is executed to allow cleanup of whatever was done in --%beforeall A test package that is raising an exception in --%beforeeach - each --%test is reported as failed with exception, --%test , --%beforetest and --%aftertest is not executed. The --%aftereach and --%afterall blocks are getting executed to allow cleanup of whatever was done in --%before... blocks A test package that is raising an exception in --%beforetest - the --%test is reported as failed with exception, --%test is not executed. The --%aftertest , --%aftereach and --%afterall blocks are getting executed to allow cleanup of whatever was done in --%before... blocks A test package that is raising an exception in --%test - the --%test is reported as failed with exception. The execution of other blocks continues normally A test package that is raising an exception in --%aftertest - the --%test is reported as failed with exception. The execution of other blocks continues normally A test package that is raising an exception in --%aftereach - each --%test is reported as failed with exception. A test package that is raising an exception in --%afterall - all blocks of the package are executed, as the --%afterall is the last step of package execution. Exception in --%afterall is not affecting test results. A warning with exception stacktrace is displayed in the summary Example of reporting with exception thrown in %beforetest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 39 ORA-06512: at line 6 Finished in ,039346 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %test : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 48 ORA-06512: at line 6 Finished in ,035726 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftertest : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content Raises exception when null room name given Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 42 ORA-06512: at line 6 Finished in ,045523 seconds 3 tests, 0 failed, 1 errored, 0 ignored. Example of reporting with exception thrown in %aftereach : Remove rooms by name Removes a room without content in it (FAILED - 1) Does not remove room when it has content (FAILED - 2) Raises exception when null room name given (FAILED - 3) Failures: 1) remove_empty_room error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 2) room_with_content error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 3) null_room_name error: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 31 ORA-06512: at line 6 Finished in ,034863 seconds 3 tests, 0 failed, 3 errored, 0 ignored. Example of reporting with exception thrown in %afterall : Remove rooms by name Removes a room without content in it Does not remove room when it has content Raises exception when null room name given Warnings: 1) test_remove_rooms_by_name - Afterall procedure failed: ORA-20001: Test exception ORA-06512: at \"UT3.TEST_REMOVE_ROOMS_BY_NAME\", line 35 ORA-06512: at line 6 Finished in ,044902 seconds 3 tests, 0 failed, 0 errored, 0 ignored. 1 warning(s)","title":"Error handling and reporting"},{"location":"userguide/expectations.html","text":"Expectation concepts \u00b6 Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. utPLSQL uses expectations and matchers to perform the check on the data. Example of an expectation begin ut . expect ( 'the tested value' ). to_equal ( 'the expected value' ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'the tested value' (varchar2) was expected to equal: 'the expected value' (varchar2) at \"anonymous block\", line 2 Expectation is a combination of: - the expected value - optional custom message for the expectation - the matcher used to perform comparison - the matcher parameters (actual value), depending on the matcher type Matcher defines the comparison operation to be performed on expected (and actual) value. Pseudo-code: ut . expect ( a_actual { data - type } [, a_message { varchar2 } ] ). to_ ( { matcher } ); ut . expect ( a_actual { data - type } [, a_message { varchar2 } ] ). not_to ( { matcher } ); Expectations provide two variants of syntax that you can use. Both variants are functionally-equal but give different usage flexibility. Syntax where matcher is passed as parameter to the expectation: ut . expect ( a_actual ). to_ ( { matcher } ); ut . expect ( a_actual ). not_to ( { matcher } ); -- example ut . expect ( 1 ). to_ ( be_null () ); Shortcut syntax, where matcher is directly part of expectation: ut . expect ( a_actual ). to_ { matcher } ; ut . expect ( a_actual ). not_to_ { matcher } ; --example ut . expect ( 1 ). to_ ( be_null () ); When using shortcut syntax you don't need to surround matcher with brackets. Shortcut syntax is provided for convenience. If you would like to perform more dynamic checks in your code, you could pass the matcher into a procedure like in the below example: declare procedure do_check ( p_actual varchar2 , p_matcher ut_matcher ) is begin ut . expect ( p_actual ). to_ ( p_matcher ); end ; begin do_check ( 'a' , equal ( 'b' ) ); do_check ( 'Alibaba' , match ( 'ali' , 'i' ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'a' (varchar2) was expected to equal: 'b' (varchar2) at \"anonymous block\", line 4 at \"anonymous block\", line 7 SUCCESS Actual: 'Alibaba' (varchar2) was expected to match: 'ali' , modifiers 'i' Note: The examples in the document will be only using shortcut syntax, to keep the document brief. Using expectations \u00b6 There are two ways to use expectations: - by invoking utPLSQL framework to execute suite(s) of utPLSQL tests - without invoking the utPLSQL framework - running expectations standalone Running expectations within utPLSQL framework \u00b6 When expectations are ran as a part of a test suite, the framework tracks: - status of each expectation - outcomes (messages) produced by each expectation - call stack to each expectation In this case: - expectation results of are not sent directly to dbms_output - utPLSQL Reporters used when running suite decide on how the expectation results are formatted and displayed Example of test suite with an expectation: create or replace package test_divide as --%suite(Divide two numbers) --%test(Returns result when divisor is not zero) procedure divide_6_by_2 ; --%test(Throws exception when divisor is zero) --%throws(zero_divide) procedure divide_by_0_throws ; end ; / create or replace package body test_divide as procedure divide_6_by_2 is begin ut . expect ( 6 / 2 ). to_equal ( 3 ); end ; procedure divide_by_0_throws is begin ut . expect ( 6 / 0 ). to_be_not_null (); end ; end ; / exec ut . run ( 'test_divide' ); drop package test_divide ; Produces following outputs: Package TEST_DIVIDE compiled Package Body TEST_DIVIDE compiled Divide two numbers Returns result when divisor is not zero [.003 sec] Throws exception when divisor is zero [.003 sec] Finished in .009774 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) PL/SQL procedure successfully completed. Package TEST_DIVIDE dropped. Please read about different options for running test suites . Running expectations outside utPLSQL framework \u00b6 When expectations are invoked outside of utPLSQL framework the outputs from expectations are redirected straight to dbms_output . Note: The output from expectation contains call stack trace only when expectation fails. Source code of the line which called the expectation is only reported when the line is part of in-database code (package) and the user calling expectation has privileges to see that source code. Important Please do not use expectations as part of your production code. They are not designed to be used as part of your code. Expectations are meant to be used only as part of your day-to-day testing activities. Note: The examples in the document will be only using standalone expectations, to keep the document brief. Matchers \u00b6 utPLSQL provides the following matchers to perform checks on the expected and actual values. be_between( a_upper_bound {data-type}, a_lower_bound {data-type} ) be_empty() be_false() be_greater_than( a_expected {data-type} ) be_greater_or_equal( a_expected {data-type} ) be_less_or_equal( a_expected {data-type} ) be_less_than( a_expected {data-type} ) be_like( a_mask {varchar2} [, a_escape_char {varchar2}] ) be_not_null() be_null() be_true() equal( a_expected {data-type} [, a_nulls_are_equal {boolean}] ) contain( a_expected {data-type}) have_count( a_expected {integer} ) match( a_patter {varchar2} [, a_modifiers {varchar2}] ) Providing a custom message \u00b6 You can provide a custom failure message by passing it as the second parameter to the expectation. ut.expect( a_actual {data-type}, a_message {varchar2} ).to_{matcher} Example: exec ut . expect ( 'supercat' , 'checked superhero-animal was not a dog' ). to_equal ( 'superdog' ); Returns following output via DBMS_OUTPUT: FAILURE \"checked superhero-animal was not a dog\" Actual: 'supercat' (varchar2) was expected to equal: 'superdog' (varchar2) at \"anonymous block\", line 1 If the message is provided, it is being added to the normal failure message returned by the matcher. This is mostly useful when your expectations accept dynamic content, as you can provide additional context to make failing test results more readable. In most cases, there is no need to provide custom message to expectation. This is because utPLSQL identifies: - The test used to execute the expectation - The line number where the expectation is placed in your test code - The line text of the expectation Custom message is useful, if your expectation is placed in a shared procedure to perform a check and your test is using the procedure multiple times. Example: create or replace package shared_expectation_test is --%suite --%test procedure the_test ; end ; / create or replace package body shared_expectation_test is procedure table_is_empty ( p_table_name varchar2 ) is l_count integer ; begin execute immediate 'select count(*) from ' || p_table_name into l_count ; ut . expect ( l_count , 'Checking table ' || p_table_name ). to_equal ( 0 ); end ; procedure the_test is begin table_is_empty ( 'ALL_USERS' ); table_is_empty ( 'ALL_TABLES' ); end ; end ; / exec ut . run ( 'shared_expectation_test' ); Returns following output via DBMS_OUTPUT: shared_expectation_test the_test [.064 sec] (FAILED - 1) Failures: 1) the_test \"Checking table ALL_USERS\" Actual: 28 (number) was expected to equal: 0 (number) at \"UT3_USER.SHARED_EXPECTATION_TEST.TABLE_IS_EMPTY\", line 6 ut.expect( l_count, 'Checking table '||p_table_name ).to_equal(0); at \"UT3_USER.SHARED_EXPECTATION_TEST.THE_TEST\", line 11 \"Checking table ALL_TABLES\" Actual: 55 (number) was expected to equal: 0 (number) at \"UT3_USER.SHARED_EXPECTATION_TEST.TABLE_IS_EMPTY\", line 6 ut.expect( l_count, 'Checking table '||p_table_name ).to_equal(0); at \"UT3_USER.SHARED_EXPECTATION_TEST.THE_TEST\", line 12 Finished in .066344 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) In the tests results window you can see the list of failed expectations for a test as well as: - the additional message for expectation - the reason why the expectation failed - the line number of the expectation - the line text of the expectations - the call stack for the expectation (in the example it's the lines that called the procedure table_is_empty ) Negating a matcher \u00b6 Expectations provide a very convenient way to perform a check on a negated matcher. Syntax to check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax to check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: declare l_actual boolean ; begin ut . expect ( l_actual ). to_be_true (); ut . expect ( l_actual ). not_to_be_true (); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: NULL (boolean) was expected to be true at \"anonymous block\", line 4 FAILURE Actual: NULL (boolean) was expected not to be true at \"anonymous block\", line 5 Since NULL is neither true nor false , both expectations will report failure. Supported data types \u00b6 The matrix below illustrates the data types supported by different matchers. Matcher blob boolean clob date number timestamp timestamp with timezone timestamp with local timezone varchar2 interval year to month interval day to second cursor nested table / varray object json be_not_null X X X X X X X X X X X X X X X be_null X X X X X X X X X X X X X X X be_false X be_true X be_greater_than X X X X X X X be_greater_or_equal X X X X X X X be_less_or_equal X X X X X X X be_less_than X X X X X X X be_between X X X X X X X X equal X X X X X X X X X X X X X X X contain X X X match X X be_like X X be_empty X X X X X have_count X X X be_within().of_() X X X X X be_within_pct().of_() X Expecting exceptions \u00b6 Testing is not limited to checking for happy-path scenarios. When writing tests, you often want to validate that in specific scenarios, an exception is thrown. Use the --%throws annotation, to test for expected exceptions. Example: create or replace function divide ( x varchar2 , y varchar2 ) return number is begin return x / y ; end ; / create or replace package test_divide as --%suite(Divide function) --%test(Throws divisor equal) --%throws(-01476) procedure raises_divisor_exception ; end ; / create or replace package body test_divide is procedure raises_divisor_exception is x integer ; begin x : = divide ( 6 , 0 ); end ; end ; / exec ut . run ( 'test_divide' ); Returns following output via DBMS_OUTPUT: Divide function Throws divisor equal [.007 sec] Finished in .009229 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) For more details see documentation of the --%throws annotation. Matchers \u00b6 You can choose different matchers to validate that your PL/SQL code is working as expected. be_between \u00b6 Validates that the actual value is between the lower and upper bound. Example: declare l_timestamp timestamp : = current_timestamp ; l_timestamp_tz timestamp with time zone : = systimestamp ; l_timestamp_ltz timestamp with local time zone : = systimestamp ; l_interval_ds interval day to second : = interval '1' second ; l_interval_ym interval year to month : = interval '1' year ; begin ut . expect ( 3 ). to_be_between ( 1 , 3 ); ut . expect ( 5 ). to_ ( be_between ( 1 , 3 ) ); ut . expect ( 3 ). not_to_be_between ( 1 , 3 ); ut . expect ( 5 ). not_to ( be_between ( 1 , 3 ) ); ut . expect ( sysdate ). to_be_between ( sysdate , sysdate + 1 ); ut . expect ( l_timestamp ). to_be_between ( l_timestamp , l_timestamp ); ut . expect ( systimestamp ). to_be_between ( l_timestamp_tz , systimestamp ); ut . expect ( systimestamp ). to_be_between ( l_timestamp_ltz , l_timestamp_ltz ); ut . expect ( l_interval_ds ). to_be_between ( interval '0.1' second , interval '1' day ); ut . expect ( l_interval_ym ). to_be_between ( interval '12' month , interval '12' year ); ut . expect ( 'Abb' ). to_be_between ( 'Aba' , 'Abc' ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 3 (number) was expected to be between: 1 and 3 FAILURE Actual: 5 (number) was expected to be between: 1 and 3 at \"anonymous block\", line 9 FAILURE Actual: 3 (number) was expected not to be between: 1 and 3 at \"anonymous block\", line 10 SUCCESS Actual: 5 (number) was expected not to be between: 1 and 3 SUCCESS Actual: 2019-07-07T21:25:27 (date) was expected to be between: 2019-07-07T21:25:27 and 2019-07-08T21:25:27 SUCCESS Actual: 2019-07-07T22:25:27.701546000 (timestamp) was expected to be between: 2019-07-07T22:25:27.701546000 and 2019-07-07T22:25:27.701546000 SUCCESS Actual: 2019-07-07T21:25:27.705768000 +00:00 (timestamp with time zone) was expected to be between: 2019-07-07T21:25:27.701596000 +00:00 and 2019-07-07T21:25:27.705808000 +00:00 FAILURE The matcher 'be between' cannot be used with data type (timestamp with time zone). at \"anonymous block\", line 15 SUCCESS Actual: +000000000 00:00:01.000000000 (interval day to second) was expected to be between: +000000000 00:00:00.100000000 and +000000001 00:00:00.000000000 SUCCESS Actual: +000000001-00 (interval year to month) was expected to be between: +000000001-00 and +000000012-00 SUCCESS Actual: 'Abb' (varchar2) was expected to be between: 'Aba' and 'Abc' be_empty \u00b6 Unary matcher that validates if the provided dataset is empty. Can be used with BLOB , CLOB , refcursor or nested table / varray passed as ANYDATA Note: BLOB/CLOB that is initialized is not NULL but it is actually equal to empty_blob() / empty_clob() . Example: declare l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 0 = 1 ; ut . expect ( l_cursor ). to_be_empty (); ut . expect ( anydata . convertCollection ( ut_varchar2_list ()) ). to_ ( be_empty () ); ut . expect ( empty_clob () ). not_to_be_empty (); ut . expect ( empty_blob () ). not_to ( be_empty () ); ut . expect ( 1 ). not_to ( be_empty () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: (refcursor [ count = 0 ]) Data-types: <DUMMY>VARCHAR2</DUMMY> Data: was expected to be empty SUCCESS Actual: (ut3.ut_varchar2_list [ count = 0 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: was expected to be empty FAILURE Actual: EMPTY (clob) was expected not to be empty at \"anonymous block\", line 7 FAILURE Actual: EMPTY (blob) was expected not to be empty at \"anonymous block\", line 8 FAILURE The matcher 'be empty' cannot be used with data type (number). at \"anonymous block\", line 9 be_false \u00b6 Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); ut . expect ( ( 1 = 1 ) ). to_ ( be_false () ); ut . expect ( ( 1 = 0 ) ). not_to_be_false (); ut . expect ( ( 1 = 1 ) ). not_to ( be_false () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: FALSE (boolean) was expected to be false FAILURE Actual: TRUE (boolean) was expected to be false at \"anonymous block\", line 3 FAILURE Actual: FALSE (boolean) was expected not to be false at \"anonymous block\", line 4 SUCCESS Actual: TRUE (boolean) was expected not to be false be_greater_or_equal \u00b6 Checks if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate + 1 ) ); ut . expect ( sysdate ). not_to_be_greater_or_equal ( sysdate - 1 ); ut . expect ( sysdate ). not_to ( be_greater_or_equal ( sysdate + 1 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 2019-07-07T22:43:29 (date) was expected to be greater or equal: 2019-07-06T22:43:29 (date) FAILURE Actual: 2019-07-07T22:43:29 (date) was expected to be greater or equal: 2019-07-08T22:43:29 (date) at \"anonymous block\", line 3 FAILURE Actual: 2019-07-07T22:43:29 (date) was expected not to be greater or equal: 2019-07-06T22:43:29 (date) at \"anonymous block\", line 4 SUCCESS Actual: 2019-07-07T22:43:29 (date) was expected not to be greater or equal: 2019-07-08T22:43:29 (date) be_greater_than \u00b6 Checks if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); ut . expect ( 0 ). to_ ( be_greater_than ( 1 ) ); ut . expect ( 2 ). not_to_be_greater_than ( 1 ); ut . expect ( 0 ). not_to ( be_greater_than ( 1 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 2 (number) was expected to be greater than: 1 (number) FAILURE Actual: 0 (number) was expected to be greater than: 1 (number) at \"anonymous block\", line 3 FAILURE Actual: 2 (number) was expected not to be greater than: 1 (number) at \"anonymous block\", line 4 SUCCESS Actual: 0 (number) was expected not to be greater than: 1 (number) be_less_or_equal \u00b6 Checks if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); ut . expect ( 4 ). to_ ( be_less_or_equal ( 3 ) ); ut . expect ( 3 ). not_to_be_less_or_equal ( 3 ); ut . expect ( 4 ). not_to ( be_less_or_equal ( 3 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 3 (number) was expected to be less or equal: 3 (number) FAILURE Actual: 4 (number) was expected to be less or equal: 3 (number) at \"anonymous block\", line 3 FAILURE Actual: 3 (number) was expected not to be less or equal: 3 (number) at \"anonymous block\", line 4 SUCCESS Actual: 4 (number) was expected not to be less or equal: 3 (number) be_less_than \u00b6 Checks if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); ut . expect ( 0 ). to_ ( be_less_than ( 2 ) ); ut . expect ( 3 ). not_to_be_less_than ( 2 ); ut . expect ( 0 ). not_to ( be_less_than ( 2 ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 3 (number) was expected to be less than: 2 (number) at \"anonymous block\", line 2 SUCCESS Actual: 0 (number) was expected to be less than: 2 (number) SUCCESS Actual: 3 (number) was expected not to be less than: 2 (number) FAILURE Actual: 0 (number) was expected not to be less than: 2 (number) at \"anonymous block\", line 5 be_like \u00b6 Validates that the actual value is like the expected expression. Syntax: ut.expect( a_actual ).to_be_like( a_mask [, a_escape_char] ) Parameters a_mask and a_escape_char represent valid parameters of the Oracle LIKE condition . If you use Oracle Database version 11.2.0.4, you may run into Oracle Bug 14402514: WRONG RESULTS WITH LIKE ON CLOB USING ESCAPE CHARACTER. In this case we recommend to use match instead of be_like . Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem%' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem\\_i%' , '\\' ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( 'Lor_m%' ) ); ut . expect ( 'Lorem_impsum' ). not_to_be_like ( '%rem%' ); ut . expect ( 'Lorem_impsum' ). not_to ( be_like ( '%reM%' ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: '%rem%' SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: '%rem\\_i%' , escape '\\' SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: 'Lor_m%' FAILURE Actual: 'Lorem_impsum' (varchar2) was expected not to be like: '%rem%' at \"anonymous block\", line 5 SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected not to be like: '%reM%' be_not_null \u00b6 Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); ut . expect ( to_clob ( '' ) ). to_ ( be_not_null () ); ut . expect ( to_clob ( 'ABC' ) ). not_to_be_not_null (); ut . expect ( '' ). not_to ( be_not_null () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 'ABC' (clob) was expected to be not null FAILURE Actual: NULL (clob) was expected to be not null at \"anonymous block\", line 3 FAILURE Actual: 'ABC' (clob) was expected not to be not null at \"anonymous block\", line 4 SUCCESS Actual: NULL (varchar2) was expected not to be not null be_null \u00b6 Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( '' ). to_be_null (); ut . expect ( 0 ). to_ ( be_null () ); ut . expect ( '' ). not_to_be_null (); ut . expect ( 0 ). not_to ( be_null () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: NULL (varchar2) was expected to be null FAILURE Actual: 0 (number) was expected to be null at \"anonymous block\", line 3 FAILURE Actual: NULL (varchar2) was expected not to be null at \"anonymous block\", line 4 SUCCESS Actual: 0 (number) was expected not to be null be_true \u00b6 Unary matcher that validates if the provided value is true. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_true (); ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); ut . expect ( ( 1 = 0 ) ). not_to_be_true (); ut . expect ( ( 1 = 1 ) ). not_to ( be_true () ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: FALSE (boolean) was expected to be true at \"anonymous block\", line 2 SUCCESS Actual: TRUE (boolean) was expected to be true SUCCESS Actual: FALSE (boolean) was expected not to be true FAILURE Actual: TRUE (boolean) was expected not to be true at \"anonymous block\", line 5 have_count \u00b6 Unary matcher that validates if the provided dataset count is equal to expected value. Can be used with refcursor , json or table type Usage: declare l_cursor sys_refcursor ; l_collection ut_varchar2_list ; begin open l_cursor for select * from dual connect by level <= 10 ; ut . expect ( l_cursor ). to_have_count ( 10 ); open l_cursor for select rownum from xmltable ( '1 to 5' ); ut . expect ( l_cursor ). to_ ( have_count ( 10 ) ); l_collection : = ut_varchar2_list ( 'a' , 'a' , 'b' ); ut . expect ( anydata . convertCollection ( l_collection ) ). not_to_have_count ( 10 ); ut . expect ( anydata . convertCollection ( l_collection ) ). not_to ( have_count ( 3 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: (refcursor [ count = 10 ]) was expected to have [ count = 10 ] FAILURE Actual: (refcursor [ count = 5 ]) was expected to have [ count = 10 ] at \"anonymous block\", line 8 SUCCESS Actual: ut3.ut_varchar2_list [ count = 3 ] was expected not to have [ count = 10 ] FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected not to have [ count = 3 ] at \"anonymous block\", line 11 match \u00b6 Validates that the actual value is matching the expected regular expression. Syntax: ut.expect( a_actual ).to_match( a_pattern [, a_modifiers] ); Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle REGEXP_LIKE condition Usage: begin ut . expect ( '123-456-ABcd' ). to_match ( '\\d{3}-\\d{3}-[a-z]{4}' , 'i' ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ) ; ut . expect ( '123-456-ABcd' ). not_to_match ( '\\d{3}-\\d{3}-[a-z]{4}' , 'i' ); ut . expect ( 'some value' ). not_to ( match ( '^some.*' ) ) ; end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: '123-456-ABcd' (varchar2) was expected to match: '\\d{3}-\\d{3}-[a-z]{4}' , modifiers 'i' SUCCESS Actual: 'some value' (varchar2) was expected to match: '^some.*' FAILURE Actual: '123-456-ABcd' (varchar2) was expected not to match: '\\d{3}-\\d{3}-[a-z]{4}' , modifiers 'i' at \"anonymous block\", line 4 FAILURE Actual: 'some value' (varchar2) was expected not to match: '^some.*' at \"anonymous block\", line 5 equal \u00b6 The equal matcher is very restrictive. Test using this matcher succeeds only when the compared data-types are exactly the same. If you are comparing a varchar2 to a number , it will fail even if the text contains the same numeric value as the number. The matcher will also fail when comparing a timestamp to a timestamp with timezone data-type etc. The matcher enables detection of data-type changes. If you expect your variable to be a number and it is now some other type, the test will fail and give you early indication of a potential problem. To keep it simple, the equal matcher will only succeed if you compare apples to apples. Syntax: ut.expect( a_actual ).to_equal( a_expected [, a_nulls_are_equal])[.advanced_options] Example usage declare l_actual varchar2 ( 20 ); l_expected varchar2 ( 20 ); begin --Arrange l_actual : = 'a dog' ; --Assert ut . expect ( l_actual ). to_equal ( 'other_dog' ); ut . expect ( l_actual ). to_equal ( '' ); ut . expect ( l_actual ). to_equal ( 1 ); l_actual : = null ; ut . expect ( l_actual ). to_equal ( '' ); ut . expect ( l_actual ). to_equal ( '' , a_nulls_are_equal => false ); ut . expect ( l_actual ). not_to_equal ( '' ); ut . expect ( sysdate ). to_equal ( sysdate ); ut . expect ( sysdate ). to_equal ( current_timestamp ); ut . expect ( current_timestamp ). to_equal ( systimestamp ); ut . expect ( to_clob ( 'varchar' ) ). to_equal ( 'varchar' ); ut . expect ( to_blob ( 'aa' ) ). to_equal ( to_blob ( 'aa' ) ); ut . expect ( to_clob ( 'aa' ) ). to_equal ( to_clob ( 'aa' ) ); ut . expect ( to_blob ( 'aa' ) ). to_equal ( to_clob ( 'aa' ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'a dog' (varchar2) was expected to equal: 'other_dog' (varchar2) at \"anonymous block\", line 8 FAILURE Actual: 'a dog' (varchar2) was expected to equal: NULL (varchar2) at \"anonymous block\", line 9 FAILURE Actual (varchar2) cannot be compared to Expected (number) using matcher 'equal'. at \"anonymous block\", line 10 SUCCESS Actual: NULL (varchar2) was expected to equal: NULL (varchar2) FAILURE Actual: NULL (varchar2) was expected to equal: NULL (varchar2) at \"anonymous block\", line 14 FAILURE Actual: NULL (varchar2) was expected not to equal: NULL (varchar2) at \"anonymous block\", line 15 SUCCESS Actual: 2019-07-07T22:50:21 (date) was expected to equal: 2019-07-07T22:50:21 (date) FAILURE Actual (date) cannot be compared to Expected (timestamp with time zone) using matcher 'equal'. at \"anonymous block\", line 17 FAILURE Actual: 2019-07-07T23:50:21.159268000 +01:00 (timestamp with time zone) was expected to equal: 2019-07-07T22:50:21.159296000 +00:00 (timestamp with time zone) at \"anonymous block\", line 18 FAILURE Actual (clob) cannot be compared to Expected (varchar2) using matcher 'equal'. at \"anonymous block\", line 19 SUCCESS Actual: 'AA' (blob) was expected to equal: 'AA' (blob) SUCCESS Actual: 'aa' (clob) was expected to equal: 'aa' (clob) FAILURE Actual (blob) cannot be compared to Expected (clob) using matcher 'equal'. at \"anonymous block\", line 22 Note: Comparing NULLs gives success by default The a_nulls_are_equal parameter controls the behavior of a null = null comparison. To change the behavior of NULL = NULL comparison pass the a_nulls_are_equal => false to the equal matcher. contain \u00b6 This matcher supports only compound data-types comparison. It check if the actual set contains all values of expected subset. When comparing data using the contain matcher, the data-types of columns for compared compound types must be exactly the same. The matcher supports all advanced comparison options as equal like: include , exclude , join_by etc.. The matcher is successful when actual data set contains all of the values from expected results. The matcher will cause a test to fail if actual data set does not contain some of expected values. Example 1. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange open l_actual for select rownum as rn from dual a connect by level < 10 ; open l_expected for select rownum as rn from dual a connect by level < 4 union all select rownum as rn from dual a connect by level < 4 ; --Act ut . expect ( l_actual ). to_contain ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: refcursor [ count = 9 ] was expected to contain: refcursor [ count = 6 ] Diff: Rows: [ 3 differences ] Missing: <RN>1</RN> Missing: <RN>2</RN> Missing: <RN>3</RN> at \"anonymous block\", line 11 When duplicate rows are present in expected data set, actual data set must also include the same amount of duplicates. Example 2. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 1 ); l_expected : = ut_varchar2_list ( 1 , 2 , 1 , 2 ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 9 ] was expected to contain: ut3.ut_varchar2_list [ count = 4 ] Diff: Rows: [ 1 differences ] Missing: <UT_VARCHAR2_LIST>2</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 The negated version of contain ( not_to_contain ) is successful only when all values from expected set are not part of actual (they are disjoint and there is no overlap). Example 3. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' ); l_expected : = ut_varchar2_list ( 'A' , 'B' , 'E' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] Diff: Rows: [ 1 differences ] Missing: <UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 FAILURE Actual: (ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST></ROW> at \"anonymous block\", line 8 Example 4. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' , 'D' ); l_expected : = ut_varchar2_list ( 'A' , 'B' , 'D' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: ut3.ut_varchar2_list [ count = 4 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] FAILURE Actual: (ut3.ut_varchar2_list [ count = 4 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW> at \"anonymous block\", line 8 Example 5. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' ); l_expected : = ut_varchar2_list ( 'D' , 'E' , 'F' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] Diff: Rows: [ 3 differences ] Missing: <UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST> Missing: <UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST> Missing: <UT_VARCHAR2_LIST>F</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 SUCCESS Actual: (ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>F</UT_VARCHAR2_LIST></ROW> to_be_within of \u00b6 Determines whether expected value is within range (tolerance) from another value. The logical formual used for calcuating the matcher is: result := ( abs( expected - actual ) <= distance ) The actual formula used for calculation is more complex to handle different data-types of expected/actual values as well as differnet types of distance value. The matcher will fail if the expected and actual are more than distance apart from each other. The matcher will fail if the dataypes of expected and actual are not the same. The matcher works with data-types: number , date , timestamp , timestamp with time zone , timestamp with local time zone The data-types of compared values must match exactly and if type does not match, the expectation will fail. expected/actual data-type distance data-type number number date interval day to second date interval year to month timestamp interval day to second timestamp interval year to month timestamp with time zone interval day to second timestamp with time zone interval year to month timestamp with local time zone interval day to second timestamp with local time zone interval year to month The distance must be expressed as a non-negative number or non-negative interval. Note: Interval year-to-moth as a distance is giving sucess if the distance between the given dates/timestamps evaluates to value less or equal of the specified interval Keep in mind that a checking for distance of interval '0-1' year to month will actuall be successful if the distance is less than a month and 15 days. This is due to how oracle evaluates conversion between timestamp difference converted to year to month interval . The behavior is similar to a call to months_between() function with results rounded to full monts ie. round(months_between(date, date)) Example 1. begin ut . expect ( 3 ). to_be_within ( 1 ). of_ ( 4 ); end ; / Example 2. begin ut . expect ( 3 ). to_be_within ( 1 ). of_ ( 5 ); end ; / Returns following output via DBMS_OUTPUT: Failures: 1) wihtin_test Actual: 3 (number) was expected to be within 1 of 5 (number) at \"UT3_DEVELOP.UT_BE_WITHIN.OF_\", line 48 l_result.expectation.to_(l_result ); at \"UT3_DEVELOP.TEST_BETWNSTR.WIHTIN_TEST\", line 5 Example 3. begin ut . expect ( sysdate ). to_be_within ( interval '1' day ). of_ ( sysdate + 2 ); end ; / Returns following output via DBMS_OUTPUT: Failures: 1) wihtin_test Actual: 2020-06-07T13:32:58 (date) was expected to be within 1 day of 2020-06-09T13:32:58 (date) at \"UT3_DEVELOP.UT_BE_WITHIN.OF_\", line 55 l_result.expectation.to_(l_result ); at \"UT3_DEVELOP.TEST_BETWNSTR.WIHTIN_TEST\", line 5 to_be_within_pct of \u00b6 Determines whether actual value is within percentage range of expected value. The matcher only works with number data-type. The percentage deviation (distance) must be expressed as a non-negative number. The formula used for calcuation of expectation is: result := ( ( distance ) * expected >= abs( expected - actual ) * 100 ) Example 1. begin ut . expect ( 9 ). to_be_within_pct ( 10 ). of_ ( 10 ); end ; / SUCCESS Actual: 9 (number) was expected to be within 10 % of 10 (number) Comparing cursors, object types, nested tables and varrays \u00b6 utPLSQL is capable of comparing compound data-types including: - ref cursors - object types - nested table/varray types Notes on comparison of compound data \u00b6 Compound data can contain elements of any data-type. This includes blob, clob, object type, nested table, varray or even a nested-cursor within a cursor. Attributes in nested table and array types are compared as ordered lists of elements . If order of attributes in nested table and array differ, expectation will fail. Columns in compound data are compared as ordered list of elements by default. Use unordered_columns option when order of columns in cursor is not relevant Comparison of compound data is data-type aware. So a column ID NUMBER in a cursor is not the same as ID VARCHAR2(100) , even if they both hold the same numeric values. Comparison of cursor columns containing DATE will only compare date part and ignore time by default. See Comparing cursor data containing DATE fields to check how to enable date-time comparison in cursors. Comparison of cursor returning TIMESTAMP columns against cursor returning TIMESTAMP bind variables requires variables to be cast to proper precision. This is an Oracle SQL - PLSQL compatibility issue and usage of CAST is the only known workaround for now. See Comparing cursor data containing TIMESTAMP bind variables for examples. To compare nested table/varray type you need to convert it to anydata by using anydata.convertCollection() To compare object type you need to convert it to anydata by using anydata.convertObject() It is possible to compare PL/SQL records, collections, varrays and associative arrays. To compare this types of data, use cursor comparison feature of utPLSQL and TABLE operator in SQL query On Oracle 11g Release 2 - pipelined table functions are needed (see section Implicit (Shadow) Types in this artcile ) On Oracle 12c and above - use TABLE function on nested tables/varrays/associative arrays of PL/SQL records utPLSQL is not able to distinguish between NULL and whitespace-only column/attribute value when comparing compound data. This is due to Oracle limitation on of XMLType. See issue #880 for details. Note: This behavior might be fixed in future releases, when utPLSQL is no longer depending on XMLType for compound data comparison. utPLSQL offers advanced data-comparison options, for comparing compound data-types. The options allow you to: - define columns/attributes to exclude from comparison - define columns/attributes to include in comparison - and more ... For details on available options and how to use them, read the advanced data comparison guide. Diff functionality for compound data-types \u00b6 When comparing compound data, utPLSQL will determine the difference between the expected and the actual data. The diff includes: - differences in column names, column positions and column data-type for cursor data - only data in columns/rows that differ The diff aims to make it easier to identify what is not expected in the actual data. Consider the following expected cursor data ID (NUMBER) FIRST_NAME (VARCHAR2) LAST_NAME (VARCHAR2) SALARY (NUMBER) 1 JACK SPARROW 10000 2 LUKE SKYWALKER 1000 3 TONY STARK 1000000 And the actual cursor data: ~~GENDER (VARCHAR2)~~ FIRST_NAME (VARCHAR2) LAST_NAME (VARCHAR2) SALARY (VARCHAR2) ID (NUMBER) M JACK SPARROW 25000 1 M TONY STARK 1000000 3 F JESSICA JONES 2345 4 M LUKE SKYWALKER 1000 2 The two data-sets above have the following differences: - column ID is misplaced (should be first column but is last) - column SALARY has data-type VARCHAR2 but should be NUMBER - column GENDER exists in actual but not in the expected (it is an Extra column) - data in column SALARY for row number 1 in actual is not matching expected - row number 2 in actual (ID=3) is not matching expected - row number 3 in actual (ID=4) is not matching expected - row number 4 in actual (ID=2) is not expected in results (Extra row in actual) utPLSQL will report all of the above differences in a readable format to help you identify what is not correct in the compared dataset. Below example illustrates, how utPLSQL will report such differences. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select 1 as ID , 'JACK' as FIRST_NAME , 'SPARROW' AS LAST_NAME , 10000 AS SALARY from dual union all select 2 as ID , 'LUKE' as FIRST_NAME , 'SKYWALKER' AS LAST_NAME , 1000 AS SALARY from dual union all select 3 as ID , 'TONY' as FIRST_NAME , 'STARK' AS LAST_NAME , 100000 AS SALARY from dual ; open l_actual for select 'M' AS GENDER , 'JACK' as FIRST_NAME , 'SPARROW' AS LAST_NAME , 1 as ID , '25000' AS SALARY from dual union all select 'M' AS GENDER , 'TONY' as FIRST_NAME , 'STARK' AS LAST_NAME , 3 as ID , '100000' AS SALARY from dual union all select 'F' AS GENDER , 'JESSICA' as FIRST_NAME , 'JONES' AS LAST_NAME , 4 as ID , '2345' AS SALARY from dual union all select 'M' AS GENDER , 'LUKE' as FIRST_NAME , 'SKYWALKER' AS LAST_NAME , 2 as ID , '1000' AS SALARY from dual ; ut . expect ( l_actual ). to_equal ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: refcursor [ count = 4 ] was expected to equal: refcursor [ count = 3 ] Diff: Columns: Column <ID> is misplaced. Expected position: 1, actual position: 4. Column <SALARY> data-type is invalid. Expected: NUMBER, actual: VARCHAR2. Column <GENDER> [position: 1, data-type: CHAR] is not expected in results. Rows: [ 4 differences ] Row No. 1 - Actual: <SALARY>25000</SALARY> Row No. 1 - Expected: <SALARY>10000</SALARY> Row No. 2 - Actual: <FIRST_NAME>TONY</FIRST_NAME><LAST_NAME>STARK</LAST_NAME><ID>3</ID><SALARY>100000</SALARY> Row No. 2 - Expected: <ID>2</ID><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><SALARY>1000</SALARY> Row No. 3 - Actual: <FIRST_NAME>JESSICA</FIRST_NAME><LAST_NAME>JONES</LAST_NAME><ID>4</ID><SALARY>2345</SALARY> Row No. 3 - Expected: <ID>3</ID><FIRST_NAME>TONY</FIRST_NAME><LAST_NAME>STARK</LAST_NAME><SALARY>100000</SALARY> Row No. 4 - Extra: <GENDER>M</GENDER><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><ID>2</ID><SALARY>1000</SALARY> Row No. 4 - Extra: <GENDER>M</GENDER><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><ID>2</ID><SALARY>1000</SALARY> at \"anonymous block\", line 21 utPLSQL identifies and reports on columns: - column misplacement - column data-type mismatch - extra/missing columns When comparing rows utPLSQL: - reports only mismatched columns when rows match - reports columns existing in both data-sets when whole row is not matching - reports whole extra (not expected) row from actual when actual has extra rows - reports whole missing (expected) row from expected when expected has extra rows Object and nested table data-type comparison examples \u00b6 When comparing object type / nested table / varray, utPLSQL will check: - if data-types match - if data in the compared elements is the same. The diff functionality for objects / nested tables / varrays is similar to diff on cursors. When diffing, utPLSQL will not check name and data-type of individual attribute as the type itself defines the underlying structure. Below examples demonstrate how to compare object and nested table data-types. Object type comparison. create type department as object ( name varchar2 ( 30 )) / create or replace function get_dept return department is begin return department ( 'IT' ); end ; / exec ut . expect ( anydata . convertObject ( get_dept () ) ). to_equal ( anydata . convertObject ( department ( 'HR' ) ) ); drop function get_dept ; drop type department ; Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.department was expected to equal: ut3.department Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <NAME>IT</NAME> Row No. 1 - Expected: <NAME>HR</NAME> at \"anonymous block\", line 1 Table type comparison. create type department as object ( name varchar2 ( 30 )) / create type departments as table of department / create or replace function get_depts return departments is begin return departments ( department ( 'IT' ), department ( 'HR' ) ); end ; / declare v_expected departments ; begin v_expected : = departments ( department ( 'HR' ), department ( 'IT' ) ); ut . expect ( anydata . convertCollection ( get_depts () ) ). to_equal ( anydata . convertCollection ( v_expected ) ); end ; / drop type function get_depts ; drop type departments ; drop type department ; Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.departments [ count = 2 ] was expected to equal: ut3.departments [ count = 2 ] Diff: Rows: [ 2 differences ] Row No. 1 - Actual: <NAME>IT</NAME> Row No. 1 - Expected: <NAME>HR</NAME> Row No. 2 - Actual: <NAME>HR</NAME> Row No. 2 - Expected: <NAME>IT</NAME> at \"anonymous block\", line 5 Some of the possible combinations of anydata and their results: clear screen set serverout on set feedback off create or replace type t_tab_varchar is table of varchar2 ( 1 ) / create or replace type dummy_obj as object ( id number , \"name\" varchar2 ( 30 ), \"Value\" varchar2 ( 30 ) ) / create or replace type dummy_obj_lst as table of dummy_obj / create or replace type t_varray is varray ( 1 ) of number / exec ut . expect ( anydata . convertObject ( dummy_obj ( 1 , 'A' , '0' ) ) ). to_equal ( anydata . convertObject ( dummy_obj ( 1 , 'A' , '0' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'B' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar () ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar () ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 2 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst () ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray ( 1 ) ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray ( 1 ) ) ). to_equal ( anydata . convertCollection ( t_varray ( 2 ) ) ); drop type t_varray ; drop type dummy_obj_lst ; drop type dummy_obj ; drop type t_tab_varchar ; Returns following output via DBMS_OUTPUT: SUCCESS Actual: ut3.dummy_obj was expected to equal: ut3.dummy_obj SUCCESS Actual: ut3.t_tab_varchar [ count = 1 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] FAILURE Actual: ut3.t_tab_varchar [ count = 1 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> Row No. 1 - Expected: <T_TAB_VARCHAR>B</T_TAB_VARCHAR> at \"anonymous block\", line 1 FAILURE Actual: (ut3.t_tab_varchar [ count = 0 ]) Data-types: <T_TAB_VARCHAR>VARCHAR2</T_TAB_VARCHAR> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 0 ] FAILURE Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> at \"anonymous block\", line 1 SUCCESS Actual: (ut3.t_tab_varchar [ count = 0 ]) was expected to have [ count = 0 ] SUCCESS Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 0 ] FAILURE Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 1 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] FAILURE Actual: ut3.dummy_obj_lst [ count = 1 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <ID>1</ID> Row No. 1 - Expected: <ID>2</ID> at \"anonymous block\", line 1 FAILURE Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <DUMMY_OBJ><ID>1</ID><name>A</name><Value>0</Value></DUMMY_OBJ> at \"anonymous block\", line 1 FAILURE Actual: (ut3.dummy_obj_lst [ count = 0 ]) Data-types: <DUMMY_OBJ>DUMMY_OBJ</DUMMY_OBJ> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 0 ] SUCCESS Actual: (ut3.dummy_obj_lst [ count = 0 ]) was expected to have [ count = 0 ] FAILURE Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <DUMMY_OBJ><ID>1</ID><name>A</name><Value>0</Value></DUMMY_OBJ> at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 0 ] FAILURE Actual: (ut3.t_varray [ count = 0 ]) Data-types: <T_VARRAY>NUMBER</T_VARRAY> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 0 ] FAILURE Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_VARRAY>1</T_VARRAY> at \"anonymous block\", line 1 SUCCESS Actual: (ut3.t_varray [ count = 0 ]) was expected to have [ count = 0 ] SUCCESS Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 0 ] FAILURE Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_VARRAY>1</T_VARRAY> at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_varray [ count = 1 ] was expected to equal: ut3.t_varray [ count = 1 ] FAILURE Actual: ut3.t_varray [ count = 1 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <T_VARRAY>1</T_VARRAY> Row No. 1 - Expected: <T_VARRAY>2</T_VARRAY> at \"anonymous block\", line 1 Comparing cursor data containing DATE fields \u00b6 Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far the most flexible method and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened determines the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time component. You should surround cursors and expectations with procedures ut.set_nls , ut.reset_nls . This way, the DATE data in cursors will be properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that the date in l_expected and l_actual is compared using date-time formatting. clear screen alter session set nls_date_format = 'yyyy-mm-dd' ; set serverout on set feedback off create table events ( description varchar2 ( 4000 ), event_date date ) / declare c_description constant varchar2 ( 30 ) : = 'Test event' ; c_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); c_second constant number : = 1 / 24 / 60 / 60 ; l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange insert into events ( description , event_date ) values ( c_description , c_event_date ); begin -- Change the NLS settings for date to be ISO date-time 'YYYY-MM-DD HH24:MI:SS' ut . set_nls (); --Act open l_expected for select c_description as description , c_event_date + c_second as event_date from dual ; open l_actual for select description , event_date from events ; --Assert ut . expect ( l_actual ). not_to_equal ( l_expected ); -- Reset the NLS settings to their default values after cursor data was processed ut . reset_nls (); end ; begin --Act open l_expected for select c_description as description , c_event_date + c_second as event_date from dual ; open l_actual for select description , event_date from events ; --Assert ut . expect ( l_actual ). not_to_equal ( l_expected ); end ; --Cleanup rollback ; end ; / drop table events ; In the above example: - The first expectation is successful, as the l_expected cursor contains different date-time then the cursor returned by get_events function call - The second expectation fails, as the column event_date will get compared as DATE without TIME (using default current session NLS date format) Output via DBMS_OUTPUT from the above example: SUCCESS Actual: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08T06:51:22</EVENT_DATE></ROW> was expected not to equal: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08T06:51:23</EVENT_DATE></ROW> FAILURE Actual: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08</EVENT_DATE></ROW> was expected not to equal: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08</EVENT_DATE></ROW> at \"anonymous block\", line 28 Comparing cursor data containing TIMESTAMP bind variables \u00b6 To properly compare timestamp column data returned by cursor against bind variable data from another cursor, a conversion needs to be done. This applies to timestamp , timestamp with timezone , timestamp with local timezone data types. Example below illustrates usage of cast operator to assure appropriate precision is applied on timestamp bind-variables in cursor result-set clear screen set serverout on set feedback off create table timestamps ( ts3 timestamp ( 3 ), ts6 timestamp ( 6 ), ts9 timestamp ( 9 ) ); declare l_time timestamp ( 9 ); l_expected sys_refcursor ; l_actual sys_refcursor ; begin --Arrange l_time : = systimestamp ; insert into timestamps ( ts3 , ts6 , ts9 ) values ( l_time , l_time , l_time ); begin --Act open l_expected for select cast ( l_time as timestamp ( 3 )) as ts3 , cast ( l_time as timestamp ( 6 )) as ts6 , cast ( l_time as timestamp ( 9 )) as ts9 from dual ; open l_actual for select ts3 , ts6 , ts9 from timestamps ; --Assert ut . expect ( l_actual ). to_equal ( l_expected ); end ; begin open l_expected for select l_time as ts3 , l_time as ts6 , l_time as ts9 from dual ; open l_actual for select ts3 , ts6 , ts9 from timestamps ; --Assert ut . expect ( l_actual ). to_equal ( l_expected ); end ; end ; / drop table timestamps ; Returns following output via DBMS_OUTPUT: SUCCESS Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] FAILURE Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <TS3>2019-07-08T22:08:41.899</TS3><TS6>2019-07-08T22:08:41.899319</TS6> Row No. 1 - Expected: <TS3>2019-07-08T22:08:41.899319000</TS3><TS6>2019-07-08T22:08:41.899319000</TS6> at \"anonymous block\", line 32 Comparing Json objects \u00b6 utPLSQL is capable of comparing json data-types of json_element_t on Oracle 12.2 and above , and also json on Oracle 21 and above Note: Whenever a database is upgraded to compatible version the utPLSQL needs to be reinstalled to pick up json changes. E.g. upgrade from 18c to 21c to enable json type compare. Notes on comparison of json data \u00b6 Json data can contain objects, scalar or arrays. During comparison of json objects the order doesn't matter. During comparison of json arrays the index of element is taken into account To compare json you have to make sure its type of json_element_t or its subtypes From version 21 and above a native json type is supported. Compare JSON example using json_element_t : declare l_expected json_element_t ; l_actual json_element_t ; begin l_expected : = json_element_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Birthdate\": \"July 3, 1962\", \"hasChildren\": true, \"children\": [ \"Connor\" ] }, { \"name\": \"Robert Downey Jr.\", \"age\": 53, \"Birthdate\": \"April 4, 1965\", \"hasChildren\": true, \"children\": [ \"Exton Elias\" ] } ] }' ); l_actual : = json_element_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Birthdate\": \"1962.07.03\", \"hasChildren\": true, \"children\": [ \"Suri\", \"Isabella Jane\", \"Connor\" ] }, { \"name\": \"Jr., Robert Downey\", \"age\": 53, \"Birthdate\": \"April 4, 1965\", \"hasChildren\": true, \"children\": [ \"Indio Falconer\", \"Avri Roel\", \"Exton Elias\" ] } ] }' ); ut . expect ( l_actual ). to_equal ( l_expected ); end ; Returns following output via DBMS_OUTPUT: FAILURE Actual: json was expected to equal: json Diff: 8 differences found 4 unequal values, 4 missing properties Extra property: \"Avri Roel\" on path: $.\"Actors\"[1].\"children\"[1] Extra property: \"Isabella Jane\" on path: $.\"Actors\"[0].\"children\"[1] Extra property: \"Connor\" on path: $.\"Actors\"[0].\"children\"[2] Extra property: \"Exton Elias\" on path: $.\"Actors\"[1].\"children\"[2] Actual value: \"Robert Downey Jr.\" was expected to be: \"Jr., Robert Downey\" on path: $.\"Actors\"[1].\"name\" Actual value: \"July 3, 1962\" was expected to be: \"1962.07.03\" on path: $.\"Actors\"[0].\"Birthdate\" Actual value: \"Connor\" was expected to be: \"Suri\" on path: $.\"Actors\"[0].\"children\"[0] Actual value: \"Exton Elias\" was expected to be: \"Indio Falconer\" on path: $.\"Actors\"[1].\"children\"[0] at \"anonymous block\", line 59 Comparing parts of JSON example using json_element_t subtypes: declare l_actual json_object_t ; l_actual_extract json_array_t ; l_expected json_array_t ; begin -- Arrange l_expected : = json_array_t . parse ( ' [ \"Indio Falconer\", \"Avri Roel\", \"Exton Elias\" ]' ); l_actual : = json_object_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Born At\": \"Syracuse, NY\", \"Birthdate\": \"July 3, 1962\", \"photo\": \"https://jsonformatter.org/img/tom-cruise.jpg\", \"wife\": null, \"weight\": 67.5, \"hasChildren\": true, \"hasGreyHair\": false, \"children\": [ \"Suri\", \"Isabella Jane\", \"Connor\" ] }, { \"name\": \"Robert Downey Jr.\", \"age\": 53, \"Born At\": \"New York City, NY\", \"Birthdate\": \"April 4, 1965\", \"photo\": \"https://jsonformatter.org/img/Robert-Downey-Jr.jpg\", \"wife\": \"Susan Downey\", \"weight\": 77.1, \"hasChildren\": true, \"hasGreyHair\": false, \"children\": [ \"Indio Falconer\", \"Exton Elias\" ] } ] }' ); l_actual_extract : = json_array_t ( json_query ( l_actual . stringify , '$.Actors[1].children' )); --Act ut . expect ( l_actual_extract ). to_equal ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: json was expected to equal: json Diff: 2 differences found 1 unequal values, 1 missing properties Missing property: \"Exton Elias\" on path: $[2] Actual value: \"Avri Roel\" was expected to be: \"Exton Elias\" on path: $[1] at \"anonymous block\", line 55","title":"Expectations"},{"location":"userguide/expectations.html#expectation-concepts","text":"Validation of the code under test (the tested logic of procedure/function etc.) is performed by comparing the actual data against the expected data. utPLSQL uses expectations and matchers to perform the check on the data. Example of an expectation begin ut . expect ( 'the tested value' ). to_equal ( 'the expected value' ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'the tested value' (varchar2) was expected to equal: 'the expected value' (varchar2) at \"anonymous block\", line 2 Expectation is a combination of: - the expected value - optional custom message for the expectation - the matcher used to perform comparison - the matcher parameters (actual value), depending on the matcher type Matcher defines the comparison operation to be performed on expected (and actual) value. Pseudo-code: ut . expect ( a_actual { data - type } [, a_message { varchar2 } ] ). to_ ( { matcher } ); ut . expect ( a_actual { data - type } [, a_message { varchar2 } ] ). not_to ( { matcher } ); Expectations provide two variants of syntax that you can use. Both variants are functionally-equal but give different usage flexibility. Syntax where matcher is passed as parameter to the expectation: ut . expect ( a_actual ). to_ ( { matcher } ); ut . expect ( a_actual ). not_to ( { matcher } ); -- example ut . expect ( 1 ). to_ ( be_null () ); Shortcut syntax, where matcher is directly part of expectation: ut . expect ( a_actual ). to_ { matcher } ; ut . expect ( a_actual ). not_to_ { matcher } ; --example ut . expect ( 1 ). to_ ( be_null () ); When using shortcut syntax you don't need to surround matcher with brackets. Shortcut syntax is provided for convenience. If you would like to perform more dynamic checks in your code, you could pass the matcher into a procedure like in the below example: declare procedure do_check ( p_actual varchar2 , p_matcher ut_matcher ) is begin ut . expect ( p_actual ). to_ ( p_matcher ); end ; begin do_check ( 'a' , equal ( 'b' ) ); do_check ( 'Alibaba' , match ( 'ali' , 'i' ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'a' (varchar2) was expected to equal: 'b' (varchar2) at \"anonymous block\", line 4 at \"anonymous block\", line 7 SUCCESS Actual: 'Alibaba' (varchar2) was expected to match: 'ali' , modifiers 'i' Note: The examples in the document will be only using shortcut syntax, to keep the document brief.","title":"Expectation concepts"},{"location":"userguide/expectations.html#using-expectations","text":"There are two ways to use expectations: - by invoking utPLSQL framework to execute suite(s) of utPLSQL tests - without invoking the utPLSQL framework - running expectations standalone","title":"Using expectations"},{"location":"userguide/expectations.html#running-expectations-within-utplsql-framework","text":"When expectations are ran as a part of a test suite, the framework tracks: - status of each expectation - outcomes (messages) produced by each expectation - call stack to each expectation In this case: - expectation results of are not sent directly to dbms_output - utPLSQL Reporters used when running suite decide on how the expectation results are formatted and displayed Example of test suite with an expectation: create or replace package test_divide as --%suite(Divide two numbers) --%test(Returns result when divisor is not zero) procedure divide_6_by_2 ; --%test(Throws exception when divisor is zero) --%throws(zero_divide) procedure divide_by_0_throws ; end ; / create or replace package body test_divide as procedure divide_6_by_2 is begin ut . expect ( 6 / 2 ). to_equal ( 3 ); end ; procedure divide_by_0_throws is begin ut . expect ( 6 / 0 ). to_be_not_null (); end ; end ; / exec ut . run ( 'test_divide' ); drop package test_divide ; Produces following outputs: Package TEST_DIVIDE compiled Package Body TEST_DIVIDE compiled Divide two numbers Returns result when divisor is not zero [.003 sec] Throws exception when divisor is zero [.003 sec] Finished in .009774 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) PL/SQL procedure successfully completed. Package TEST_DIVIDE dropped. Please read about different options for running test suites .","title":"Running expectations within utPLSQL framework"},{"location":"userguide/expectations.html#running-expectations-outside-utplsql-framework","text":"When expectations are invoked outside of utPLSQL framework the outputs from expectations are redirected straight to dbms_output . Note: The output from expectation contains call stack trace only when expectation fails. Source code of the line which called the expectation is only reported when the line is part of in-database code (package) and the user calling expectation has privileges to see that source code. Important Please do not use expectations as part of your production code. They are not designed to be used as part of your code. Expectations are meant to be used only as part of your day-to-day testing activities. Note: The examples in the document will be only using standalone expectations, to keep the document brief.","title":"Running expectations outside utPLSQL framework"},{"location":"userguide/expectations.html#matchers","text":"utPLSQL provides the following matchers to perform checks on the expected and actual values. be_between( a_upper_bound {data-type}, a_lower_bound {data-type} ) be_empty() be_false() be_greater_than( a_expected {data-type} ) be_greater_or_equal( a_expected {data-type} ) be_less_or_equal( a_expected {data-type} ) be_less_than( a_expected {data-type} ) be_like( a_mask {varchar2} [, a_escape_char {varchar2}] ) be_not_null() be_null() be_true() equal( a_expected {data-type} [, a_nulls_are_equal {boolean}] ) contain( a_expected {data-type}) have_count( a_expected {integer} ) match( a_patter {varchar2} [, a_modifiers {varchar2}] )","title":"Matchers"},{"location":"userguide/expectations.html#providing-a-custom-message","text":"You can provide a custom failure message by passing it as the second parameter to the expectation. ut.expect( a_actual {data-type}, a_message {varchar2} ).to_{matcher} Example: exec ut . expect ( 'supercat' , 'checked superhero-animal was not a dog' ). to_equal ( 'superdog' ); Returns following output via DBMS_OUTPUT: FAILURE \"checked superhero-animal was not a dog\" Actual: 'supercat' (varchar2) was expected to equal: 'superdog' (varchar2) at \"anonymous block\", line 1 If the message is provided, it is being added to the normal failure message returned by the matcher. This is mostly useful when your expectations accept dynamic content, as you can provide additional context to make failing test results more readable. In most cases, there is no need to provide custom message to expectation. This is because utPLSQL identifies: - The test used to execute the expectation - The line number where the expectation is placed in your test code - The line text of the expectation Custom message is useful, if your expectation is placed in a shared procedure to perform a check and your test is using the procedure multiple times. Example: create or replace package shared_expectation_test is --%suite --%test procedure the_test ; end ; / create or replace package body shared_expectation_test is procedure table_is_empty ( p_table_name varchar2 ) is l_count integer ; begin execute immediate 'select count(*) from ' || p_table_name into l_count ; ut . expect ( l_count , 'Checking table ' || p_table_name ). to_equal ( 0 ); end ; procedure the_test is begin table_is_empty ( 'ALL_USERS' ); table_is_empty ( 'ALL_TABLES' ); end ; end ; / exec ut . run ( 'shared_expectation_test' ); Returns following output via DBMS_OUTPUT: shared_expectation_test the_test [.064 sec] (FAILED - 1) Failures: 1) the_test \"Checking table ALL_USERS\" Actual: 28 (number) was expected to equal: 0 (number) at \"UT3_USER.SHARED_EXPECTATION_TEST.TABLE_IS_EMPTY\", line 6 ut.expect( l_count, 'Checking table '||p_table_name ).to_equal(0); at \"UT3_USER.SHARED_EXPECTATION_TEST.THE_TEST\", line 11 \"Checking table ALL_TABLES\" Actual: 55 (number) was expected to equal: 0 (number) at \"UT3_USER.SHARED_EXPECTATION_TEST.TABLE_IS_EMPTY\", line 6 ut.expect( l_count, 'Checking table '||p_table_name ).to_equal(0); at \"UT3_USER.SHARED_EXPECTATION_TEST.THE_TEST\", line 12 Finished in .066344 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) In the tests results window you can see the list of failed expectations for a test as well as: - the additional message for expectation - the reason why the expectation failed - the line number of the expectation - the line text of the expectations - the call stack for the expectation (in the example it's the lines that called the procedure table_is_empty )","title":"Providing a custom message"},{"location":"userguide/expectations.html#negating-a-matcher","text":"Expectations provide a very convenient way to perform a check on a negated matcher. Syntax to check for matcher evaluating to true: begin ut . expect ( a_actual { data - type } ). to_ { matcher } ; ut . expect ( a_actual { data - type } ). to_ ( { matcher } ); end ; Syntax to check for matcher evaluating to false: begin ut . expect ( a_actual { data - type } ). not_to_ { matcher } ; ut . expect ( a_actual { data - type } ). not_to ( { matcher } ); end ; If a matcher evaluated to NULL, then both to_ and not_to will cause the expectation to report failure. Example: declare l_actual boolean ; begin ut . expect ( l_actual ). to_be_true (); ut . expect ( l_actual ). not_to_be_true (); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: NULL (boolean) was expected to be true at \"anonymous block\", line 4 FAILURE Actual: NULL (boolean) was expected not to be true at \"anonymous block\", line 5 Since NULL is neither true nor false , both expectations will report failure.","title":"Negating a matcher"},{"location":"userguide/expectations.html#supported-data-types","text":"The matrix below illustrates the data types supported by different matchers. Matcher blob boolean clob date number timestamp timestamp with timezone timestamp with local timezone varchar2 interval year to month interval day to second cursor nested table / varray object json be_not_null X X X X X X X X X X X X X X X be_null X X X X X X X X X X X X X X X be_false X be_true X be_greater_than X X X X X X X be_greater_or_equal X X X X X X X be_less_or_equal X X X X X X X be_less_than X X X X X X X be_between X X X X X X X X equal X X X X X X X X X X X X X X X contain X X X match X X be_like X X be_empty X X X X X have_count X X X be_within().of_() X X X X X be_within_pct().of_() X","title":"Supported data types"},{"location":"userguide/expectations.html#expecting-exceptions","text":"Testing is not limited to checking for happy-path scenarios. When writing tests, you often want to validate that in specific scenarios, an exception is thrown. Use the --%throws annotation, to test for expected exceptions. Example: create or replace function divide ( x varchar2 , y varchar2 ) return number is begin return x / y ; end ; / create or replace package test_divide as --%suite(Divide function) --%test(Throws divisor equal) --%throws(-01476) procedure raises_divisor_exception ; end ; / create or replace package body test_divide is procedure raises_divisor_exception is x integer ; begin x : = divide ( 6 , 0 ); end ; end ; / exec ut . run ( 'test_divide' ); Returns following output via DBMS_OUTPUT: Divide function Throws divisor equal [.007 sec] Finished in .009229 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) For more details see documentation of the --%throws annotation.","title":"Expecting exceptions"},{"location":"userguide/expectations.html#matchers_1","text":"You can choose different matchers to validate that your PL/SQL code is working as expected.","title":"Matchers"},{"location":"userguide/expectations.html#be_between","text":"Validates that the actual value is between the lower and upper bound. Example: declare l_timestamp timestamp : = current_timestamp ; l_timestamp_tz timestamp with time zone : = systimestamp ; l_timestamp_ltz timestamp with local time zone : = systimestamp ; l_interval_ds interval day to second : = interval '1' second ; l_interval_ym interval year to month : = interval '1' year ; begin ut . expect ( 3 ). to_be_between ( 1 , 3 ); ut . expect ( 5 ). to_ ( be_between ( 1 , 3 ) ); ut . expect ( 3 ). not_to_be_between ( 1 , 3 ); ut . expect ( 5 ). not_to ( be_between ( 1 , 3 ) ); ut . expect ( sysdate ). to_be_between ( sysdate , sysdate + 1 ); ut . expect ( l_timestamp ). to_be_between ( l_timestamp , l_timestamp ); ut . expect ( systimestamp ). to_be_between ( l_timestamp_tz , systimestamp ); ut . expect ( systimestamp ). to_be_between ( l_timestamp_ltz , l_timestamp_ltz ); ut . expect ( l_interval_ds ). to_be_between ( interval '0.1' second , interval '1' day ); ut . expect ( l_interval_ym ). to_be_between ( interval '12' month , interval '12' year ); ut . expect ( 'Abb' ). to_be_between ( 'Aba' , 'Abc' ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 3 (number) was expected to be between: 1 and 3 FAILURE Actual: 5 (number) was expected to be between: 1 and 3 at \"anonymous block\", line 9 FAILURE Actual: 3 (number) was expected not to be between: 1 and 3 at \"anonymous block\", line 10 SUCCESS Actual: 5 (number) was expected not to be between: 1 and 3 SUCCESS Actual: 2019-07-07T21:25:27 (date) was expected to be between: 2019-07-07T21:25:27 and 2019-07-08T21:25:27 SUCCESS Actual: 2019-07-07T22:25:27.701546000 (timestamp) was expected to be between: 2019-07-07T22:25:27.701546000 and 2019-07-07T22:25:27.701546000 SUCCESS Actual: 2019-07-07T21:25:27.705768000 +00:00 (timestamp with time zone) was expected to be between: 2019-07-07T21:25:27.701596000 +00:00 and 2019-07-07T21:25:27.705808000 +00:00 FAILURE The matcher 'be between' cannot be used with data type (timestamp with time zone). at \"anonymous block\", line 15 SUCCESS Actual: +000000000 00:00:01.000000000 (interval day to second) was expected to be between: +000000000 00:00:00.100000000 and +000000001 00:00:00.000000000 SUCCESS Actual: +000000001-00 (interval year to month) was expected to be between: +000000001-00 and +000000012-00 SUCCESS Actual: 'Abb' (varchar2) was expected to be between: 'Aba' and 'Abc'","title":"be_between"},{"location":"userguide/expectations.html#be_empty","text":"Unary matcher that validates if the provided dataset is empty. Can be used with BLOB , CLOB , refcursor or nested table / varray passed as ANYDATA Note: BLOB/CLOB that is initialized is not NULL but it is actually equal to empty_blob() / empty_clob() . Example: declare l_cursor sys_refcursor ; begin open l_cursor for select * from dual where 0 = 1 ; ut . expect ( l_cursor ). to_be_empty (); ut . expect ( anydata . convertCollection ( ut_varchar2_list ()) ). to_ ( be_empty () ); ut . expect ( empty_clob () ). not_to_be_empty (); ut . expect ( empty_blob () ). not_to ( be_empty () ); ut . expect ( 1 ). not_to ( be_empty () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: (refcursor [ count = 0 ]) Data-types: <DUMMY>VARCHAR2</DUMMY> Data: was expected to be empty SUCCESS Actual: (ut3.ut_varchar2_list [ count = 0 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: was expected to be empty FAILURE Actual: EMPTY (clob) was expected not to be empty at \"anonymous block\", line 7 FAILURE Actual: EMPTY (blob) was expected not to be empty at \"anonymous block\", line 8 FAILURE The matcher 'be empty' cannot be used with data type (number). at \"anonymous block\", line 9","title":"be_empty"},{"location":"userguide/expectations.html#be_false","text":"Unary matcher that validates if the provided value is false. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_false (); ut . expect ( ( 1 = 1 ) ). to_ ( be_false () ); ut . expect ( ( 1 = 0 ) ). not_to_be_false (); ut . expect ( ( 1 = 1 ) ). not_to ( be_false () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: FALSE (boolean) was expected to be false FAILURE Actual: TRUE (boolean) was expected to be false at \"anonymous block\", line 3 FAILURE Actual: FALSE (boolean) was expected not to be false at \"anonymous block\", line 4 SUCCESS Actual: TRUE (boolean) was expected not to be false","title":"be_false"},{"location":"userguide/expectations.html#be_greater_or_equal","text":"Checks if the actual value is greater or equal than the expected. Usage: begin ut . expect ( sysdate ). to_be_greater_or_equal ( sysdate - 1 ); ut . expect ( sysdate ). to_ ( be_greater_or_equal ( sysdate + 1 ) ); ut . expect ( sysdate ). not_to_be_greater_or_equal ( sysdate - 1 ); ut . expect ( sysdate ). not_to ( be_greater_or_equal ( sysdate + 1 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 2019-07-07T22:43:29 (date) was expected to be greater or equal: 2019-07-06T22:43:29 (date) FAILURE Actual: 2019-07-07T22:43:29 (date) was expected to be greater or equal: 2019-07-08T22:43:29 (date) at \"anonymous block\", line 3 FAILURE Actual: 2019-07-07T22:43:29 (date) was expected not to be greater or equal: 2019-07-06T22:43:29 (date) at \"anonymous block\", line 4 SUCCESS Actual: 2019-07-07T22:43:29 (date) was expected not to be greater or equal: 2019-07-08T22:43:29 (date)","title":"be_greater_or_equal"},{"location":"userguide/expectations.html#be_greater_than","text":"Checks if the actual value is greater than the expected. Usage: begin ut . expect ( 2 ). to_be_greater_than ( 1 ); ut . expect ( 0 ). to_ ( be_greater_than ( 1 ) ); ut . expect ( 2 ). not_to_be_greater_than ( 1 ); ut . expect ( 0 ). not_to ( be_greater_than ( 1 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 2 (number) was expected to be greater than: 1 (number) FAILURE Actual: 0 (number) was expected to be greater than: 1 (number) at \"anonymous block\", line 3 FAILURE Actual: 2 (number) was expected not to be greater than: 1 (number) at \"anonymous block\", line 4 SUCCESS Actual: 0 (number) was expected not to be greater than: 1 (number)","title":"be_greater_than"},{"location":"userguide/expectations.html#be_less_or_equal","text":"Checks if the actual value is less or equal than the expected. Usage: begin ut . expect ( 3 ). to_be_less_or_equal ( 3 ); ut . expect ( 4 ). to_ ( be_less_or_equal ( 3 ) ); ut . expect ( 3 ). not_to_be_less_or_equal ( 3 ); ut . expect ( 4 ). not_to ( be_less_or_equal ( 3 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 3 (number) was expected to be less or equal: 3 (number) FAILURE Actual: 4 (number) was expected to be less or equal: 3 (number) at \"anonymous block\", line 3 FAILURE Actual: 3 (number) was expected not to be less or equal: 3 (number) at \"anonymous block\", line 4 SUCCESS Actual: 4 (number) was expected not to be less or equal: 3 (number)","title":"be_less_or_equal"},{"location":"userguide/expectations.html#be_less_than","text":"Checks if the actual value is less than the expected. Usage: begin ut . expect ( 3 ). to_be_less_than ( 2 ); ut . expect ( 0 ). to_ ( be_less_than ( 2 ) ); ut . expect ( 3 ). not_to_be_less_than ( 2 ); ut . expect ( 0 ). not_to ( be_less_than ( 2 ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 3 (number) was expected to be less than: 2 (number) at \"anonymous block\", line 2 SUCCESS Actual: 0 (number) was expected to be less than: 2 (number) SUCCESS Actual: 3 (number) was expected not to be less than: 2 (number) FAILURE Actual: 0 (number) was expected not to be less than: 2 (number) at \"anonymous block\", line 5","title":"be_less_than"},{"location":"userguide/expectations.html#be_like","text":"Validates that the actual value is like the expected expression. Syntax: ut.expect( a_actual ).to_be_like( a_mask [, a_escape_char] ) Parameters a_mask and a_escape_char represent valid parameters of the Oracle LIKE condition . If you use Oracle Database version 11.2.0.4, you may run into Oracle Bug 14402514: WRONG RESULTS WITH LIKE ON CLOB USING ESCAPE CHARACTER. In this case we recommend to use match instead of be_like . Usage: begin ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem%' ); ut . expect ( 'Lorem_impsum' ). to_be_like ( '%rem\\_i%' , '\\' ); ut . expect ( 'Lorem_impsum' ). to_ ( be_like ( 'Lor_m%' ) ); ut . expect ( 'Lorem_impsum' ). not_to_be_like ( '%rem%' ); ut . expect ( 'Lorem_impsum' ). not_to ( be_like ( '%reM%' ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: '%rem%' SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: '%rem\\_i%' , escape '\\' SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected to be like: 'Lor_m%' FAILURE Actual: 'Lorem_impsum' (varchar2) was expected not to be like: '%rem%' at \"anonymous block\", line 5 SUCCESS Actual: 'Lorem_impsum' (varchar2) was expected not to be like: '%reM%'","title":"be_like"},{"location":"userguide/expectations.html#be_not_null","text":"Unary matcher that validates if the actual value is not null. Usage: begin ut . expect ( to_clob ( 'ABC' ) ). to_be_not_null (); ut . expect ( to_clob ( '' ) ). to_ ( be_not_null () ); ut . expect ( to_clob ( 'ABC' ) ). not_to_be_not_null (); ut . expect ( '' ). not_to ( be_not_null () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: 'ABC' (clob) was expected to be not null FAILURE Actual: NULL (clob) was expected to be not null at \"anonymous block\", line 3 FAILURE Actual: 'ABC' (clob) was expected not to be not null at \"anonymous block\", line 4 SUCCESS Actual: NULL (varchar2) was expected not to be not null","title":"be_not_null"},{"location":"userguide/expectations.html#be_null","text":"Unary matcher that validates if the actual value is null. Usage: begin ut . expect ( '' ). to_be_null (); ut . expect ( 0 ). to_ ( be_null () ); ut . expect ( '' ). not_to_be_null (); ut . expect ( 0 ). not_to ( be_null () ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: NULL (varchar2) was expected to be null FAILURE Actual: 0 (number) was expected to be null at \"anonymous block\", line 3 FAILURE Actual: NULL (varchar2) was expected not to be null at \"anonymous block\", line 4 SUCCESS Actual: 0 (number) was expected not to be null","title":"be_null"},{"location":"userguide/expectations.html#be_true","text":"Unary matcher that validates if the provided value is true. Usage: begin ut . expect ( ( 1 = 0 ) ). to_be_true (); ut . expect ( ( 1 = 1 ) ). to_ ( be_true () ); ut . expect ( ( 1 = 0 ) ). not_to_be_true (); ut . expect ( ( 1 = 1 ) ). not_to ( be_true () ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: FALSE (boolean) was expected to be true at \"anonymous block\", line 2 SUCCESS Actual: TRUE (boolean) was expected to be true SUCCESS Actual: FALSE (boolean) was expected not to be true FAILURE Actual: TRUE (boolean) was expected not to be true at \"anonymous block\", line 5","title":"be_true"},{"location":"userguide/expectations.html#have_count","text":"Unary matcher that validates if the provided dataset count is equal to expected value. Can be used with refcursor , json or table type Usage: declare l_cursor sys_refcursor ; l_collection ut_varchar2_list ; begin open l_cursor for select * from dual connect by level <= 10 ; ut . expect ( l_cursor ). to_have_count ( 10 ); open l_cursor for select rownum from xmltable ( '1 to 5' ); ut . expect ( l_cursor ). to_ ( have_count ( 10 ) ); l_collection : = ut_varchar2_list ( 'a' , 'a' , 'b' ); ut . expect ( anydata . convertCollection ( l_collection ) ). not_to_have_count ( 10 ); ut . expect ( anydata . convertCollection ( l_collection ) ). not_to ( have_count ( 3 ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: (refcursor [ count = 10 ]) was expected to have [ count = 10 ] FAILURE Actual: (refcursor [ count = 5 ]) was expected to have [ count = 10 ] at \"anonymous block\", line 8 SUCCESS Actual: ut3.ut_varchar2_list [ count = 3 ] was expected not to have [ count = 10 ] FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected not to have [ count = 3 ] at \"anonymous block\", line 11","title":"have_count"},{"location":"userguide/expectations.html#match","text":"Validates that the actual value is matching the expected regular expression. Syntax: ut.expect( a_actual ).to_match( a_pattern [, a_modifiers] ); Parameters a_pattern and a_modifiers represent a valid regexp pattern accepted by Oracle REGEXP_LIKE condition Usage: begin ut . expect ( '123-456-ABcd' ). to_match ( '\\d{3}-\\d{3}-[a-z]{4}' , 'i' ); ut . expect ( 'some value' ). to_ ( match ( '^some.*' ) ) ; ut . expect ( '123-456-ABcd' ). not_to_match ( '\\d{3}-\\d{3}-[a-z]{4}' , 'i' ); ut . expect ( 'some value' ). not_to ( match ( '^some.*' ) ) ; end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: '123-456-ABcd' (varchar2) was expected to match: '\\d{3}-\\d{3}-[a-z]{4}' , modifiers 'i' SUCCESS Actual: 'some value' (varchar2) was expected to match: '^some.*' FAILURE Actual: '123-456-ABcd' (varchar2) was expected not to match: '\\d{3}-\\d{3}-[a-z]{4}' , modifiers 'i' at \"anonymous block\", line 4 FAILURE Actual: 'some value' (varchar2) was expected not to match: '^some.*' at \"anonymous block\", line 5","title":"match"},{"location":"userguide/expectations.html#equal","text":"The equal matcher is very restrictive. Test using this matcher succeeds only when the compared data-types are exactly the same. If you are comparing a varchar2 to a number , it will fail even if the text contains the same numeric value as the number. The matcher will also fail when comparing a timestamp to a timestamp with timezone data-type etc. The matcher enables detection of data-type changes. If you expect your variable to be a number and it is now some other type, the test will fail and give you early indication of a potential problem. To keep it simple, the equal matcher will only succeed if you compare apples to apples. Syntax: ut.expect( a_actual ).to_equal( a_expected [, a_nulls_are_equal])[.advanced_options] Example usage declare l_actual varchar2 ( 20 ); l_expected varchar2 ( 20 ); begin --Arrange l_actual : = 'a dog' ; --Assert ut . expect ( l_actual ). to_equal ( 'other_dog' ); ut . expect ( l_actual ). to_equal ( '' ); ut . expect ( l_actual ). to_equal ( 1 ); l_actual : = null ; ut . expect ( l_actual ). to_equal ( '' ); ut . expect ( l_actual ). to_equal ( '' , a_nulls_are_equal => false ); ut . expect ( l_actual ). not_to_equal ( '' ); ut . expect ( sysdate ). to_equal ( sysdate ); ut . expect ( sysdate ). to_equal ( current_timestamp ); ut . expect ( current_timestamp ). to_equal ( systimestamp ); ut . expect ( to_clob ( 'varchar' ) ). to_equal ( 'varchar' ); ut . expect ( to_blob ( 'aa' ) ). to_equal ( to_blob ( 'aa' ) ); ut . expect ( to_clob ( 'aa' ) ). to_equal ( to_clob ( 'aa' ) ); ut . expect ( to_blob ( 'aa' ) ). to_equal ( to_clob ( 'aa' ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: 'a dog' (varchar2) was expected to equal: 'other_dog' (varchar2) at \"anonymous block\", line 8 FAILURE Actual: 'a dog' (varchar2) was expected to equal: NULL (varchar2) at \"anonymous block\", line 9 FAILURE Actual (varchar2) cannot be compared to Expected (number) using matcher 'equal'. at \"anonymous block\", line 10 SUCCESS Actual: NULL (varchar2) was expected to equal: NULL (varchar2) FAILURE Actual: NULL (varchar2) was expected to equal: NULL (varchar2) at \"anonymous block\", line 14 FAILURE Actual: NULL (varchar2) was expected not to equal: NULL (varchar2) at \"anonymous block\", line 15 SUCCESS Actual: 2019-07-07T22:50:21 (date) was expected to equal: 2019-07-07T22:50:21 (date) FAILURE Actual (date) cannot be compared to Expected (timestamp with time zone) using matcher 'equal'. at \"anonymous block\", line 17 FAILURE Actual: 2019-07-07T23:50:21.159268000 +01:00 (timestamp with time zone) was expected to equal: 2019-07-07T22:50:21.159296000 +00:00 (timestamp with time zone) at \"anonymous block\", line 18 FAILURE Actual (clob) cannot be compared to Expected (varchar2) using matcher 'equal'. at \"anonymous block\", line 19 SUCCESS Actual: 'AA' (blob) was expected to equal: 'AA' (blob) SUCCESS Actual: 'aa' (clob) was expected to equal: 'aa' (clob) FAILURE Actual (blob) cannot be compared to Expected (clob) using matcher 'equal'. at \"anonymous block\", line 22 Note: Comparing NULLs gives success by default The a_nulls_are_equal parameter controls the behavior of a null = null comparison. To change the behavior of NULL = NULL comparison pass the a_nulls_are_equal => false to the equal matcher.","title":"equal"},{"location":"userguide/expectations.html#contain","text":"This matcher supports only compound data-types comparison. It check if the actual set contains all values of expected subset. When comparing data using the contain matcher, the data-types of columns for compared compound types must be exactly the same. The matcher supports all advanced comparison options as equal like: include , exclude , join_by etc.. The matcher is successful when actual data set contains all of the values from expected results. The matcher will cause a test to fail if actual data set does not contain some of expected values. Example 1. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange open l_actual for select rownum as rn from dual a connect by level < 10 ; open l_expected for select rownum as rn from dual a connect by level < 4 union all select rownum as rn from dual a connect by level < 4 ; --Act ut . expect ( l_actual ). to_contain ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: refcursor [ count = 9 ] was expected to contain: refcursor [ count = 6 ] Diff: Rows: [ 3 differences ] Missing: <RN>1</RN> Missing: <RN>2</RN> Missing: <RN>3</RN> at \"anonymous block\", line 11 When duplicate rows are present in expected data set, actual data set must also include the same amount of duplicates. Example 2. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 1 ); l_expected : = ut_varchar2_list ( 1 , 2 , 1 , 2 ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 9 ] was expected to contain: ut3.ut_varchar2_list [ count = 4 ] Diff: Rows: [ 1 differences ] Missing: <UT_VARCHAR2_LIST>2</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 The negated version of contain ( not_to_contain ) is successful only when all values from expected set are not part of actual (they are disjoint and there is no overlap). Example 3. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' ); l_expected : = ut_varchar2_list ( 'A' , 'B' , 'E' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] Diff: Rows: [ 1 differences ] Missing: <UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 FAILURE Actual: (ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST></ROW> at \"anonymous block\", line 8 Example 4. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' , 'D' ); l_expected : = ut_varchar2_list ( 'A' , 'B' , 'D' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: SUCCESS Actual: ut3.ut_varchar2_list [ count = 4 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] FAILURE Actual: (ut3.ut_varchar2_list [ count = 4 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW> at \"anonymous block\", line 8 Example 5. declare l_actual ut_varchar2_list ; l_expected ut_varchar2_list ; begin l_actual : = ut_varchar2_list ( 'A' , 'B' , 'C' ); l_expected : = ut_varchar2_list ( 'D' , 'E' , 'F' ); ut . expect ( anydata . convertCollection ( l_actual ) ). to_contain ( anydata . convertCollection ( l_expected ) ); ut . expect ( anydata . convertCollection ( l_actual ) ). not_to_contain ( anydata . convertCollection ( l_expected ) ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.ut_varchar2_list [ count = 3 ] was expected to contain: ut3.ut_varchar2_list [ count = 3 ] Diff: Rows: [ 3 differences ] Missing: <UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST> Missing: <UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST> Missing: <UT_VARCHAR2_LIST>F</UT_VARCHAR2_LIST> at \"anonymous block\", line 7 SUCCESS Actual: (ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>A</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>B</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>C</UT_VARCHAR2_LIST></ROW> was expected not to contain:(ut3.ut_varchar2_list [ count = 3 ]) Data-types: <UT_VARCHAR2_LIST>VARCHAR2</UT_VARCHAR2_LIST> Data: <ROW><UT_VARCHAR2_LIST>D</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>E</UT_VARCHAR2_LIST></ROW><ROW><UT_VARCHAR2_LIST>F</UT_VARCHAR2_LIST></ROW>","title":"contain"},{"location":"userguide/expectations.html#to_be_within-of","text":"Determines whether expected value is within range (tolerance) from another value. The logical formual used for calcuating the matcher is: result := ( abs( expected - actual ) <= distance ) The actual formula used for calculation is more complex to handle different data-types of expected/actual values as well as differnet types of distance value. The matcher will fail if the expected and actual are more than distance apart from each other. The matcher will fail if the dataypes of expected and actual are not the same. The matcher works with data-types: number , date , timestamp , timestamp with time zone , timestamp with local time zone The data-types of compared values must match exactly and if type does not match, the expectation will fail. expected/actual data-type distance data-type number number date interval day to second date interval year to month timestamp interval day to second timestamp interval year to month timestamp with time zone interval day to second timestamp with time zone interval year to month timestamp with local time zone interval day to second timestamp with local time zone interval year to month The distance must be expressed as a non-negative number or non-negative interval. Note: Interval year-to-moth as a distance is giving sucess if the distance between the given dates/timestamps evaluates to value less or equal of the specified interval Keep in mind that a checking for distance of interval '0-1' year to month will actuall be successful if the distance is less than a month and 15 days. This is due to how oracle evaluates conversion between timestamp difference converted to year to month interval . The behavior is similar to a call to months_between() function with results rounded to full monts ie. round(months_between(date, date)) Example 1. begin ut . expect ( 3 ). to_be_within ( 1 ). of_ ( 4 ); end ; / Example 2. begin ut . expect ( 3 ). to_be_within ( 1 ). of_ ( 5 ); end ; / Returns following output via DBMS_OUTPUT: Failures: 1) wihtin_test Actual: 3 (number) was expected to be within 1 of 5 (number) at \"UT3_DEVELOP.UT_BE_WITHIN.OF_\", line 48 l_result.expectation.to_(l_result ); at \"UT3_DEVELOP.TEST_BETWNSTR.WIHTIN_TEST\", line 5 Example 3. begin ut . expect ( sysdate ). to_be_within ( interval '1' day ). of_ ( sysdate + 2 ); end ; / Returns following output via DBMS_OUTPUT: Failures: 1) wihtin_test Actual: 2020-06-07T13:32:58 (date) was expected to be within 1 day of 2020-06-09T13:32:58 (date) at \"UT3_DEVELOP.UT_BE_WITHIN.OF_\", line 55 l_result.expectation.to_(l_result ); at \"UT3_DEVELOP.TEST_BETWNSTR.WIHTIN_TEST\", line 5","title":"to_be_within of"},{"location":"userguide/expectations.html#to_be_within_pct-of","text":"Determines whether actual value is within percentage range of expected value. The matcher only works with number data-type. The percentage deviation (distance) must be expressed as a non-negative number. The formula used for calcuation of expectation is: result := ( ( distance ) * expected >= abs( expected - actual ) * 100 ) Example 1. begin ut . expect ( 9 ). to_be_within_pct ( 10 ). of_ ( 10 ); end ; / SUCCESS Actual: 9 (number) was expected to be within 10 % of 10 (number)","title":"to_be_within_pct of"},{"location":"userguide/expectations.html#comparing-cursors-object-types-nested-tables-and-varrays","text":"utPLSQL is capable of comparing compound data-types including: - ref cursors - object types - nested table/varray types","title":"Comparing cursors, object types, nested tables and varrays"},{"location":"userguide/expectations.html#notes-on-comparison-of-compound-data","text":"Compound data can contain elements of any data-type. This includes blob, clob, object type, nested table, varray or even a nested-cursor within a cursor. Attributes in nested table and array types are compared as ordered lists of elements . If order of attributes in nested table and array differ, expectation will fail. Columns in compound data are compared as ordered list of elements by default. Use unordered_columns option when order of columns in cursor is not relevant Comparison of compound data is data-type aware. So a column ID NUMBER in a cursor is not the same as ID VARCHAR2(100) , even if they both hold the same numeric values. Comparison of cursor columns containing DATE will only compare date part and ignore time by default. See Comparing cursor data containing DATE fields to check how to enable date-time comparison in cursors. Comparison of cursor returning TIMESTAMP columns against cursor returning TIMESTAMP bind variables requires variables to be cast to proper precision. This is an Oracle SQL - PLSQL compatibility issue and usage of CAST is the only known workaround for now. See Comparing cursor data containing TIMESTAMP bind variables for examples. To compare nested table/varray type you need to convert it to anydata by using anydata.convertCollection() To compare object type you need to convert it to anydata by using anydata.convertObject() It is possible to compare PL/SQL records, collections, varrays and associative arrays. To compare this types of data, use cursor comparison feature of utPLSQL and TABLE operator in SQL query On Oracle 11g Release 2 - pipelined table functions are needed (see section Implicit (Shadow) Types in this artcile ) On Oracle 12c and above - use TABLE function on nested tables/varrays/associative arrays of PL/SQL records utPLSQL is not able to distinguish between NULL and whitespace-only column/attribute value when comparing compound data. This is due to Oracle limitation on of XMLType. See issue #880 for details. Note: This behavior might be fixed in future releases, when utPLSQL is no longer depending on XMLType for compound data comparison. utPLSQL offers advanced data-comparison options, for comparing compound data-types. The options allow you to: - define columns/attributes to exclude from comparison - define columns/attributes to include in comparison - and more ... For details on available options and how to use them, read the advanced data comparison guide.","title":"Notes on comparison of compound data"},{"location":"userguide/expectations.html#diff-functionality-for-compound-data-types","text":"When comparing compound data, utPLSQL will determine the difference between the expected and the actual data. The diff includes: - differences in column names, column positions and column data-type for cursor data - only data in columns/rows that differ The diff aims to make it easier to identify what is not expected in the actual data. Consider the following expected cursor data ID (NUMBER) FIRST_NAME (VARCHAR2) LAST_NAME (VARCHAR2) SALARY (NUMBER) 1 JACK SPARROW 10000 2 LUKE SKYWALKER 1000 3 TONY STARK 1000000 And the actual cursor data: ~~GENDER (VARCHAR2)~~ FIRST_NAME (VARCHAR2) LAST_NAME (VARCHAR2) SALARY (VARCHAR2) ID (NUMBER) M JACK SPARROW 25000 1 M TONY STARK 1000000 3 F JESSICA JONES 2345 4 M LUKE SKYWALKER 1000 2 The two data-sets above have the following differences: - column ID is misplaced (should be first column but is last) - column SALARY has data-type VARCHAR2 but should be NUMBER - column GENDER exists in actual but not in the expected (it is an Extra column) - data in column SALARY for row number 1 in actual is not matching expected - row number 2 in actual (ID=3) is not matching expected - row number 3 in actual (ID=4) is not matching expected - row number 4 in actual (ID=2) is not expected in results (Extra row in actual) utPLSQL will report all of the above differences in a readable format to help you identify what is not correct in the compared dataset. Below example illustrates, how utPLSQL will report such differences. declare l_actual sys_refcursor ; l_expected sys_refcursor ; begin open l_expected for select 1 as ID , 'JACK' as FIRST_NAME , 'SPARROW' AS LAST_NAME , 10000 AS SALARY from dual union all select 2 as ID , 'LUKE' as FIRST_NAME , 'SKYWALKER' AS LAST_NAME , 1000 AS SALARY from dual union all select 3 as ID , 'TONY' as FIRST_NAME , 'STARK' AS LAST_NAME , 100000 AS SALARY from dual ; open l_actual for select 'M' AS GENDER , 'JACK' as FIRST_NAME , 'SPARROW' AS LAST_NAME , 1 as ID , '25000' AS SALARY from dual union all select 'M' AS GENDER , 'TONY' as FIRST_NAME , 'STARK' AS LAST_NAME , 3 as ID , '100000' AS SALARY from dual union all select 'F' AS GENDER , 'JESSICA' as FIRST_NAME , 'JONES' AS LAST_NAME , 4 as ID , '2345' AS SALARY from dual union all select 'M' AS GENDER , 'LUKE' as FIRST_NAME , 'SKYWALKER' AS LAST_NAME , 2 as ID , '1000' AS SALARY from dual ; ut . expect ( l_actual ). to_equal ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: refcursor [ count = 4 ] was expected to equal: refcursor [ count = 3 ] Diff: Columns: Column <ID> is misplaced. Expected position: 1, actual position: 4. Column <SALARY> data-type is invalid. Expected: NUMBER, actual: VARCHAR2. Column <GENDER> [position: 1, data-type: CHAR] is not expected in results. Rows: [ 4 differences ] Row No. 1 - Actual: <SALARY>25000</SALARY> Row No. 1 - Expected: <SALARY>10000</SALARY> Row No. 2 - Actual: <FIRST_NAME>TONY</FIRST_NAME><LAST_NAME>STARK</LAST_NAME><ID>3</ID><SALARY>100000</SALARY> Row No. 2 - Expected: <ID>2</ID><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><SALARY>1000</SALARY> Row No. 3 - Actual: <FIRST_NAME>JESSICA</FIRST_NAME><LAST_NAME>JONES</LAST_NAME><ID>4</ID><SALARY>2345</SALARY> Row No. 3 - Expected: <ID>3</ID><FIRST_NAME>TONY</FIRST_NAME><LAST_NAME>STARK</LAST_NAME><SALARY>100000</SALARY> Row No. 4 - Extra: <GENDER>M</GENDER><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><ID>2</ID><SALARY>1000</SALARY> Row No. 4 - Extra: <GENDER>M</GENDER><FIRST_NAME>LUKE</FIRST_NAME><LAST_NAME>SKYWALKER</LAST_NAME><ID>2</ID><SALARY>1000</SALARY> at \"anonymous block\", line 21 utPLSQL identifies and reports on columns: - column misplacement - column data-type mismatch - extra/missing columns When comparing rows utPLSQL: - reports only mismatched columns when rows match - reports columns existing in both data-sets when whole row is not matching - reports whole extra (not expected) row from actual when actual has extra rows - reports whole missing (expected) row from expected when expected has extra rows","title":"Diff functionality for compound data-types"},{"location":"userguide/expectations.html#object-and-nested-table-data-type-comparison-examples","text":"When comparing object type / nested table / varray, utPLSQL will check: - if data-types match - if data in the compared elements is the same. The diff functionality for objects / nested tables / varrays is similar to diff on cursors. When diffing, utPLSQL will not check name and data-type of individual attribute as the type itself defines the underlying structure. Below examples demonstrate how to compare object and nested table data-types. Object type comparison. create type department as object ( name varchar2 ( 30 )) / create or replace function get_dept return department is begin return department ( 'IT' ); end ; / exec ut . expect ( anydata . convertObject ( get_dept () ) ). to_equal ( anydata . convertObject ( department ( 'HR' ) ) ); drop function get_dept ; drop type department ; Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.department was expected to equal: ut3.department Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <NAME>IT</NAME> Row No. 1 - Expected: <NAME>HR</NAME> at \"anonymous block\", line 1 Table type comparison. create type department as object ( name varchar2 ( 30 )) / create type departments as table of department / create or replace function get_depts return departments is begin return departments ( department ( 'IT' ), department ( 'HR' ) ); end ; / declare v_expected departments ; begin v_expected : = departments ( department ( 'HR' ), department ( 'IT' ) ); ut . expect ( anydata . convertCollection ( get_depts () ) ). to_equal ( anydata . convertCollection ( v_expected ) ); end ; / drop type function get_depts ; drop type departments ; drop type department ; Returns following output via DBMS_OUTPUT: FAILURE Actual: ut3.departments [ count = 2 ] was expected to equal: ut3.departments [ count = 2 ] Diff: Rows: [ 2 differences ] Row No. 1 - Actual: <NAME>IT</NAME> Row No. 1 - Expected: <NAME>HR</NAME> Row No. 2 - Actual: <NAME>HR</NAME> Row No. 2 - Expected: <NAME>IT</NAME> at \"anonymous block\", line 5 Some of the possible combinations of anydata and their results: clear screen set serverout on set feedback off create or replace type t_tab_varchar is table of varchar2 ( 1 ) / create or replace type dummy_obj as object ( id number , \"name\" varchar2 ( 30 ), \"Value\" varchar2 ( 30 ) ) / create or replace type dummy_obj_lst as table of dummy_obj / create or replace type t_varray is varray ( 1 ) of number / exec ut . expect ( anydata . convertObject ( dummy_obj ( 1 , 'A' , '0' ) ) ). to_equal ( anydata . convertObject ( dummy_obj ( 1 , 'A' , '0' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'B' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar () ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar () ) ); exec ut . expect ( anydata . convertCollection ( t_tab_varchar () ) ). to_equal ( anydata . convertCollection ( t_tab_varchar ( 'A' ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 2 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst () ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst ( dummy_obj ( 1 , 'A' , '0' ) ) ) ); exec ut . expect ( anydata . convertCollection ( dummy_obj_lst () ) ). to_equal ( anydata . convertCollection ( dummy_obj_lst () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_be_null (); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_have_count ( 0 ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray () ) ); exec ut . expect ( anydata . convertCollection ( t_varray () ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray ( 1 ) ) ). to_equal ( anydata . convertCollection ( t_varray ( 1 ) ) ); exec ut . expect ( anydata . convertCollection ( t_varray ( 1 ) ) ). to_equal ( anydata . convertCollection ( t_varray ( 2 ) ) ); drop type t_varray ; drop type dummy_obj_lst ; drop type dummy_obj ; drop type t_tab_varchar ; Returns following output via DBMS_OUTPUT: SUCCESS Actual: ut3.dummy_obj was expected to equal: ut3.dummy_obj SUCCESS Actual: ut3.t_tab_varchar [ count = 1 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] FAILURE Actual: ut3.t_tab_varchar [ count = 1 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> Row No. 1 - Expected: <T_TAB_VARCHAR>B</T_TAB_VARCHAR> at \"anonymous block\", line 1 FAILURE Actual: (ut3.t_tab_varchar [ count = 0 ]) Data-types: <T_TAB_VARCHAR>VARCHAR2</T_TAB_VARCHAR> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 0 ] FAILURE Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> at \"anonymous block\", line 1 SUCCESS Actual: (ut3.t_tab_varchar [ count = 0 ]) was expected to have [ count = 0 ] SUCCESS Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 0 ] FAILURE Actual: ut3.t_tab_varchar [ count = 0 ] was expected to equal: ut3.t_tab_varchar [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_TAB_VARCHAR>A</T_TAB_VARCHAR> at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 1 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] FAILURE Actual: ut3.dummy_obj_lst [ count = 1 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <ID>1</ID> Row No. 1 - Expected: <ID>2</ID> at \"anonymous block\", line 1 FAILURE Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <DUMMY_OBJ><ID>1</ID><name>A</name><Value>0</Value></DUMMY_OBJ> at \"anonymous block\", line 1 FAILURE Actual: (ut3.dummy_obj_lst [ count = 0 ]) Data-types: <DUMMY_OBJ>DUMMY_OBJ</DUMMY_OBJ> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 0 ] SUCCESS Actual: (ut3.dummy_obj_lst [ count = 0 ]) was expected to have [ count = 0 ] FAILURE Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <DUMMY_OBJ><ID>1</ID><name>A</name><Value>0</Value></DUMMY_OBJ> at \"anonymous block\", line 1 SUCCESS Actual: ut3.dummy_obj_lst [ count = 0 ] was expected to equal: ut3.dummy_obj_lst [ count = 0 ] FAILURE Actual: (ut3.t_varray [ count = 0 ]) Data-types: <T_VARRAY>NUMBER</T_VARRAY> Data: was expected to be null at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 0 ] FAILURE Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_VARRAY>1</T_VARRAY> at \"anonymous block\", line 1 SUCCESS Actual: (ut3.t_varray [ count = 0 ]) was expected to have [ count = 0 ] SUCCESS Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 0 ] FAILURE Actual: ut3.t_varray [ count = 0 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Missing: <T_VARRAY>1</T_VARRAY> at \"anonymous block\", line 1 SUCCESS Actual: ut3.t_varray [ count = 1 ] was expected to equal: ut3.t_varray [ count = 1 ] FAILURE Actual: ut3.t_varray [ count = 1 ] was expected to equal: ut3.t_varray [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <T_VARRAY>1</T_VARRAY> Row No. 1 - Expected: <T_VARRAY>2</T_VARRAY> at \"anonymous block\", line 1","title":"Object and nested table data-type comparison examples"},{"location":"userguide/expectations.html#comparing-cursor-data-containing-date-fields","text":"Important note utPLSQL uses XMLType internally to represent rows of the cursor data. This is by far the most flexible method and allows comparison of cursors containing LONG, CLOB, BLOB, user defined types and even nested cursors. Due to the way Oracle handles DATE data type when converting from cursor data to XML, utPLSQL has no control over the DATE formatting. The NLS_DATE_FORMAT setting from the moment the cursor was opened determines the formatting of dates used for cursor data comparison. By default, Oracle NLS_DATE_FORMAT is timeless, so data of DATE datatype, will be compared ignoring the time component. You should surround cursors and expectations with procedures ut.set_nls , ut.reset_nls . This way, the DATE data in cursors will be properly formatted for comparison using date-time format. The example below makes use of ut.set_nls , ut.reset_nls , so that the date in l_expected and l_actual is compared using date-time formatting. clear screen alter session set nls_date_format = 'yyyy-mm-dd' ; set serverout on set feedback off create table events ( description varchar2 ( 4000 ), event_date date ) / declare c_description constant varchar2 ( 30 ) : = 'Test event' ; c_event_date constant date : = to_date ( '2016-09-08 06:51:22' , 'yyyy-mm-dd hh24:mi:ss' ); c_second constant number : = 1 / 24 / 60 / 60 ; l_actual sys_refcursor ; l_expected sys_refcursor ; begin --Arrange insert into events ( description , event_date ) values ( c_description , c_event_date ); begin -- Change the NLS settings for date to be ISO date-time 'YYYY-MM-DD HH24:MI:SS' ut . set_nls (); --Act open l_expected for select c_description as description , c_event_date + c_second as event_date from dual ; open l_actual for select description , event_date from events ; --Assert ut . expect ( l_actual ). not_to_equal ( l_expected ); -- Reset the NLS settings to their default values after cursor data was processed ut . reset_nls (); end ; begin --Act open l_expected for select c_description as description , c_event_date + c_second as event_date from dual ; open l_actual for select description , event_date from events ; --Assert ut . expect ( l_actual ). not_to_equal ( l_expected ); end ; --Cleanup rollback ; end ; / drop table events ; In the above example: - The first expectation is successful, as the l_expected cursor contains different date-time then the cursor returned by get_events function call - The second expectation fails, as the column event_date will get compared as DATE without TIME (using default current session NLS date format) Output via DBMS_OUTPUT from the above example: SUCCESS Actual: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08T06:51:22</EVENT_DATE></ROW> was expected not to equal: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08T06:51:23</EVENT_DATE></ROW> FAILURE Actual: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08</EVENT_DATE></ROW> was expected not to equal: (refcursor [ count = 1 ]) Data-types: <DESCRIPTION>VARCHAR2</DESCRIPTION><EVENT_DATE>DATE</EVENT_DATE> Data: <ROW><DESCRIPTION>Test event</DESCRIPTION><EVENT_DATE>2016-09-08</EVENT_DATE></ROW> at \"anonymous block\", line 28","title":"Comparing cursor data containing DATE fields"},{"location":"userguide/expectations.html#comparing-cursor-data-containing-timestamp-bind-variables","text":"To properly compare timestamp column data returned by cursor against bind variable data from another cursor, a conversion needs to be done. This applies to timestamp , timestamp with timezone , timestamp with local timezone data types. Example below illustrates usage of cast operator to assure appropriate precision is applied on timestamp bind-variables in cursor result-set clear screen set serverout on set feedback off create table timestamps ( ts3 timestamp ( 3 ), ts6 timestamp ( 6 ), ts9 timestamp ( 9 ) ); declare l_time timestamp ( 9 ); l_expected sys_refcursor ; l_actual sys_refcursor ; begin --Arrange l_time : = systimestamp ; insert into timestamps ( ts3 , ts6 , ts9 ) values ( l_time , l_time , l_time ); begin --Act open l_expected for select cast ( l_time as timestamp ( 3 )) as ts3 , cast ( l_time as timestamp ( 6 )) as ts6 , cast ( l_time as timestamp ( 9 )) as ts9 from dual ; open l_actual for select ts3 , ts6 , ts9 from timestamps ; --Assert ut . expect ( l_actual ). to_equal ( l_expected ); end ; begin open l_expected for select l_time as ts3 , l_time as ts6 , l_time as ts9 from dual ; open l_actual for select ts3 , ts6 , ts9 from timestamps ; --Assert ut . expect ( l_actual ). to_equal ( l_expected ); end ; end ; / drop table timestamps ; Returns following output via DBMS_OUTPUT: SUCCESS Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] FAILURE Actual: refcursor [ count = 1 ] was expected to equal: refcursor [ count = 1 ] Diff: Rows: [ 1 differences ] Row No. 1 - Actual: <TS3>2019-07-08T22:08:41.899</TS3><TS6>2019-07-08T22:08:41.899319</TS6> Row No. 1 - Expected: <TS3>2019-07-08T22:08:41.899319000</TS3><TS6>2019-07-08T22:08:41.899319000</TS6> at \"anonymous block\", line 32","title":"Comparing cursor data containing TIMESTAMP bind variables"},{"location":"userguide/expectations.html#comparing-json-objects","text":"utPLSQL is capable of comparing json data-types of json_element_t on Oracle 12.2 and above , and also json on Oracle 21 and above Note: Whenever a database is upgraded to compatible version the utPLSQL needs to be reinstalled to pick up json changes. E.g. upgrade from 18c to 21c to enable json type compare.","title":"Comparing Json objects"},{"location":"userguide/expectations.html#notes-on-comparison-of-json-data","text":"Json data can contain objects, scalar or arrays. During comparison of json objects the order doesn't matter. During comparison of json arrays the index of element is taken into account To compare json you have to make sure its type of json_element_t or its subtypes From version 21 and above a native json type is supported. Compare JSON example using json_element_t : declare l_expected json_element_t ; l_actual json_element_t ; begin l_expected : = json_element_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Birthdate\": \"July 3, 1962\", \"hasChildren\": true, \"children\": [ \"Connor\" ] }, { \"name\": \"Robert Downey Jr.\", \"age\": 53, \"Birthdate\": \"April 4, 1965\", \"hasChildren\": true, \"children\": [ \"Exton Elias\" ] } ] }' ); l_actual : = json_element_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Birthdate\": \"1962.07.03\", \"hasChildren\": true, \"children\": [ \"Suri\", \"Isabella Jane\", \"Connor\" ] }, { \"name\": \"Jr., Robert Downey\", \"age\": 53, \"Birthdate\": \"April 4, 1965\", \"hasChildren\": true, \"children\": [ \"Indio Falconer\", \"Avri Roel\", \"Exton Elias\" ] } ] }' ); ut . expect ( l_actual ). to_equal ( l_expected ); end ; Returns following output via DBMS_OUTPUT: FAILURE Actual: json was expected to equal: json Diff: 8 differences found 4 unequal values, 4 missing properties Extra property: \"Avri Roel\" on path: $.\"Actors\"[1].\"children\"[1] Extra property: \"Isabella Jane\" on path: $.\"Actors\"[0].\"children\"[1] Extra property: \"Connor\" on path: $.\"Actors\"[0].\"children\"[2] Extra property: \"Exton Elias\" on path: $.\"Actors\"[1].\"children\"[2] Actual value: \"Robert Downey Jr.\" was expected to be: \"Jr., Robert Downey\" on path: $.\"Actors\"[1].\"name\" Actual value: \"July 3, 1962\" was expected to be: \"1962.07.03\" on path: $.\"Actors\"[0].\"Birthdate\" Actual value: \"Connor\" was expected to be: \"Suri\" on path: $.\"Actors\"[0].\"children\"[0] Actual value: \"Exton Elias\" was expected to be: \"Indio Falconer\" on path: $.\"Actors\"[1].\"children\"[0] at \"anonymous block\", line 59 Comparing parts of JSON example using json_element_t subtypes: declare l_actual json_object_t ; l_actual_extract json_array_t ; l_expected json_array_t ; begin -- Arrange l_expected : = json_array_t . parse ( ' [ \"Indio Falconer\", \"Avri Roel\", \"Exton Elias\" ]' ); l_actual : = json_object_t . parse ( ' { \"Actors\": [ { \"name\": \"Tom Cruise\", \"age\": 56, \"Born At\": \"Syracuse, NY\", \"Birthdate\": \"July 3, 1962\", \"photo\": \"https://jsonformatter.org/img/tom-cruise.jpg\", \"wife\": null, \"weight\": 67.5, \"hasChildren\": true, \"hasGreyHair\": false, \"children\": [ \"Suri\", \"Isabella Jane\", \"Connor\" ] }, { \"name\": \"Robert Downey Jr.\", \"age\": 53, \"Born At\": \"New York City, NY\", \"Birthdate\": \"April 4, 1965\", \"photo\": \"https://jsonformatter.org/img/Robert-Downey-Jr.jpg\", \"wife\": \"Susan Downey\", \"weight\": 77.1, \"hasChildren\": true, \"hasGreyHair\": false, \"children\": [ \"Indio Falconer\", \"Exton Elias\" ] } ] }' ); l_actual_extract : = json_array_t ( json_query ( l_actual . stringify , '$.Actors[1].children' )); --Act ut . expect ( l_actual_extract ). to_equal ( l_expected ); end ; / Returns following output via DBMS_OUTPUT: FAILURE Actual: json was expected to equal: json Diff: 2 differences found 1 unequal values, 1 missing properties Missing property: \"Exton Elias\" on path: $[2] Actual value: \"Avri Roel\" was expected to be: \"Exton Elias\" on path: $[1] at \"anonymous block\", line 55","title":"Notes on comparison of json data"},{"location":"userguide/getting-started.html","text":"Getting started with TDD and utPLSQL \u00b6 utPLSQL is designed in a way that allows you to follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD. Gather requirements \u00b6 We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position Create a test \u00b6 We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable. Create test package \u00b6 create or replace package test_betwnstr as --%suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Define specification for the test \u00b6 create or replace package test_betwnstr as --%suite(Between string function) --%test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as the package specification requires a body. Define body of first test \u00b6 create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing as the test suite package body is invalid. Looks like we need to define the function we want to test. Implement code to fulfill the requirement \u00b6 Define tested function \u00b6 create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return the expected results. Let us fix this and continue from here. Fix the tested function \u00b6 The function returned a string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great! Refactor \u00b6 Once our tests are passing, we can safely refactor (restructure) the code as we have a safety harness in place to ensure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is equally important. Further requirements \u00b6 It seems like our work is done. We have a function that returns a substring from start position to end position. As we move through the process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of these edge cases. Once defined we can start implementing tests for those behaviors and adjust the tested function to meet the requirements specified in the tests. Add test for additional requirement \u00b6 A new requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as --%suite(Between string function) --%test(Returns substring from start position to end position) procedure basic_usage ; --%test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position. Implementing the requirement \u00b6 Let's fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress. Refactoring \u00b6 When all tests are passing we can proceed with a safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. An alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Remaining requirements \u00b6 You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Getting Started"},{"location":"userguide/getting-started.html#getting-started-with-tdd-and-utplsql","text":"utPLSQL is designed in a way that allows you to follow Test Driven Development (TDD) software development process. Below is an example of building a simple function with TDD.","title":"Getting started with TDD and utPLSQL"},{"location":"userguide/getting-started.html#gather-requirements","text":"We have a requirement to build a function that will return a substring of a string that is passed to the function. The function should accept three parameters: input_string start_position end_position","title":"Gather requirements"},{"location":"userguide/getting-started.html#create-a-test","text":"We will start from the bare minimum and move step by step, executing tests every time we make minimal progress. This way, we assure we don't jump ahead too much and produce code that is untested or untestable.","title":"Create a test"},{"location":"userguide/getting-started.html#create-test-package","text":"create or replace package test_betwnstr as --%suite(Between string function) end ; / Execute all tests: begin ut.run(); end; Test results: Between string function Finished in .451423 seconds 0 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Create test package"},{"location":"userguide/getting-started.html#define-specification-for-the-test","text":"create or replace package test_betwnstr as --%suite(Between string function) --%test(Returns substring from start position to end position) procedure basic_usage ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04067: not executed, package body \"UT3_USER.TEST_BETWNSTR\" does not exist ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .509673 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Well our test is failing as the package specification requires a body.","title":"Define specification for the test"},{"location":"userguide/getting-started.html#define-body-of-first-test","text":"create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage ORA-04063: package body \"UT3_USER.TEST_BETWNSTR\" has errors ORA-06508: PL/SQL: could not find program unit being called: \"UT3_USER.TEST_BETWNSTR\" ORA-06512: at line 6 Finished in .415851 seconds 1 tests, 0 failed, 1 errored, 0 disabled, 0 warning(s) Our test is failing as the test suite package body is invalid. Looks like we need to define the function we want to test.","title":"Define body of first test"},{"location":"userguide/getting-started.html#implement-code-to-fulfill-the-requirement","text":"","title":"Implement code to fulfill the requirement"},{"location":"userguide/getting-started.html#define-tested-function","text":"create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position (FAILED - 1) Failures: 1) basic_usage Actual: '234' (varchar2) was expected to equal: '2345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 5 Finished in .375178 seconds 1 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) So now we see that our test works but the function does not return the expected results. Let us fix this and continue from here.","title":"Define tested function"},{"location":"userguide/getting-started.html#fix-the-tested-function","text":"The function returned a string one character short, so we need to add 1 to the substr parameter. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Finished in .006077 seconds 1 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) So our test is now passing, great!","title":"Fix the tested function"},{"location":"userguide/getting-started.html#refactor","text":"Once our tests are passing, we can safely refactor (restructure) the code as we have a safety harness in place to ensure that after the restructuring and cleanup of the code, everything is still working. One thing worth mentioning is that refactoring of tests is as important as refactoring of code. Maintainability of both is equally important.","title":"Refactor"},{"location":"userguide/getting-started.html#further-requirements","text":"It seems like our work is done. We have a function that returns a substring from start position to end position. As we move through the process of adding tests, it's very important to think about edge cases. Here is a list of edge cases for our function: start position zero input string is null start position is null end position is null start position is negative start position is bigger than end position start position is negative end position is negative We should define expected behavior for each of these edge cases. Once defined we can start implementing tests for those behaviors and adjust the tested function to meet the requirements specified in the tests.","title":"Further requirements"},{"location":"userguide/getting-started.html#add-test-for-additional-requirement","text":"A new requirement was added: Start position zero - should be treated as start position one create or replace package test_betwnstr as --%suite(Between string function) --%test(Returns substring from start position to end position) procedure basic_usage ; --%test(Returns substring when start position is zero) procedure zero_start_position ; end ; / create or replace package body test_betwnstr as procedure basic_usage is begin ut . expect ( betwnstr ( '1234567' , 2 , 5 ) ). to_equal ( '2345' ); end ; procedure zero_start_position is begin ut . expect ( betwnstr ( '1234567' , 0 , 5 ) ). to_equal ( '12345' ); end ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero (FAILED - 1) Failures: 1) zero_start_position Actual: '123456' (varchar2) was expected to equal: '12345' (varchar2) at \"\"UT3_USER.TEST_BETWNSTR\"\", line 10 Finished in .232584 seconds 2 tests, 1 failed, 0 errored, 0 disabled, 0 warning(s) Looks like our function does not work as expected for zero start position.","title":"Add test for additional requirement"},{"location":"userguide/getting-started.html#implementing-the-requirement","text":"Let's fix our function so that the new requirement is met create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin if a_start_pos = 0 then return substr ( a_string , a_start_pos , a_end_pos - a_start_pos ); else return substr ( a_string , a_start_pos , a_end_pos - a_start_pos + 1 ); end if ; end ; / Execute test package: begin ut.run('test_betwnstr'); end; Test results: Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .012718 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s) Great! We have made some visible progress.","title":"Implementing the requirement"},{"location":"userguide/getting-started.html#refactoring","text":"When all tests are passing we can proceed with a safe cleanup of our code. The function works well, but we use the return twice, which is not the best coding practice. An alternative implementation could be cleaner. create or replace function betwnstr ( a_string varchar2 , a_start_pos integer , a_end_pos integer ) return varchar2 is begin return substr ( a_string , a_start_pos , a_end_pos - greatest ( a_start_pos , 1 ) + 1 ); end ; / As we refactor we should probably run our tests as often as we compile code, so we know not only that the code compiles, but also works as expected. Between string function Returns substring from start position to end position Returns substring when start position is zero Finished in .013739 seconds 2 tests, 0 failed, 0 errored, 0 disabled, 0 warning(s)","title":"Refactoring"},{"location":"userguide/getting-started.html#remaining-requirements","text":"You may continue on with the remaining edge cases from here. identify requirement define requirement with test run test to check if requirement is met implement code to meet requirement run test to check if requirement is met refactor/cleanup code and tests Hope you will enjoy it as much as we do.","title":"Remaining requirements"},{"location":"userguide/install.html","text":"Supported database versions \u00b6 utPLSQL is continuously tested against following versions of Oracle databases 11g R2 12c 12c R2 18c 19c We do our best to assure full compatibility with supported versions of Oracle databases See Requirements \u00b6 utPLSQL will run on any Oracle Database version 11g relase 2 or above. Licensed features required \u00b6 utPLSQL doesn't require any extra licensed features of Oracle database. It can be installed on any Standard Edition Oracle Database. In fact, it even supports Oracle 11g XE which is a free Oracle Database version with minimal features and storage limits. Storage requirements \u00b6 utPLSQL will use tablespace for the following: - storage of annotation cache - storage of suite cache - storage of profiler results - storage for staging utPLSQL reports outputs utPLSQL purges the staging storage for reports while fetching reports to screen / saving reports to files. Suite and annotation cache storage requirements are minimal and unless you have hundreds of thousands of tests, you'll probably not even notice the space used. Profiler results may require regular purging to assure low space consumption. utPLSQl does not purge profiler tables as those tables can can be shared with other tools. Downloading utPLSQL \u00b6 Manual download \u00b6 Go to GitHub releases page for utPLSQL https://github.com/utPLSQL/utPLSQL/releases Choose the version to download - latest is always greatest Download one of files utPLSQL.tar.gz utPLSQL.zip The files have identical content but use different compression (tar / zip ) so choose whichever you prefer depending on your platform (Win/Mac/Unix/Linux). Scripted download of latest utPLSQL version \u00b6 The below snippets can be used to download latest version of utPLSQL from github releases. After downloading follow the installation instructions in next sections of this document. Unix/Linux \u00b6 #!/bin/bash # Get the url to latest release \"zip\" file UTPLSQL_DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' ) Windows \u00b6 To run the script on windows you will need PowerShell 3.0 or above. You will also need .NET 4.0 Framework or above. $archiveName = 'utPLSQL.zip' $latestRepo = Invoke-WebRequest https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest $repo = $latestRepo.Content | Convertfrom-Json $urlList = $repo.assets.browser_download_url Add-Type -assembly \"system.io.compression.filesystem\" foreach ($i in $urlList) { $fileName = $i.substring($i.LastIndexOf( \"/\" ) + 1) if ( $fileName.substring($fileName.LastIndexOf(\".\") + 1) -eq 'zip' ) { Invoke-WebRequest $i -OutFile $archiveName $fileLocation = Get-ChildItem | where {$_.Name -eq $archiveName} if ($fileLocation) { [io.compression.zipfile]::ExtractToDirectory($($fileLocation.FullName),$($fileLocation.DirectoryName)) } } } Headless installation \u00b6 utPLSQL can be installed with DDL trigger, to enable tracking of DDL changes to your unit test packages. This is the recommended installation approach, when you want to compile and run unit test packages in a schema containing huge amount of database packages (for example Oracle EBS installation schema). The reason for having DDL trigger is to enable in-time annotation parsing for utPLSQL. Without DDL trigger, utPLSQL needs to investigate your schema objects last_ddl_timestamp each time tests are executed to check if any of DB packages were changed in given schema and if they need scanning for annotation changes. This process can be time-consuming if DB schema is large. The headless scripts accept three optional parameters that define: - username to create as owner of utPLSQL (default ut3 ) - password for owner of utPLSQL (default XNtxj8eEgA6X6b6f ) - tablespace to use for storage of profiler data (default users ) The scripts need to be executed by SYSDBA , in order to grant access to DBMS_LOCK and DBMS_CRYPTO system packages. Note: Grant on DBMS_LOCK is required only for installation on Oracle versions below 18c. For versions 18c and above, utPLSQL uses DBMS_SESSION.SLEEP so access to DBMS_LOCK package is no longer needed. Note: The user performing the installation must have the ADMINISTER DATABASE TRIGGER privilege. This is required for installation of trigger that is responsible for parsing annotations at at compile-time of a package. Note: When installing with DDL trigger, utPLSQL will not be registering unit tests for any of oracle-maintained schemas. For Oracle 11g following users are excluded: ANONYMOUS, APPQOSSYS, AUDSYS, DBSFWUSER, DBSNMP, DIP, GGSYS, GSMADMIN_INTERNAL, GSMCATUSER, GSMUSER, ORACLE_OCM, OUTLN, REMOTE_SCHEDULER_AGENT, SYS, SYS$UMF, SYSBACKUP, SYSDG, SYSKM, SYSRAC, SYSTEM, WMSYS, XDB, XS$NULL For Oracle 12c and above the users returned by below query are excluded by utPLSQL: select username from all_users where oracle_maintained = 'Y' ; Installation without DDL trigger \u00b6 To install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @install_headless.sql Invoking script with parameters: cd source sqlplus sys/sys_pass@db as sysdba @install_headless.sql utp3 my_verySecret_password utp3_tablespace Installation with DDL trigger \u00b6 To install the utPLSQL into a new database schema and grant it to public, execute the script install_headless_with_trigger.sql as SYSDBA. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @install_headless_with_trigger.sql Invoking script with parameters: cd source sqlplus sys/sys_pass@db as sysdba @install_headless_with_trigger.sql utp3 my_verySecret_password utp3_tablespace Recommended Schema \u00b6 It is highly recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. Installing uPLSQL into a shared schema is really not recommended as you loose isolation of framework. If the installing user and utPLSQL owner is one and the same, the user must have the following Oracle system permissions before you can proceed with the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE SEQUENCE CREATE VIEW CREATE SYNONYM ALTER SESSION CREATE TRIGGER In addition, the user must be granted the execute privilege on DBMS_LOCK and DBMS_CRYPTO packages. utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. It is up to DBA to maintain the storage of the profiler tables. Manual installation procedure \u00b6 Creating schema for utPLSQL \u00b6 To create the utPLSQL schema and grant all the required privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users Installing utPLSQL \u00b6 To install the utPLSQL framework into your database, go to source directory, run the install.sql providing the schema_name for utPLSQL as parameter. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3 Installing DDL trigger \u00b6 To minimize startup time of utPLSQL framework (especially on a database with large schema) it is recommended to install utPLSQL DDL trigger to enable utPLSQL annotation to be updated at compile-time. It's recommended to install DDL trigger when connected as SYSDBA user. Trigger is created in utPLSQL schema. If using the owner schema of utPLSQL to install trigger, the owner needs to have ADMINISTER DATABASE TRIGGER and CREATE TRIGGER system privileges. If using different user to install trigger, the user needs to have ADMINISTER DATABASE TRIGGER and CREATE ANY TRIGGER system privileges. To install DDL trigger go to source directory, run the install_ddl_trigger.sql providing the schema_name for utPLSQL as parameter. Example invocation: cd source sqlplus admin/admins_password@database @install_ddl_trigger.sql ut3 Note: Trigger can be installed ant any point in time. Allowing other users to access the utPLSQL framework \u00b6 In order to allow other users to access utPLSQL, synonyms must be created and privileges granted. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to an individual user, execute scripts source/create_user_grants.sql and source/create_user_synonyms.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus ut3_owner_schema/ut3_password@database @create_user_grants.sql ut3 hr sqlplus user/user_password@database @create_user_synonyms.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer Checking environment and utPLSQL version \u00b6 To check the framework version execute the following query: select substr ( ut . version (), 1 , 60 ) as ut_version from dual ; Additionally you may retrieve more information about your environment by executing the following query: select xmlserialize ( content xmltype ( ut_run_info ()) as clob indent size = 2 ) from dual ; Additional requirements \u00b6 In order to use the Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges. Uninstalling utPLSQL \u00b6 To uninstall run uninstall.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @uninstall.sql ut3 The uninstall script will remove all the objects installed by the installation script. Additionally, all the public and private synonyms pointing to the objects in the utPLSQL schema will be removed. If you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. The uninstall script does not drop the schema. In order for the uninstall to be successful, you need to use the uninstall script that was provided with the exact utPLSQL version installed on your database. i.e. the uninstall script provided with version 3.1.11 will not work correctly if you want to remove version 3.0.0 from your database. Alternatively you can drop the user that owns utPLSQL and re-create it using headless install. Version upgrade \u00b6 Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install the new version. Working with utPLSQL v2 \u00b6 If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in a different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Installation"},{"location":"userguide/install.html#supported-database-versions","text":"utPLSQL is continuously tested against following versions of Oracle databases 11g R2 12c 12c R2 18c 19c We do our best to assure full compatibility with supported versions of Oracle databases See","title":"Supported database versions"},{"location":"userguide/install.html#requirements","text":"utPLSQL will run on any Oracle Database version 11g relase 2 or above.","title":"Requirements"},{"location":"userguide/install.html#licensed-features-required","text":"utPLSQL doesn't require any extra licensed features of Oracle database. It can be installed on any Standard Edition Oracle Database. In fact, it even supports Oracle 11g XE which is a free Oracle Database version with minimal features and storage limits.","title":"Licensed features required"},{"location":"userguide/install.html#storage-requirements","text":"utPLSQL will use tablespace for the following: - storage of annotation cache - storage of suite cache - storage of profiler results - storage for staging utPLSQL reports outputs utPLSQL purges the staging storage for reports while fetching reports to screen / saving reports to files. Suite and annotation cache storage requirements are minimal and unless you have hundreds of thousands of tests, you'll probably not even notice the space used. Profiler results may require regular purging to assure low space consumption. utPLSQl does not purge profiler tables as those tables can can be shared with other tools.","title":"Storage requirements"},{"location":"userguide/install.html#downloading-utplsql","text":"","title":"Downloading utPLSQL"},{"location":"userguide/install.html#manual-download","text":"Go to GitHub releases page for utPLSQL https://github.com/utPLSQL/utPLSQL/releases Choose the version to download - latest is always greatest Download one of files utPLSQL.tar.gz utPLSQL.zip The files have identical content but use different compression (tar / zip ) so choose whichever you prefer depending on your platform (Win/Mac/Unix/Linux).","title":"Manual download"},{"location":"userguide/install.html#scripted-download-of-latest-utplsql-version","text":"The below snippets can be used to download latest version of utPLSQL from github releases. After downloading follow the installation instructions in next sections of this document.","title":"Scripted download of latest utPLSQL version"},{"location":"userguide/install.html#unixlinux","text":"#!/bin/bash # Get the url to latest release \"zip\" file UTPLSQL_DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ UTPLSQL_DOWNLOAD_URL } \" -o utPLSQL.zip # Extract downloaded \"zip\" file unzip -q utPLSQL.zip You may download with a one-liner if that is more convenient. #!/bin/bash curl -LOk $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' )","title":"Unix/Linux"},{"location":"userguide/install.html#windows","text":"To run the script on windows you will need PowerShell 3.0 or above. You will also need .NET 4.0 Framework or above. $archiveName = 'utPLSQL.zip' $latestRepo = Invoke-WebRequest https://api.github.com/repos/utPLSQL/utPLSQL/releases/latest $repo = $latestRepo.Content | Convertfrom-Json $urlList = $repo.assets.browser_download_url Add-Type -assembly \"system.io.compression.filesystem\" foreach ($i in $urlList) { $fileName = $i.substring($i.LastIndexOf( \"/\" ) + 1) if ( $fileName.substring($fileName.LastIndexOf(\".\") + 1) -eq 'zip' ) { Invoke-WebRequest $i -OutFile $archiveName $fileLocation = Get-ChildItem | where {$_.Name -eq $archiveName} if ($fileLocation) { [io.compression.zipfile]::ExtractToDirectory($($fileLocation.FullName),$($fileLocation.DirectoryName)) } } }","title":"Windows"},{"location":"userguide/install.html#headless-installation","text":"utPLSQL can be installed with DDL trigger, to enable tracking of DDL changes to your unit test packages. This is the recommended installation approach, when you want to compile and run unit test packages in a schema containing huge amount of database packages (for example Oracle EBS installation schema). The reason for having DDL trigger is to enable in-time annotation parsing for utPLSQL. Without DDL trigger, utPLSQL needs to investigate your schema objects last_ddl_timestamp each time tests are executed to check if any of DB packages were changed in given schema and if they need scanning for annotation changes. This process can be time-consuming if DB schema is large. The headless scripts accept three optional parameters that define: - username to create as owner of utPLSQL (default ut3 ) - password for owner of utPLSQL (default XNtxj8eEgA6X6b6f ) - tablespace to use for storage of profiler data (default users ) The scripts need to be executed by SYSDBA , in order to grant access to DBMS_LOCK and DBMS_CRYPTO system packages. Note: Grant on DBMS_LOCK is required only for installation on Oracle versions below 18c. For versions 18c and above, utPLSQL uses DBMS_SESSION.SLEEP so access to DBMS_LOCK package is no longer needed. Note: The user performing the installation must have the ADMINISTER DATABASE TRIGGER privilege. This is required for installation of trigger that is responsible for parsing annotations at at compile-time of a package. Note: When installing with DDL trigger, utPLSQL will not be registering unit tests for any of oracle-maintained schemas. For Oracle 11g following users are excluded: ANONYMOUS, APPQOSSYS, AUDSYS, DBSFWUSER, DBSNMP, DIP, GGSYS, GSMADMIN_INTERNAL, GSMCATUSER, GSMUSER, ORACLE_OCM, OUTLN, REMOTE_SCHEDULER_AGENT, SYS, SYS$UMF, SYSBACKUP, SYSDG, SYSKM, SYSRAC, SYSTEM, WMSYS, XDB, XS$NULL For Oracle 12c and above the users returned by below query are excluded by utPLSQL: select username from all_users where oracle_maintained = 'Y' ;","title":"Headless installation"},{"location":"userguide/install.html#installation-without-ddl-trigger","text":"To install the utPLSQL into a new database schema and grant it to public, execute the script install_headless.sql as SYSDBA. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @install_headless.sql Invoking script with parameters: cd source sqlplus sys/sys_pass@db as sysdba @install_headless.sql utp3 my_verySecret_password utp3_tablespace","title":"Installation without DDL trigger"},{"location":"userguide/install.html#installation-with-ddl-trigger","text":"To install the utPLSQL into a new database schema and grant it to public, execute the script install_headless_with_trigger.sql as SYSDBA. Example invocation of the script from command line: cd source sqlplus sys/sys_pass@db as sysdba @install_headless_with_trigger.sql Invoking script with parameters: cd source sqlplus sys/sys_pass@db as sysdba @install_headless_with_trigger.sql utp3 my_verySecret_password utp3_tablespace","title":"Installation with DDL trigger"},{"location":"userguide/install.html#recommended-schema","text":"It is highly recommended to install utPLSQL in it's own schema. You are free to choose any name for this schema. Installing uPLSQL into a shared schema is really not recommended as you loose isolation of framework. If the installing user and utPLSQL owner is one and the same, the user must have the following Oracle system permissions before you can proceed with the installation. CREATE SESSION CREATE PROCEDURE CREATE TYPE CREATE TABLE CREATE SEQUENCE CREATE VIEW CREATE SYNONYM ALTER SESSION CREATE TRIGGER In addition, the user must be granted the execute privilege on DBMS_LOCK and DBMS_CRYPTO packages. utPLSQL is using DBMS_PROFILER tables for code coverage. The tables required by DBMS_PROFILER will be created in the installation schema unless they already exist. It is up to DBA to maintain the storage of the profiler tables.","title":"Recommended Schema"},{"location":"userguide/install.html#manual-installation-procedure","text":"","title":"Manual installation procedure"},{"location":"userguide/install.html#creating-schema-for-utplsql","text":"To create the utPLSQL schema and grant all the required privileges execute script create_utplsql_owner.sql from the source directory with parameters: user name - the name of the user that will own of utPLSQL object password - the password to be set for that user tablespace name - the tablespace name to hold data created during test execution Example invocation: cd source sqlplus sys/sys_password@database as sysdba @create_utPLSQL_owner.sql ut3 ut3 users","title":"Creating schema for utPLSQL"},{"location":"userguide/install.html#installing-utplsql","text":"To install the utPLSQL framework into your database, go to source directory, run the install.sql providing the schema_name for utPLSQL as parameter. Schema must be created prior to calling the install script. You may install utPLSQL from any account that has sufficient privileges to create objects in other users schema. Example invocation: cd source sqlplus admin/admins_password@database @install.sql ut3","title":"Installing utPLSQL"},{"location":"userguide/install.html#installing-ddl-trigger","text":"To minimize startup time of utPLSQL framework (especially on a database with large schema) it is recommended to install utPLSQL DDL trigger to enable utPLSQL annotation to be updated at compile-time. It's recommended to install DDL trigger when connected as SYSDBA user. Trigger is created in utPLSQL schema. If using the owner schema of utPLSQL to install trigger, the owner needs to have ADMINISTER DATABASE TRIGGER and CREATE TRIGGER system privileges. If using different user to install trigger, the user needs to have ADMINISTER DATABASE TRIGGER and CREATE ANY TRIGGER system privileges. To install DDL trigger go to source directory, run the install_ddl_trigger.sql providing the schema_name for utPLSQL as parameter. Example invocation: cd source sqlplus admin/admins_password@database @install_ddl_trigger.sql ut3 Note: Trigger can be installed ant any point in time.","title":"Installing DDL trigger"},{"location":"userguide/install.html#allowing-other-users-to-access-the-utplsql-framework","text":"In order to allow other users to access utPLSQL, synonyms must be created and privileges granted. You have two options: use grants and synonyms to public, to allow all users to access the framework use synonyms and grants for individual users to limit the access to the framework To grant utPLSQL to public execute script source/create_synonyms_and_grants_for_public.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @create_synonyms_and_grants_for_public.sql ut3 To grant utPLSQL to an individual user, execute scripts source/create_user_grants.sql and source/create_user_synonyms.sql , provide schema_name where utPLSQL is installed and user_name to grant access for. Example invocation: cd source sqlplus ut3_owner_schema/ut3_password@database @create_user_grants.sql ut3 hr sqlplus user/user_password@database @create_user_synonyms.sql ut3 hr The following tools that support the SQL*Plus commands can be used to run the installation script: SQL*Plus SQLcl Oracle SQL Developer","title":"Allowing other users to access the utPLSQL framework"},{"location":"userguide/install.html#checking-environment-and-utplsql-version","text":"To check the framework version execute the following query: select substr ( ut . version (), 1 , 60 ) as ut_version from dual ; Additionally you may retrieve more information about your environment by executing the following query: select xmlserialize ( content xmltype ( ut_run_info ()) as clob indent size = 2 ) from dual ;","title":"Checking environment and utPLSQL version"},{"location":"userguide/install.html#additional-requirements","text":"In order to use the Code Coverage functionality of utPLSQL, users executing the tests must have the CREATE privilege on the PLSQL code that the coverage is gathered on. This is a requirement of DBMS_PROFILER package . In practice, user running tests for PLSQL code that he does not own, needs to have CREATE ANY PROCEDURE/CREATE ANY TRIGGER privileges. Running code coverage on objects that the user does not own will not produce any coverage information without those privileges.","title":"Additional requirements"},{"location":"userguide/install.html#uninstalling-utplsql","text":"To uninstall run uninstall.sql and provide schema_name where utPLSQL is installed. Example invocation: cd source sqlplus admin/admins_password@database @uninstall.sql ut3 The uninstall script will remove all the objects installed by the installation script. Additionally, all the public and private synonyms pointing to the objects in the utPLSQL schema will be removed. If you have extended any utPLSQL types such as a custom reporter, these will need to be dropped before the uninstall, otherwise the uninstall script might fail. The uninstall script does not drop the schema. In order for the uninstall to be successful, you need to use the uninstall script that was provided with the exact utPLSQL version installed on your database. i.e. the uninstall script provided with version 3.1.11 will not work correctly if you want to remove version 3.0.0 from your database. Alternatively you can drop the user that owns utPLSQL and re-create it using headless install.","title":"Uninstalling utPLSQL"},{"location":"userguide/install.html#version-upgrade","text":"Currently, the only way to upgrade version of utPLSQL v3.0.0 and above is to remove the previous version and install the new version.","title":"Version upgrade"},{"location":"userguide/install.html#working-with-utplsql-v2","text":"If you are using utPLSQL v2, you can still install utPLSQL v3. The only requirement is that utPLSQL v3 needs to be installed in a different schema than utPLSQL v2. utPLSQL v3 and utPLSQL v2 do not collide on public synonym names.","title":"Working with utPLSQL v2"},{"location":"userguide/querying_suites.html","text":"Obtaining information about suites \u00b6 utPLSQL framework provides ability to read inforamtion about unit test suites that exist in a schema. Pipelined table function ut_runner.get_suites_info(a_owner, a_package_name) allows you to retrieve information about: all suites that exist in a given user/schema individual test suite pacakage Querying the data from function provides the follwing details: object_owner - the owner of test suite packages object_name - the name of test suite package item_name - the name of suite/test item_description - the description of suite/suite item item_type - the type of item (UT_SUITE/UT_SUITE_CONTEXT/UT_TEST/UT_LOGICAL_SUITE) item_line_no - line_number where annotation identifying the item exists path - suitepath of the item disabled_flag - (0/1) indicator if item is disabled by --%disabled annotation tags - tags associated with suites To get list of all test suites in current schema select * from table ( ut_runner . get_suites_info ()) where item_type = 'UT_SUITE' ; To get list of all tests for test suite TEST_STUFF in current user schema select * from table ( ut_runner . get_suites_info ( USER , 'TEST_STUFF' )) where item_type = 'UT_TEST' ; To get a full information about suite TEST_STUFF including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( USER , 'TEST_STUFF' )) where item_type = 'UT_TEST' ; To get a full information about suites that have a path like ut3:tests.test_package_* including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( 'ut3:tests.test_package_*' ) where item_type = 'UT_TEST' ; To get a full information about suites that have object name like test_package_* including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( 'test_package_*' )); Checking if schema contains tests \u00b6 Function ut_runner.has_suites(a_owner) returns boolean value indicating if given schema contains test suites. Example: begin if ut_runner . has_suites ( USER ) then dbms_output . put_line ( 'User ' || USER || ' owns test suites' ); else dbms_output . put_line ( 'User ' || USER || ' does not own test suites' ); end if ; end ; Checking if package is a test suite \u00b6 Function ut_runner.is_suite(a_owner, a_package_name) returns boolean value indicating if given package is a test suites. Example: begin if ut_runner . is_suite ( USER , 'TEST_STUFF' ) then dbms_output . put_line ( 'Package ' || USER || '.TEST_STUFF is a test suite' ); else dbms_output . put_line ( 'Package ' || USER || '.TEST_STUFF is not a test suite' ); end if ; end ; Checking if procedure is a test within a suite \u00b6 Function ut_runner.is_test(a_owner, a_package_name, a_procedure_name) returns boolean value indicating if given package is a test suites. Example: begin if ut_runner . is_test ( USER , 'TEST_STUFF' , 'A_TEST_TO_CHECK_STUFF' ) then dbms_output . put_line ( 'Procedure ' || USER || '.TEST_STUFF.A_TEST_TO_CHECK_STUFF is a test' ); else dbms_output . put_line ( 'Procedure ' || USER || '.TEST_STUFF.A_TEST_TO_CHECK_STUFF is not a test' ); end if ; end ;","title":"Querying for test suites"},{"location":"userguide/querying_suites.html#obtaining-information-about-suites","text":"utPLSQL framework provides ability to read inforamtion about unit test suites that exist in a schema. Pipelined table function ut_runner.get_suites_info(a_owner, a_package_name) allows you to retrieve information about: all suites that exist in a given user/schema individual test suite pacakage Querying the data from function provides the follwing details: object_owner - the owner of test suite packages object_name - the name of test suite package item_name - the name of suite/test item_description - the description of suite/suite item item_type - the type of item (UT_SUITE/UT_SUITE_CONTEXT/UT_TEST/UT_LOGICAL_SUITE) item_line_no - line_number where annotation identifying the item exists path - suitepath of the item disabled_flag - (0/1) indicator if item is disabled by --%disabled annotation tags - tags associated with suites To get list of all test suites in current schema select * from table ( ut_runner . get_suites_info ()) where item_type = 'UT_SUITE' ; To get list of all tests for test suite TEST_STUFF in current user schema select * from table ( ut_runner . get_suites_info ( USER , 'TEST_STUFF' )) where item_type = 'UT_TEST' ; To get a full information about suite TEST_STUFF including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( USER , 'TEST_STUFF' )) where item_type = 'UT_TEST' ; To get a full information about suites that have a path like ut3:tests.test_package_* including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( 'ut3:tests.test_package_*' ) where item_type = 'UT_TEST' ; To get a full information about suites that have object name like test_package_* including suite description, all contexts and tests in a suite select * from table ( ut_runner . get_suites_info ( 'test_package_*' ));","title":"Obtaining information about suites"},{"location":"userguide/querying_suites.html#checking-if-schema-contains-tests","text":"Function ut_runner.has_suites(a_owner) returns boolean value indicating if given schema contains test suites. Example: begin if ut_runner . has_suites ( USER ) then dbms_output . put_line ( 'User ' || USER || ' owns test suites' ); else dbms_output . put_line ( 'User ' || USER || ' does not own test suites' ); end if ; end ;","title":"Checking if schema contains tests"},{"location":"userguide/querying_suites.html#checking-if-package-is-a-test-suite","text":"Function ut_runner.is_suite(a_owner, a_package_name) returns boolean value indicating if given package is a test suites. Example: begin if ut_runner . is_suite ( USER , 'TEST_STUFF' ) then dbms_output . put_line ( 'Package ' || USER || '.TEST_STUFF is a test suite' ); else dbms_output . put_line ( 'Package ' || USER || '.TEST_STUFF is not a test suite' ); end if ; end ;","title":"Checking if package is a test suite"},{"location":"userguide/querying_suites.html#checking-if-procedure-is-a-test-within-a-suite","text":"Function ut_runner.is_test(a_owner, a_package_name, a_procedure_name) returns boolean value indicating if given package is a test suites. Example: begin if ut_runner . is_test ( USER , 'TEST_STUFF' , 'A_TEST_TO_CHECK_STUFF' ) then dbms_output . put_line ( 'Procedure ' || USER || '.TEST_STUFF.A_TEST_TO_CHECK_STUFF is a test' ); else dbms_output . put_line ( 'Procedure ' || USER || '.TEST_STUFF.A_TEST_TO_CHECK_STUFF is not a test' ); end if ; end ;","title":"Checking if procedure is a test within a suite"},{"location":"userguide/reporters.html","text":"utPLSQL provides the following reporting formats. Documentation reporter \u00b6 The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution Color output from documentation reporter \u00b6 When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter. JUnit reporter \u00b6 Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in JUnit format. The ut_junit_reporter in earlier version referred as ut_xunit_reporter is producing outcomes as JUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Please note that in previous versions it was called ut_xunit_reporter and for backward compatibility that name still exists. Invocation of tests with JUnit reporter. exec ut.run(ut_junit_reporter()); The ut_junit_reporter doesn't accept any arguments. Example of junit report integrated with Jenkins CI Example of failure report details Teamcity reporter \u00b6 Teamcity is a CI server by Jetbrains. It supports JUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details Sonar test reporter \u00b6 If you are using SonarQube or SonarCloud to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section. TFS / VSTS Reporter \u00b6 If you are using TFS or VSTS to do static code analysis for you PLSQL projects and run builds, your code analysis can benefit from code coverage and test results. TFS reporter is designed specifically to work with Microsoft Team Fundation Server report format which is very old version of JUnit . Main diffrence between standard JUnit is that elements cannot be nested and attribute skipped is not present. utPLSQL provides test reporter to for TFS / VSTS server: - ut_tfs_junit_reporter - provides an XML output of each test executed per each project test file (package) Example of test report from TFS CI server. Summary: Details: Coverage reporters \u00b6 utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them. Debug reporter \u00b6 The ut_debug_reporter provides a highly verbose output containing thorough details about framework and test execution. Use this reporter only when you need to investigate framework issues or raise a bug report to utPLSQL team. Usage of this reporter might have impact on performance of test-suite execution. Amongst others, reporter provides the following information: - framework version - database version - database OS - database, instance and session NLS settings - timing of each event - time between events logged - time from start of the run - stack trace - information about input parameters for the run including - run paths - source file mappings - test file mappings - coverage schemas - coverage exclusions and inclusions - client character set - information about every step of the run including - every suite and context - every before/after procedure - every test - every expectation and it's result Some of the information in debug log might be redundant. Note: Some of the information in debug log may be sensitive. In particular: - expectation results and messages (logged even for successful runs) - test structure - db object names - etc. Custom reporters \u00b6 It is possible to add your own reporters by creating an appropriate object type. In principle, it has to be a subtype of ut_reporter_base . However, if the reporter is expected to produce output consumable by a client oustside of the database (e.g. the data has to be reported to the screen or to a file), then you should base it on ut_output_reporter_base (which is a subtype of ut_reporter_base ). In contrast, if you would like to create a reporter that, for example, saves the data to a database table, then it should be based directly on ut_reporter_base . (Currently, all reporters in the utPLSQL framework are based on ut_output_reporter_base .) Coverage reporters are based on ut_coverage_reporter_base (a subtype of ut_output_reporter_base ). If you need to produce a colored text output from the custom reporter, then you can build it basing on ut_console_reporter_base (a subtype of ut_output_reporter_base ). In many cases it may also be more convenient to create the custom reporter type under a more specialized type, like ut_documentation_reporter or ut_junit_reporter , and override just some of the functionality. It is recommended to create the reporter type in the schema where utPLSQL is installed (by default it is the UT3 schema). Note that before running the utPLSQL uninstall scripts, all custom reporters should be dropped (cf. the installation documentation ). In particular, when upgrading to a newer version of utPLSQL, one has to drop the custom reporters and recreate them after the upgrade. Note: It is possible, but cumbersome, to use another schema for storing the custom reporters. This requires to create a synonym for the base reporter type in the schema that is going to own the custom reporter, and to provide appropriate grants both to the owner of the custom reporter and to the user running the reporter. After upgrading or reinstalling utPLSQL, the extra privileges need to be recreated. This approach is not recommended. Assuming that the custom reporter type is created in the UT3 schema, to run the tests using a custom reporter just call: exec ut.run(ut3.custom_reporter_name()); , optionally providing parameter values to the custom_reporter_name constructor. One may get acquainted with the source code of the standard reporters bundled with utPLSQL (including the coverage reporters) by browsing the source/reporters/ directory. The base reporter types ut_reporter_base , ut_output_reporter_base and ut_console_reporter_base are defined in source/core/types . The base coverage reporter type ut_coverage_reporter_base is in source/core/coverage . There are also two examples of custom reporters in examples/custom_reporters/ , both extending the functionality of ut_documentation_reporter : ut_custom_reporter accepts an integer parameter a_tab_size ; it alters the behaviour of ut_documentation_reporter by changing the size of the indentation according to the parameter value (by default the indentation is increased). ut_expectations_reporter accepts a varchar2 parameter a_report_all_expectations ; if its value is 'Y' (which is the default), then the reporter shows the results of all expectations that are run. This stays in contrast with ut_documentation_reporter , which shows the results of all tests that are run, but only of the expectations that failed (keep in mind that a single test may consist of several expectations).","title":"Using reporters"},{"location":"userguide/reporters.html#documentation-reporter","text":"The ut_documentation_reporter is the default reporting format used by the framework. It provides a human readable test results. To invoke tests with documentation reporter use one of following calls from sql console (SQLPlus) exec ut.run(); exec ut.run(ut_documentation_reporter()); Example outputs from documentation reporter. The documentation report provides the following information. - Test suite name or test package name (nested with suitepath if suitepath is used) - Test description name or test procedure name - Information about test failing (FAILED - n) - Information about disabled test (IGNORED) - List of all errors and failures - Summary with total number of tests, number of tests with status and timing for the execution","title":"Documentation reporter"},{"location":"userguide/reporters.html#color-output-from-documentation-reporter","text":"When invoking tests with documentation reporter and your command line supports ANSICONSOLE (default on Unix) available for Windows , you can obtain the coloured outputs from the documentation reporter. To invoke tests with documentation reporter in color mode use one of following calls. exec ut.run(a_color_console=>true); exec ut.run(ut_documentation_reporter(), a_color_console=>true); Example outputs from documentation reporter.","title":"Color output from documentation reporter"},{"location":"userguide/reporters.html#junit-reporter","text":"Most of continuous integration servers (like Jenkins) are capable of consuming unit test execution results in JUnit format. The ut_junit_reporter in earlier version referred as ut_xunit_reporter is producing outcomes as JUnit-compatible XML unit test report, that can be used by CI servers to display their custom reports and provide metrics (like tests execution trends). Please note that in previous versions it was called ut_xunit_reporter and for backward compatibility that name still exists. Invocation of tests with JUnit reporter. exec ut.run(ut_junit_reporter()); The ut_junit_reporter doesn't accept any arguments. Example of junit report integrated with Jenkins CI Example of failure report details","title":"JUnit reporter"},{"location":"userguide/reporters.html#teamcity-reporter","text":"Teamcity is a CI server by Jetbrains. It supports JUnit reporting and additionally has it's own format of reporting that allows tracking of progress of a CI step/task as it executes. The TeamCity format developed by Jetbrains is supported by utPLSQL with ut_teamcity_reporter . Invocation of tests with Teamcity reporter. exec ut.run(ut_teamcity_reporter()); The ut_teamcity_reporter doesn't accept any arguments. Example of unit test report from Teamcity CI server. Example of failure report details","title":"Teamcity reporter"},{"location":"userguide/reporters.html#sonar-test-reporter","text":"If you are using SonarQube or SonarCloud to do static code analysis for you PLSQL projects, your code analysis can benefit from code coverage and test results. utPLSQL provides two reporters to for SonarQube: - ut_sonar_test_reporter - provides an XML output of each test executed per each project test file (package) - ut_coverage_sonar_reporter - provides XML output of code coverage per each project source file ut_sonar_test_reporter needs to be called with a list of paths to test files (packages). The paths to files can be relative to the project root directory (recommended) or be absolute. ut_coverage_sonar_reporter needs to be called with a list of paths to source files for your project. The paths to files can be relative to the project root directory (recommended) or be absolute. Providing invalid paths or paths to non-existing files will result in failure when publishing test results/coverage results to sonar server. For details on how to invoke reporter with paths, see the Coverage reporters section.","title":"Sonar test reporter"},{"location":"userguide/reporters.html#tfs-vsts-reporter","text":"If you are using TFS or VSTS to do static code analysis for you PLSQL projects and run builds, your code analysis can benefit from code coverage and test results. TFS reporter is designed specifically to work with Microsoft Team Fundation Server report format which is very old version of JUnit . Main diffrence between standard JUnit is that elements cannot be nested and attribute skipped is not present. utPLSQL provides test reporter to for TFS / VSTS server: - ut_tfs_junit_reporter - provides an XML output of each test executed per each project test file (package) Example of test report from TFS CI server. Summary: Details:","title":"TFS / VSTS Reporter"},{"location":"userguide/reporters.html#coverage-reporters","text":"utPLSQL comes with a set of build-in coverage reporters. Have a look into the coverage documentation to learn more about them.","title":"Coverage reporters"},{"location":"userguide/reporters.html#debug-reporter","text":"The ut_debug_reporter provides a highly verbose output containing thorough details about framework and test execution. Use this reporter only when you need to investigate framework issues or raise a bug report to utPLSQL team. Usage of this reporter might have impact on performance of test-suite execution. Amongst others, reporter provides the following information: - framework version - database version - database OS - database, instance and session NLS settings - timing of each event - time between events logged - time from start of the run - stack trace - information about input parameters for the run including - run paths - source file mappings - test file mappings - coverage schemas - coverage exclusions and inclusions - client character set - information about every step of the run including - every suite and context - every before/after procedure - every test - every expectation and it's result Some of the information in debug log might be redundant. Note: Some of the information in debug log may be sensitive. In particular: - expectation results and messages (logged even for successful runs) - test structure - db object names - etc.","title":"Debug reporter"},{"location":"userguide/reporters.html#custom-reporters","text":"It is possible to add your own reporters by creating an appropriate object type. In principle, it has to be a subtype of ut_reporter_base . However, if the reporter is expected to produce output consumable by a client oustside of the database (e.g. the data has to be reported to the screen or to a file), then you should base it on ut_output_reporter_base (which is a subtype of ut_reporter_base ). In contrast, if you would like to create a reporter that, for example, saves the data to a database table, then it should be based directly on ut_reporter_base . (Currently, all reporters in the utPLSQL framework are based on ut_output_reporter_base .) Coverage reporters are based on ut_coverage_reporter_base (a subtype of ut_output_reporter_base ). If you need to produce a colored text output from the custom reporter, then you can build it basing on ut_console_reporter_base (a subtype of ut_output_reporter_base ). In many cases it may also be more convenient to create the custom reporter type under a more specialized type, like ut_documentation_reporter or ut_junit_reporter , and override just some of the functionality. It is recommended to create the reporter type in the schema where utPLSQL is installed (by default it is the UT3 schema). Note that before running the utPLSQL uninstall scripts, all custom reporters should be dropped (cf. the installation documentation ). In particular, when upgrading to a newer version of utPLSQL, one has to drop the custom reporters and recreate them after the upgrade. Note: It is possible, but cumbersome, to use another schema for storing the custom reporters. This requires to create a synonym for the base reporter type in the schema that is going to own the custom reporter, and to provide appropriate grants both to the owner of the custom reporter and to the user running the reporter. After upgrading or reinstalling utPLSQL, the extra privileges need to be recreated. This approach is not recommended. Assuming that the custom reporter type is created in the UT3 schema, to run the tests using a custom reporter just call: exec ut.run(ut3.custom_reporter_name()); , optionally providing parameter values to the custom_reporter_name constructor. One may get acquainted with the source code of the standard reporters bundled with utPLSQL (including the coverage reporters) by browsing the source/reporters/ directory. The base reporter types ut_reporter_base , ut_output_reporter_base and ut_console_reporter_base are defined in source/core/types . The base coverage reporter type ut_coverage_reporter_base is in source/core/coverage . There are also two examples of custom reporters in examples/custom_reporters/ , both extending the functionality of ut_documentation_reporter : ut_custom_reporter accepts an integer parameter a_tab_size ; it alters the behaviour of ut_documentation_reporter by changing the size of the indentation according to the parameter value (by default the indentation is increased). ut_expectations_reporter accepts a varchar2 parameter a_report_all_expectations ; if its value is 'Y' (which is the default), then the reporter shows the results of all expectations that are run. This stays in contrast with ut_documentation_reporter , which shows the results of all tests that are run, but only of the expectations that failed (keep in mind that a single test may consist of several expectations).","title":"Custom reporters"},{"location":"userguide/running-unit-tests.html","text":"utPLSQL framework provides two main entry points to run unit tests from within the database: ut.run procedures and functions ut_runner.run procedures These two entry points differ in purpose and behavior. Most of the time you will want to use ut.run as ut_runner.run is designed for API integration and does not display the results to the screen. Running from CI servers and command line \u00b6 The best way to run your tests from CI server or command line is to use the utPLSQL-cli command line client. Amongst many benefits it provides ability to: * see the progress of test execution for long-running tests - real-time reporting * use many reporting formats simultaneously and save reports to files (publish) * map your project source files and test files into database objects You may download the latest release of the command line client from here or do it automatically using the command below (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-cli/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-cli.zip ut.run \u00b6 The ut package contains overloaded run procedures and functions. The run API is designed to be called directly by a developer when using an IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. A single line call is enough to execute a set of tests from one or more schemes. The procedures execute the specified tests and produce output to DBMS_OUTPUT using the specified reporter. The functions can only be used in SELECT statements. They execute the specified tests and produce outputs as a pipelined data stream to be consumed by a select statement. ut.run procedures \u00b6 The examples below illustrate different ways and options to invoke ut.run procedures. You can use a wildcard character * to call tests by part of their name or to call tests that are located on paths matched by part of path string. Wildcard character can be placed anywhere on the path and can occur mutliple times. Schema name cannot contain a wildcard character whether is in a suitepath call or call by object name. alter session set current_schema = hr ; set serveroutput on begin ut . run (); end ; Executes all tests in current schema ( HR ). set serveroutput on begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). set serveroutput on begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. set serveroutput on begin ut . run ( 'hr:com*' ); end ; Executes all tests in schema hr from all packages that are on suitepath starting with com . set serveroutput on begin ut . run ( 'hr:co*.my_*.my_*' ); end ; Executes all tests in schema hr from all packages that starting with my_ and all tests starting with my_* that are on suitepath starting with co . set serveroutput on begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . set serveroutput on begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . set serveroutput on begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . set serveroutput on begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus,cust)' ); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . set serveroutput on begin ut . run ( 'hr.test_apply_bonus,cust' ); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. List can be passed as a comma separated list or a list of ut_varchar2_list objects or as a list within ut_varchar2_list. set serveroutput on begin ut . run ( 'hr.test*' ); end ; Executes all tests in schema hr located in packages starting with name test . set serveroutput on begin ut . run ( 'hr.test_apply_bonus.bonus_*' ); end ; Executes test procedures with names starting with bonus in package hr.test_apply_bonus . Note: ut_documentation_reporter is the default reporter for all APIs defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the JUnit reporter. For details on build-in reporters look at reporters documentation . ut.run functions \u00b6 The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide output as a pipelined stream and therefore need to be executed as select statements. Note: When running tests with ut.run functions, whole test run is executed as autonomous transaction. At the end of the run, the transaction is automatically rolled-back and all uncommitted changes are reverted. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter ())); ut_runner.run procedures \u00b6 The ut_runner package provides an API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference compared to the ut.run API is that ut_runner.run does not print output to the screen. ut_runner.run accepts multiple reporters. Each reporter pipes to a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. ut_runner.run API is used by utPLSQL-cli, utPLSQL-SQLDeveloper extension and utPLSQL-maven-plugin and allows for: - deciding on the scope of test run (by schema names, object names, suite paths or tags ) - running tests with several concurrent reporters - real-time reporting of test execution progress - controlling colored text output to the screen - controlling scope of code coverage reports - mapping of database source code to project files - controlling behavior on test-failures - controlling client character set for HTML and XML reports - controlling rollback behavior of test-run - controlling random order of test execution Running with multiple reporters. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_ids. as a separate thread, start ut_runner.run and pass reporters with previously defined output_ids. for each reporter start a separate thread and read outputs from the reporter.get_lines table function or from reporter.get_lines_cursor() by providing the reporter_id defined in the main thread. each reporter for each test-run must have a unique reporter_id . The reporter_id is used between two sessions to identify the data stream Example: --main test run ( session 1 ) declare l_reporter ut_realtime_reporter : = ut_realtime_reporter (); begin l_reporter . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ); l_reporter . output_buffer . init (); ut_runner . run ( ut_varchar2_list ( 'ut3_tester' , 'ut3_user' ), ut_reporters ( l_reporter ) ); end ; / --report consumer ( session 2 ) set arraysize 1 set pagesize 0 select * from table ( ut_realtime_reporter () . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ) . get_lines () ); --alternative version of report consumer ( session 2 ) set arraysize 1 set pagesize 0 select ut_realtime_reporter () . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ) . get_lines_cursor () from dual ; Order of test execution \u00b6 Default order \u00b6 When unit tests are executed without random order, they are ordered by: - schema name - suite path or test package name if --%suitepath was not specified for that package - --%test line number in package Random order \u00b6 You can force a test run to execute tests in random order by providing one of options to ut.run : - a_random_test_order - true/false for procedures and 1/0 for functions - a_random_test_order_seed - positive number in range of 1 .. 1 000 000 000 When tests are executed with random order, randomization is applied to single level of suitepath hierarchy tree. This is needed to maintain visibility and accessibility of common setup/cleanup beforeall / afterall in tests. Example: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_random_test_order => true ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_random_test_order => 1 )); When running with random order, the default report ( ut_documentation_reporter ) will include information about the random test run seed. Example output: ... Finished in .12982 seconds 35 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s) Tests were executed with random order seed '302980531'. If you want to re-run tests using previously generated seed, you may do so by running them with parameter a_random_test_order_seed Example: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_random_test_order_seed => 302980531 ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_random_test_order_seed => 302980531 )); Note Random order seed must be a positive number within range of 1 .. 1 000 000 000. Run by Tags \u00b6 In addition to the path, you can filter the tests to be run by specifying tags. Tags are defined in the test / context / suite with the --%tags -annotation ( Read more ). Multiple tags are separated by comma. The framework applies OR logic to all specified tags so any test / suite that matches at least one tag will be included in the test run. begin ut . run ( 'hr.test_apply_bonus' , a_tags => 'test1,test2' ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_tags => 'suite1' )) You can also exclude specific tags by adding a - (dash) in front of the tag select * from table ( ut . run ( 'hr.test_apply_bonus' , a_tags => '-suite1' )) Keeping uncommitted data after test-run \u00b6 utPLSQL by default runs tests in autonomous transaction and performs automatic rollback to assure that tests do not impact one-another and do not have impact on the current session in your IDE. If you would like to keep your uncommitted data persisted after running tests, you can do so by using a_force_manual_rollback flag. Setting this flag to true has following side-effects: test execution is done in current transaction - if while running tests commit or rollback is issued your current session data will get commited too. automatic rollback is forced to be disabled in test-run even if it was explicitly enabled by using annotation `--%rollback(manual) Example invocation: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_force_manual_rollback => true ); end ; Note: This option is not available when running tests using ut.run as a table function. Reports character-set encoding \u00b6 To get properly encoded reports, when running utPLSQL with HTML/XML reports on data containing national characters you need to provide your client character set when calling ut.run functions and procedures. If you run your tests using utPLSQL-cli , this is done automatically and no action needs to be taken. To make sure that the reports will display your national characters properly when running from IDE like SQLDeveloper/TOAD/SQLPlus or sqlcl you need to provide the charaterset manualy to ut.run . Example call with characterset provided: begin ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter (), a_client_character_set => 'Windows-1251' ); end ;","title":"Running unit tests"},{"location":"userguide/running-unit-tests.html#running-from-ci-servers-and-command-line","text":"The best way to run your tests from CI server or command line is to use the utPLSQL-cli command line client. Amongst many benefits it provides ability to: * see the progress of test execution for long-running tests - real-time reporting * use many reporting formats simultaneously and save reports to files (publish) * map your project source files and test files into database objects You may download the latest release of the command line client from here or do it automatically using the command below (Unix). #!/bin/bash # Get the url to latest release \"zip\" file DOWNLOAD_URL = $( curl --silent https://api.github.com/repos/utPLSQL/utPLSQL-cli/releases/latest | awk '/browser_download_url/ { print $2 }' | grep \".zip\\\"\" | sed 's/\"//g' ) # Download the latest release \"zip\" file curl -Lk \" ${ DOWNLOAD_URL } \" -o utplsql-cli.zip # Extract downloaded \"zip\" file unzip -q utplsql-cli.zip","title":"Running from CI servers and command line"},{"location":"userguide/running-unit-tests.html#utrun","text":"The ut package contains overloaded run procedures and functions. The run API is designed to be called directly by a developer when using an IDE/SQL console to execute unit tests. The main benefit of using this API is it's simplicity. A single line call is enough to execute a set of tests from one or more schemes. The procedures execute the specified tests and produce output to DBMS_OUTPUT using the specified reporter. The functions can only be used in SELECT statements. They execute the specified tests and produce outputs as a pipelined data stream to be consumed by a select statement.","title":"ut.run"},{"location":"userguide/running-unit-tests.html#utrun-procedures","text":"The examples below illustrate different ways and options to invoke ut.run procedures. You can use a wildcard character * to call tests by part of their name or to call tests that are located on paths matched by part of path string. Wildcard character can be placed anywhere on the path and can occur mutliple times. Schema name cannot contain a wildcard character whether is in a suitepath call or call by object name. alter session set current_schema = hr ; set serveroutput on begin ut . run (); end ; Executes all tests in current schema ( HR ). set serveroutput on begin ut . run ( 'HR' ); end ; Executes all tests in specified schema ( HR ). set serveroutput on begin ut . run ( 'hr:com.my_org.my_project' ); end ; Executes all tests from all packages that are on the com.my_org.my_project suitepath. Check the annotations documentation to find out about suitepaths and how they can be used to organize test packages for your project. set serveroutput on begin ut . run ( 'hr:com*' ); end ; Executes all tests in schema hr from all packages that are on suitepath starting with com . set serveroutput on begin ut . run ( 'hr:co*.my_*.my_*' ); end ; Executes all tests in schema hr from all packages that starting with my_ and all tests starting with my_* that are on suitepath starting with co . set serveroutput on begin ut . run ( 'hr.test_apply_bonus' ); end ; Executes all tests from package hr.test_apply_bonus . set serveroutput on begin ut . run ( 'hr.test_apply_bonus.bonus_cannot_be_negative' ); end ; Executes single test procedure hr.test_apply_bonus.bonus_cannot_be_negative . set serveroutput on begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus' , 'cust' )); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . set serveroutput on begin ut . run ( ut_varchar2_list ( 'hr.test_apply_bonus,cust)' ); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . set serveroutput on begin ut . run ( 'hr.test_apply_bonus,cust' ); end ; Executes all tests from package hr.test_apply_bonus and all tests from schema cust . Using a list of items to execute allows you to execute a fine-grained set of tests. List can be passed as a comma separated list or a list of ut_varchar2_list objects or as a list within ut_varchar2_list. set serveroutput on begin ut . run ( 'hr.test*' ); end ; Executes all tests in schema hr located in packages starting with name test . set serveroutput on begin ut . run ( 'hr.test_apply_bonus.bonus_*' ); end ; Executes test procedures with names starting with bonus in package hr.test_apply_bonus . Note: ut_documentation_reporter is the default reporter for all APIs defined for running unit tests. The ut.run procedures and functions accept a_reporter attribute that defines the reporter to be used in the run. You can execute any set of tests with any of the predefined reporters. set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter ()); end ; Executes all tests from package HR.TEST_APPLY_BONUS and provide outputs to DBMS_OUTPUT using the JUnit reporter. For details on build-in reporters look at reporters documentation .","title":"ut.run procedures"},{"location":"userguide/running-unit-tests.html#utrun-functions","text":"The ut.run functions provide exactly the same functionality as the ut.run procedures. You may use the same sets of parameters with both functions and procedures. The only difference is the output of the results. Functions provide output as a pipelined stream and therefore need to be executed as select statements. Note: When running tests with ut.run functions, whole test run is executed as autonomous transaction. At the end of the run, the transaction is automatically rolled-back and all uncommitted changes are reverted. Example. select * from table ( ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter ()));","title":"ut.run functions"},{"location":"userguide/running-unit-tests.html#ut_runnerrun-procedures","text":"The ut_runner package provides an API for integrating utPLSQL with other products. Maven, Jenkins, SQL Develper, PL/SQL Developer, TOAD and others can leverage this API to call utPLSQL. The main difference compared to the ut.run API is that ut_runner.run does not print output to the screen. ut_runner.run accepts multiple reporters. Each reporter pipes to a separate output (uniquely identified by output_id). Outputs of multiple reporters can be consumed in parallel. This allows for live reporting of test execution progress with threads and several database sessions. ut_runner.run API is used by utPLSQL-cli, utPLSQL-SQLDeveloper extension and utPLSQL-maven-plugin and allows for: - deciding on the scope of test run (by schema names, object names, suite paths or tags ) - running tests with several concurrent reporters - real-time reporting of test execution progress - controlling colored text output to the screen - controlling scope of code coverage reports - mapping of database source code to project files - controlling behavior on test-failures - controlling client character set for HTML and XML reports - controlling rollback behavior of test-run - controlling random order of test execution Running with multiple reporters. in the main thread (session), define the reporters to be used. Each reporter has it's output_id and so you need to extract and store those output_ids. as a separate thread, start ut_runner.run and pass reporters with previously defined output_ids. for each reporter start a separate thread and read outputs from the reporter.get_lines table function or from reporter.get_lines_cursor() by providing the reporter_id defined in the main thread. each reporter for each test-run must have a unique reporter_id . The reporter_id is used between two sessions to identify the data stream Example: --main test run ( session 1 ) declare l_reporter ut_realtime_reporter : = ut_realtime_reporter (); begin l_reporter . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ); l_reporter . output_buffer . init (); ut_runner . run ( ut_varchar2_list ( 'ut3_tester' , 'ut3_user' ), ut_reporters ( l_reporter ) ); end ; / --report consumer ( session 2 ) set arraysize 1 set pagesize 0 select * from table ( ut_realtime_reporter () . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ) . get_lines () ); --alternative version of report consumer ( session 2 ) set arraysize 1 set pagesize 0 select ut_realtime_reporter () . set_reporter_id ( 'd8a79e85915640a6a4e1698fdf90ba74' ) . get_lines_cursor () from dual ;","title":"ut_runner.run procedures"},{"location":"userguide/running-unit-tests.html#order-of-test-execution","text":"","title":"Order of test execution"},{"location":"userguide/running-unit-tests.html#default-order","text":"When unit tests are executed without random order, they are ordered by: - schema name - suite path or test package name if --%suitepath was not specified for that package - --%test line number in package","title":"Default order"},{"location":"userguide/running-unit-tests.html#random-order","text":"You can force a test run to execute tests in random order by providing one of options to ut.run : - a_random_test_order - true/false for procedures and 1/0 for functions - a_random_test_order_seed - positive number in range of 1 .. 1 000 000 000 When tests are executed with random order, randomization is applied to single level of suitepath hierarchy tree. This is needed to maintain visibility and accessibility of common setup/cleanup beforeall / afterall in tests. Example: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_random_test_order => true ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_random_test_order => 1 )); When running with random order, the default report ( ut_documentation_reporter ) will include information about the random test run seed. Example output: ... Finished in .12982 seconds 35 tests, 0 failed, 0 errored, 1 disabled, 0 warning(s) Tests were executed with random order seed '302980531'. If you want to re-run tests using previously generated seed, you may do so by running them with parameter a_random_test_order_seed Example: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_random_test_order_seed => 302980531 ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_random_test_order_seed => 302980531 )); Note Random order seed must be a positive number within range of 1 .. 1 000 000 000.","title":"Random order"},{"location":"userguide/running-unit-tests.html#run-by-tags","text":"In addition to the path, you can filter the tests to be run by specifying tags. Tags are defined in the test / context / suite with the --%tags -annotation ( Read more ). Multiple tags are separated by comma. The framework applies OR logic to all specified tags so any test / suite that matches at least one tag will be included in the test run. begin ut . run ( 'hr.test_apply_bonus' , a_tags => 'test1,test2' ); end ; select * from table ( ut . run ( 'hr.test_apply_bonus' , a_tags => 'suite1' )) You can also exclude specific tags by adding a - (dash) in front of the tag select * from table ( ut . run ( 'hr.test_apply_bonus' , a_tags => '-suite1' ))","title":"Run by Tags"},{"location":"userguide/running-unit-tests.html#keeping-uncommitted-data-after-test-run","text":"utPLSQL by default runs tests in autonomous transaction and performs automatic rollback to assure that tests do not impact one-another and do not have impact on the current session in your IDE. If you would like to keep your uncommitted data persisted after running tests, you can do so by using a_force_manual_rollback flag. Setting this flag to true has following side-effects: test execution is done in current transaction - if while running tests commit or rollback is issued your current session data will get commited too. automatic rollback is forced to be disabled in test-run even if it was explicitly enabled by using annotation `--%rollback(manual) Example invocation: set serveroutput on begin ut . run ( 'hr.test_apply_bonus' , a_force_manual_rollback => true ); end ; Note: This option is not available when running tests using ut.run as a table function.","title":"Keeping uncommitted data after test-run"},{"location":"userguide/running-unit-tests.html#reports-character-set-encoding","text":"To get properly encoded reports, when running utPLSQL with HTML/XML reports on data containing national characters you need to provide your client character set when calling ut.run functions and procedures. If you run your tests using utPLSQL-cli , this is done automatically and no action needs to be taken. To make sure that the reports will display your national characters properly when running from IDE like SQLDeveloper/TOAD/SQLPlus or sqlcl you need to provide the charaterset manualy to ut.run . Example call with characterset provided: begin ut . run ( 'hr.test_apply_bonus' , ut_junit_reporter (), a_client_character_set => 'Windows-1251' ); end ;","title":"Reports character-set encoding"},{"location":"userguide/upgrade.html","text":"Upgrading from version 2 \u00b6 utPLSQL v3 is a total rewrite of the framework. To make utPLSQL v2 packages run on v3 framework you need to install and execute migration utility. See the utPLSQL-v2-v3-migration project for details on how to install and execute the migration.","title":"Upgrade utPLSQL"},{"location":"userguide/upgrade.html#upgrading-from-version-2","text":"utPLSQL v3 is a total rewrite of the framework. To make utPLSQL v2 packages run on v3 framework you need to install and execute migration utility. See the utPLSQL-v2-v3-migration project for details on how to install and execute the migration.","title":"Upgrading from version 2"}]}